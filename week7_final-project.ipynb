{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Проект: предсказания победителя в онлайн-игре](https://www.coursera.org/learn/vvedenie-mashinnoe-obuchenie/peer/J1SH8/proiekt-priedskazaniia-pobieditielia-v-onlain-ighrie)\n",
    "\n",
    "\n",
    "[Dota 2](https://en.wikipedia.org/wiki/Dota_2) — многопользовательская компьютерная игра жанра [MOBA](https://en.wikipedia.org/wiki/Multiplayer_online_battle_arena). Игроки играют между собой матчи. В каждом матче, как правило, участвует 10 человек. Матчи формируются из живой очереди, с учётом уровня игры всех игроков. Перед началом игры игроки автоматически разделяются на две команды по пять человек. Одна команда играет за светлую сторону (The Radiant), другая — за тёмную (The Dire). Цель каждой команды — уничтожить главное здание базы противника, трон.\n",
    "\n",
    "Вам нужно построить модель, которая по данным о первых пяти минутах матча будет предсказывать его исход — то есть определять команду-победителя.\n",
    "\n",
    "Чтобы выполнить это задание, вам необходимо провести ряд исследований, сравнить несколько алгоритмов машинного обучения и проверить эффект от ряда манипуляций с признаками. Также, если вам понравится работать с этими данными, вы можете принять участие в [соревновании на Kaggle](https://kaggle.com/join/coursera_ml_dota2_contest) и сравнить свои навыки с другими участниками курса!\n",
    "\n",
    "К заданию приложены следующие файлы:\n",
    "\n",
    "* final-statement.ipynb и final-statement.html — постановка задачи, описание данных, инструкции по выполнению\n",
    "* features.zip — архив с обучающей выборкой\n",
    "* features_test.zip — архив с тестовой выборкой\n",
    "* data.zip — полный архив с сырыми данными и скриптом для извлечения признаков (этот архив понадобится вам только для участия в kaggle; для выполнения данного задания он не нужен)\n",
    "\n",
    "[final-statement.html](https://d3c33hcgiwev3.cloudfront.net/_e60a53b55ae721da5831786533147c27_final-statement.html?Expires=1457481600&Signature=f0tU2fG3UTmqzjrxs-dz40r31S~0jMwUW9wR2RiDVFy9VV9FIePdw~NrT2oObVuYVr7p1iQxsKrlwroNXqa0nYAGMp2fa~NwBGdqEisnbpCbHU8rBBlLKsaaOzSzdOyKwacp4y465qR-TIsDGnN1GtcmrrwduHObeOdGs7s5NJc_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A)\n",
    "\n",
    "[final-statement.ipynb](https://d3c33hcgiwev3.cloudfront.net/_e60a53b55ae721da5831786533147c27_final-statement.ipynb?Expires=1457481600&Signature=XfE89gtPaIx0gn5tFt9pJ5ymG361DOWmBmwrJG2vqU6Gn66BPuz9AL2L7bHU1t9ZF51q43QbAyCet5NSmzS6rDdL5brdHpQ5fAQ7fbeLO2CT2SMXejGnqg4azte11LEiX4~XnSoHTAK8yGDfaMILFuPk-rDOC~13bBqCY8EuivE_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A)\n",
    "\n",
    "[features.zip](https://d3c33hcgiwev3.cloudfront.net/_47ea8666d262362a0b41164cb497658e_features.zip?Expires=1457481600&Signature=KwYUSQlGPM4obwR3UlplFXMk16Ssy5TwyS9bcbDlTv2dQQ6Xv2GuU50YZeoLLYb2c0dKxI1dlyfsNtfT4uFAXxov-s0CYBCwp1YlNDPw4tjkhZV0GDGWtXuYgDlsEdyB-tYV~vZcZ4xG2rtEcF6~DgAuOwzgkDJ9Q6ZLUbop5Mk_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A)\n",
    "\n",
    "[features_test.zip](https://d3c33hcgiwev3.cloudfront.net/_6866d458468373e164b1e859f3103826_features_test.zip?Expires=1457481600&Signature=J1gWAykqyOms-b3LshhbkAhLdJZ0on412Wq5Uepa7Arhmfu9PRJwviQz~eL0sgTX2EnJz3Y4By4nQk2BES2EOwj7e3iZrDuY0LkAw~czv~JRFgT0bNcZbLeA~ZIMRmUzHVV48S1VHKdBQna~w830uOVDi8Y3lMcwCZrib~kIHho_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A)\n",
    "\n",
    "[data.zip](https://d3c33hcgiwev3.cloudfront.net/_0af1b642c31910510072aee30c1db762_data.zip?Expires=1457481600&Signature=cKd63HB1rvoLQODgNrevDYtRWOGS4gRcGg91RwFejOX3JFgpCqteL9SI6KxIm6EY69-DZkRD08~yiF7q7c1hh9muH6dVmVlnZT3wqjvhh7cUOwJ2gCMgTGjwgjqdp2gsq3ewnW7zanaJVnOqsGzNiY~2C5oxIX258XmVhf6wzaE_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A)\n",
    "\n",
    "Будет удобно выполнять это задание в IPython/Jupyter Notebook — интерактивной среде, которая устанавливается, например, вместе с пакетом Anaconda. При этом мы не настаиваем на его использовании, и в качестве файла с кодом можно отправлять обычный py-файл, подготовленный в вашей любимой среде.\n",
    "\n",
    "В сданном файле для каждого пункта задания должен быть код, с помощью которого получен ответ. Постарайтесь обозначить части кода, отвечающие на разные вопросы задания — так будет проще проверять вашу работу.\n",
    "\n",
    "### Review criteria\n",
    "\n",
    "Вам необходимо провести описанные в документе final-statement.html (или final-statement.ipynb) два этапа исследования (для двух подходов к решению задачи), написать по результатам каждого этапа небольшой отчет (ниже указаны вопросы, ответы на которые должны содержаться в отчете), и предоставить для ревью данный отчет и код, с помощью которого вы выполнили задание.\n",
    "\n",
    "Не забывайте, что в выборке есть признаки, которые \"заглядывают в будущее\" — они помечены в описании данных как отсутствующие в тестовой выборке. Их прямое использование в модели приведет к переобучению, поэтому не забудьте исключить их из выборки.\n",
    "\n",
    "**<u>Подход 1: градиентный бустинг \"в лоб\"</u>**\n",
    "\n",
    "Один из самых универсальных алгоритмов, изученных в нашем курсе, является градиентный бустинг. Он не очень требователен к данным, восстанавливает нелинейные зависимости, и хорошо работает на многих наборах данных, что и обуславливает его популярность. В данном разделе предлагается попробовать градиентный бустинг для решения нашей задачи.\n",
    "\n",
    "В отчете по данному этапу должны содержаться ответы на следующие вопросы:\n",
    "\n",
    "1.  Какие признаки имеют пропуски среди своих значений (приведите полный список имен этих признаков)? Что могут означать пропуски в этих признаках (ответьте на этот вопрос для двух любых признаков)?\n",
    "2.  Как называется столбец, содержащий целевую переменную?\n",
    "3.  Как долго проводилась кросс-валидация для градиентного бустинга с 30 деревьями? Инструкцию по измерению времени можно найти выше по тексту. Какое качество при этом получилось?\n",
    "4.  Имеет ли смысл использовать больше 30 деревьев в градиентном бустинге? Что можно сделать, чтобы ускорить его обучение при увеличении количества деревьев?\n",
    "\n",
    "**<u>Подход 2: логистическая регрессия</u>**[](http://localhost:8888/notebooks/Dropbox/teaching/ml-coursera/final-assignment/ContestDescription.ipynb#Подход-2:-логистическая-регрессия)\n",
    "\n",
    "Линейные методы работают гораздо быстрее композиций деревьев, поэтому кажется разумным воспользоваться именно ими для ускорение анализа данных. Одним из наиболее распространенных методов для классификации является логистическая регрессия. В данном разделе предлгается применить ее к данным, а также попробовать различные манипуляции с признаками.\n",
    "\n",
    "В отчете по данному этапу должны содержаться ответы на следующие вопросы:\n",
    "\n",
    "1.  Какое качество получилось у логистической регрессии над всеми исходными признаками? Как оно соотносится с качеством градиентного бустинга? Чем можно объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?\n",
    "2.  Как влияет на качество логистической регрессии удаление категориальных признаков (укажите новое значение метрики качества)? Чем можно объяснить это изменение?\n",
    "3.  Сколько различных идентификаторов героев существует в данной игре?\n",
    "4.  Какое получилось качество при добавлении \"мешка слов\" по героям? Улучшилось ли оно по сравнению с предыдущим вариантом? Чем можно это объяснить?\n",
    "5.  Какое минимальное и максимальное значение прогноза на тестовой выборке получилось у лучшего из алгоритмов?\n",
    "\n",
    "Следует понимать, что конкретные показатели метрик качества могут отличаться в зависимости от конкретных разбиений выборки, значений параметров и версий библиотек. Ответы следует проверять на адекватность — в правильную ли сторону изменяется показатель качества при том или ином изменении модели или выборки, корректные ли выводы делаются из соответствующих результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['linalg', 'random', 'power', 'info', 'draw_if_interactive', 'fft']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "from pylab import *\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<u>Подход 1: градиентный бустинг \"в лоб\"</u>**\n",
    "\n",
    "Один из самых универсальных алгоритмов, изученных в нашем курсе, является градиентный бустинг. Он не очень требователен к данным, восстанавливает нелинейные зависимости, и хорошо работает на многих наборах данных, что и обуславливает его популярность. В данном разделе предлагается попробовать градиентный бустинг для решения нашей задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1.Считайте таблицу с признаками из файла `features.csv` с помощью кода, приведенного выше. Удалите признаки, связанные с итогами матча (они помечены в описании данных как отсутствующие в тестовой выборке). **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>lobby_type</th>\n",
       "      <th>r1_hero</th>\n",
       "      <th>r1_level</th>\n",
       "      <th>r1_xp</th>\n",
       "      <th>r1_gold</th>\n",
       "      <th>r1_lh</th>\n",
       "      <th>r1_kills</th>\n",
       "      <th>r1_deaths</th>\n",
       "      <th>r1_items</th>\n",
       "      <th>...</th>\n",
       "      <th>dire_boots_count</th>\n",
       "      <th>dire_ward_observer_count</th>\n",
       "      <th>dire_ward_sentry_count</th>\n",
       "      <th>dire_first_ward_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>radiant_win</th>\n",
       "      <th>tower_status_radiant</th>\n",
       "      <th>tower_status_dire</th>\n",
       "      <th>barracks_status_radiant</th>\n",
       "      <th>barracks_status_dire</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430198770</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2098</td>\n",
       "      <td>1489</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-52</td>\n",
       "      <td>2874</td>\n",
       "      <td>1</td>\n",
       "      <td>1796</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1430220345</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>1188</td>\n",
       "      <td>1033</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>2463</td>\n",
       "      <td>1</td>\n",
       "      <td>1974</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1430227081</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>1319</td>\n",
       "      <td>1270</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1830</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1430263531</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1779</td>\n",
       "      <td>1056</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1459</td>\n",
       "      <td>0</td>\n",
       "      <td>1920</td>\n",
       "      <td>2047</td>\n",
       "      <td>50</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1430282290</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1431</td>\n",
       "      <td>1090</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-16</td>\n",
       "      <td>2449</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1974</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          start_time  lobby_type  r1_hero  r1_level  r1_xp  r1_gold  r1_lh  \\\n",
       "match_id                                                                     \n",
       "0         1430198770           7       11         5   2098     1489     20   \n",
       "1         1430220345           0       42         4   1188     1033      9   \n",
       "2         1430227081           7       33         4   1319     1270     22   \n",
       "3         1430263531           1       29         4   1779     1056     14   \n",
       "4         1430282290           7       13         4   1431     1090      8   \n",
       "\n",
       "          r1_kills  r1_deaths  r1_items          ...           \\\n",
       "match_id                                         ...            \n",
       "0                0          0         7          ...            \n",
       "1                0          1        12          ...            \n",
       "2                0          0        12          ...            \n",
       "3                0          0         5          ...            \n",
       "4                1          0         8          ...            \n",
       "\n",
       "          dire_boots_count  dire_ward_observer_count  dire_ward_sentry_count  \\\n",
       "match_id                                                                       \n",
       "0                        4                         2                       2   \n",
       "1                        4                         3                       1   \n",
       "2                        4                         3                       1   \n",
       "3                        4                         2                       0   \n",
       "4                        3                         3                       0   \n",
       "\n",
       "          dire_first_ward_time  duration  radiant_win  tower_status_radiant  \\\n",
       "match_id                                                                      \n",
       "0                          -52      2874            1                  1796   \n",
       "1                           -5      2463            1                  1974   \n",
       "2                           13      2130            0                     0   \n",
       "3                           27      1459            0                  1920   \n",
       "4                          -16      2449            0                     4   \n",
       "\n",
       "          tower_status_dire  barracks_status_radiant  barracks_status_dire  \n",
       "match_id                                                                    \n",
       "0                         0                       51                     0  \n",
       "1                         0                       63                     1  \n",
       "2                      1830                        0                    63  \n",
       "3                      2047                       50                    63  \n",
       "4                      1974                        3                    63  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zfile = zipfile.ZipFile('features.zip')\n",
    "\n",
    "data = pd.read_csv(zfile.open('features.csv'), index_col='match_id')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97230,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.radiant_win\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97230, 102)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(['radiant_win','duration','tower_status_radiant','tower_status_dire',\n",
    "                                        'barracks_status_radiant','barracks_status_dire'], axis=1)\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.Проверьте выборку на наличие пропусков с помощью функции `count()`, которая для каждого столбца показывает число заполненных значений. Много ли пропусков в данных? Запишите названия признаков, имеющих пропуски, и попробуйте для любых двух из них дать обоснование, почему их значения могут быть пропущены. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_blood_time               77677\n",
       "first_blood_team               77677\n",
       "first_blood_player1            77677\n",
       "first_blood_player2            53243\n",
       "radiant_bottle_time            81539\n",
       "radiant_courier_time           96538\n",
       "radiant_flying_courier_time    69751\n",
       "radiant_first_ward_time        95394\n",
       "dire_bottle_time               81087\n",
       "dire_courier_time              96554\n",
       "dire_flying_courier_time       71132\n",
       "dire_first_ward_time           95404\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.count()[ X.count() != len(X) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.Замените пропуски на нули с помощью функции `fillna()`. На самом деле этот способ является предпочтительным для логистической регрессии, поскольку он позволит пропущенному значению не вносить никакого вклада в предсказание. Для деревьев часто лучшим вариантом оказывается замена пропуска на очень большое или очень маленькое значение — в этом случае при построении разбиения вершины можно будет отправить объекты с пропусками в отдельную ветвь дерева. Также есть и другие подходы — например, замена пропуска на среднее значение признака. Мы не требуем этого в задании, но при желании попробуйте разные подходы к обработке пропусков и сравните их между собой. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any( X.count()!=len(X) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.Какой столбец содержит целевую переменную? Запишите его название. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    97230.000000\n",
       "mean         0.518503\n",
       "std          0.499660\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          1.000000\n",
       "75%          1.000000\n",
       "max          1.000000\n",
       "Name: radiant_win, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['radiant_win'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5.Забудем, что в выборке есть категориальные признаки, и попробуем обучить градиентный бустинг над деревьями на имеющейся матрице \"объекты-признаки\". Зафиксируйте генератор разбиений для кросс-валидации по 5 блокам (`KFold`), не забудьте перемешать при этом выборку (`shuffle=True`), поскольку данные в таблице отсортированы по времени, и без перемешивания можно столкнуться с нежелательными эффектами при оценивании качества. Оцените качество градиентного бустинга (`GradientBoostingClassifier`) с помощью данной кросс-валидации, попробуйте при этом разное количество деревьев (как минимум протестируйте следующие значения для количества деревьев: 10, 20, 30). Долго ли настраивались классификаторы? Достигнут ли оптимум на испытанных значениях параметра `n_estimators`, или же качество, скорее всего, продолжит расти при дальнейшем его увеличении? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kfold = sklearn.cross_validation.KFold(len(X), n_folds=5, shuffle=True)\n",
    "\n",
    "boost_classifier = sklearn.ensemble.GradientBoostingClassifier(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9723, 102), (9723,))"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X10 = np.array(X[::10])\n",
    "y10 = np.array(y[::10])\n",
    "np.shape(X10), np.shape(y10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def calc_scores(X10, y10, n_folds=5, n_estimators=200):\n",
    "    \n",
    "    tic=time.time()\n",
    "    \n",
    "    scores_test = list()\n",
    "    scores_train = list()\n",
    "\n",
    "    kfold2 = sklearn.cross_validation.KFold(len(X10), n_folds=n_folds, shuffle=True)\n",
    "\n",
    "    boost_classifier = sklearn.ensemble.GradientBoostingClassifier(n_estimators=n_estimators, verbose=1)\n",
    "\n",
    "    for i, (train, test) in enumerate(kfold2):\n",
    "        scores_test.append(list())\n",
    "        scores_train.append(list())\n",
    "\n",
    "        boost_classifier.fit(X10[train], y10[train])\n",
    "        probas_test = [* boost_classifier.staged_predict_proba(X10[test]) ]\n",
    "        probas_train = [* boost_classifier.staged_predict_proba(X10[train]) ]\n",
    "\n",
    "        for e in range(boost_classifier.n_estimators):\n",
    "            scores_ = sklearn.metrics.roc_auc_score( y10[test], probas_test[e][:,1] )\n",
    "            scores_test[i].append(scores_)\n",
    "\n",
    "            scores_ = sklearn.metrics.roc_auc_score( y10[train], probas_train[e][:,1] )\n",
    "            scores_train[i].append(scores_)\n",
    "            \n",
    "    mean_scores_test = np.mean(scores_test,axis=0)\n",
    "    std_scores_test = np.std(scores_test,axis=0)\n",
    "    mean_scores_train = np.mean(scores_train,axis=0)\n",
    "    std_scores_train = np.std(scores_train,axis=0)\n",
    "\n",
    "    toc=time.time()\n",
    "    \n",
    "    return [mean_scores_test, std_scores_test], [mean_scores_train, std_scores_train], toc-tic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3786            5.17m\n",
      "         2           1.3731            5.05m\n",
      "         3           1.3681            4.86m\n",
      "         4           1.3634            4.69m\n",
      "         5           1.3592            4.53m\n",
      "         6           1.3543            4.34m\n",
      "         7           1.3499            4.14m\n",
      "         8           1.3455            3.96m\n",
      "         9           1.3415            3.77m\n",
      "        10           1.3377            3.61m\n",
      "        20           1.3080            1.87m\n",
      "        30           1.2876            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3786            5.42m\n",
      "         2           1.3728            5.07m\n",
      "         3           1.3679            4.90m\n",
      "         4           1.3634            4.79m\n",
      "         5           1.3589            4.60m\n",
      "         6           1.3541            4.42m\n",
      "         7           1.3498            4.21m\n",
      "         8           1.3456            4.01m\n",
      "         9           1.3416            3.82m\n",
      "        10           1.3378            3.66m\n",
      "        20           1.3081            1.88m\n",
      "        30           1.2880            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3784            5.47m\n",
      "         2           1.3725            5.30m\n",
      "         3           1.3676            5.12m\n",
      "         4           1.3632            4.97m\n",
      "         5           1.3585            4.84m\n",
      "         6           1.3542            4.67m\n",
      "         7           1.3498            4.45m\n",
      "         8           1.3456            4.28m\n",
      "         9           1.3415            4.09m\n",
      "        10           1.3377            3.91m\n",
      "        20           1.3078            1.95m\n",
      "        30           1.2872            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785            5.35m\n",
      "         2           1.3729            5.14m\n",
      "         3           1.3677            4.98m\n",
      "         4           1.3633            4.77m\n",
      "         5           1.3588            4.60m\n",
      "         6           1.3542            4.40m\n",
      "         7           1.3497            4.34m\n",
      "         8           1.3455            4.13m\n",
      "         9           1.3415            3.91m\n",
      "        10           1.3378            3.72m\n",
      "        20           1.3081            1.83m\n",
      "        30           1.2878            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785            5.16m\n",
      "         2           1.3729            4.95m\n",
      "         3           1.3680            4.77m\n",
      "         4           1.3632            4.60m\n",
      "         5           1.3591            4.43m\n",
      "         6           1.3545            4.25m\n",
      "         7           1.3500            4.07m\n",
      "         8           1.3458            3.89m\n",
      "         9           1.3419            3.70m\n",
      "        10           1.3381            3.53m\n",
      "        20           1.3082            1.78m\n",
      "        30           1.2879            0.00s\n"
     ]
    }
   ],
   "source": [
    "scores_X_test, scores_X_train, time_X = calc_scores(np.array(X), np.array(y), n_folds=5, n_estimators=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 30), (2, 30), '28.387487403551738 m.')"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(scores_X_test), np.shape(scores_X_train), str(time_X/60)+' m.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3772            2.43m\n",
      "         2           1.3693            2.25m\n",
      "         3           1.3624            2.18m\n",
      "         4           1.3548            2.16m\n",
      "         5           1.3479            2.22m\n",
      "         6           1.3414            2.20m\n",
      "         7           1.3351            2.18m\n",
      "         8           1.3296            2.14m\n",
      "         9           1.3238            2.12m\n",
      "        10           1.3188            2.11m\n",
      "        20           1.2722            1.96m\n",
      "        30           1.2380            1.83m\n",
      "        40           1.2093            1.70m\n",
      "        50           1.1840            1.59m\n",
      "        60           1.1630            1.47m\n",
      "        70           1.1441            1.35m\n",
      "        80           1.1267            1.25m\n",
      "        90           1.1118            1.14m\n",
      "       100           1.0970            1.04m\n",
      "       200           0.9828            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3759            2.20m\n",
      "         2           1.3681            2.14m\n",
      "         3           1.3613            2.10m\n",
      "         4           1.3544            2.24m\n",
      "         5           1.3474            2.29m\n",
      "         6           1.3411            2.26m\n",
      "         7           1.3348            2.21m\n",
      "         8           1.3293            2.17m\n",
      "         9           1.3236            2.14m\n",
      "        10           1.3181            2.11m\n",
      "        20           1.2727            1.92m\n",
      "        30           1.2382            1.78m\n",
      "        40           1.2098            1.67m\n",
      "        50           1.1848            1.55m\n",
      "        60           1.1630            1.44m\n",
      "        70           1.1429            1.34m\n",
      "        80           1.1268            1.23m\n",
      "        90           1.1106            1.13m\n",
      "       100           1.0963            1.02m\n",
      "       200           0.9917            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3742            2.16m\n",
      "         2           1.3660            2.12m\n",
      "         3           1.3588            2.14m\n",
      "         4           1.3516            2.21m\n",
      "         5           1.3445            2.17m\n",
      "         6           1.3378            2.12m\n",
      "         7           1.3315            2.10m\n",
      "         8           1.3245            2.09m\n",
      "         9           1.3181            2.07m\n",
      "        10           1.3127            2.05m\n",
      "        20           1.2673            1.89m\n",
      "        30           1.2340            1.79m\n",
      "        40           1.2066            1.67m\n",
      "        50           1.1833            1.56m\n",
      "        60           1.1622            1.46m\n",
      "        70           1.1444            1.35m\n",
      "        80           1.1284            1.25m\n",
      "        90           1.1147            1.15m\n",
      "       100           1.1003            1.04m\n",
      "       200           0.9924            0.00s\n"
     ]
    }
   ],
   "source": [
    "scores_X10_test, scores_X10_train, time_X10 = calc_scores(X10, y10, n_folds=3, n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 200), (2, 200), '6.336785733699799 m.')"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(scores_X10_test), np.shape(scores_X10_train), str(time_X10/60)+' m.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_plot(y, error_y, label='', xlabel='n_estimators', ylabel='roc_auc_score', title=None, *args, **kwargs):\n",
    "    plt.plot(np.arange(len(y))+1, y, label=label, *args, **kwargs)\n",
    "    plt.fill_between(x=np.arange(len(y))+1, y1=y-error_y, y2=y+error_y, alpha=0.25, *args, **kwargs)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    if title: plt.title(title)\n",
    "        \n",
    "    plt.legend(loc=0)\n",
    "\n",
    "    plt.axvline(10,c='k',linestyle=':')\n",
    "    plt.axvline(20,c='k',linestyle=':')\n",
    "    plt.axvline(30,c='k',linestyle=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4YAAAFSCAYAAACuQ8EdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXd4VUXawH9zQwLplYR0Sgi9Q0ABCboiIAgqKOrK5woo\ndth1RREVLLBWFMsqXWwgrl0RXSlSFVzpID2BJLT0kJ7M98fchBtIJTckJO/vec6Te+acmTNz7s15\nzztvGaW1RhAEQRAEQRAEQWi4WGq7A4IgCIIgCIIgCELtIoqhIAiCIAiCIAhCA0cUQ0EQBEEQBEEQ\nhAaOKIaCIAiCIAiCIAgNHFEMBUEQBEEQBEEQGjiiGAqCIAiCIAiCIDRwRDEUBEEQBEEQBEFo4Ihi\nKNRblFKLlFJJSqnNlTi3UCnVsoxj/6eUWmf/HtYMSqnvlVJ31nY/BEEQ6gNKqSNKqavt1FZ7pdSW\nKpz/ilJqoj2uXVsopZoopb5RSqUopZZVcG64VR6X+n6qlHpGKfVBzfTU/iildimlrqrtfghCZRHF\nULArSilXqxC9zabMTSkVo5S66RL2ox9wDRCkte5TiSq6mscrjVWw5Sql0pRS6da/zavR1hLbMq31\nUK11rQlOpVRvpdSPSqlEpdRJpdQypVQzm+NOSql3lVInlFJnlFJfKaUCy2irnVJqi1XBT7S2287m\nuKdSarH1OieUUs9cijEKgiBcJM8CL0Gl5eUrwFSlVCPbRpRSfZRSG6yfn1VK7VBK5Smlnj7/gkqp\n25VSR63y5nOllFeNja50RgFNAW+t9a2VOP9SyuMXlVKxSqlU63fxeDXaWqSUeta2TGvdUWv9S/V7\nevEopfyUUh9ZFfPE8hRrpdQqpdQp67l/KKVuKOO8heVNqAuXL6IYCnZFa30WuBd4Qynlay1+GfhN\na/35JexKc+Co1jq7kuerGuxLaSzVWntord2tf49e4uvXJN7Ae0C4dcsAFtkcnwT0BjoCQUAK8GYZ\nbcUBt2itfQA/4Btgqc3x1wFnIMza5p1Kqf+z20gEQRDshHWCLBr4CionL7XWJ4C9wPkv6NcD31k/\nHwD+CXxbyjU7AO8CdwABQBbwb7sNqnKEA/u11nZT6OzIAqC91toTuBL4q1JqZC33yd58DsQDIYA/\nZrKhLB4BgrXWXpjf5odKqQDbE5RSfYGW2FFBF+oOohgKdkdr/SNGQL2plBqAmS28/2LasnErGWud\nRT2llJpaQZ27gXnAFVZr3DPW8glKqQNWK9WX5VipfJRSX1tnEDcDrc47PttqoUpVSm1XSrW/mLFV\nF6XUdcBU4FbrTPAf1vLV1ntQ5Aa7Xin1mlIqWSl1UCl1hbU81mplG2vTppMyrksxSqkEpdQ7SqnG\nVemX1voHrfV/tNYZVsX8LYzALaI5sFJrfUZrnQssAzqU0Vaa1vqIddcBKKTk9zEMeElrnaO1jsEI\n+bvLuF9Fv6W7rGNPVErdq5Tqaf0ek5RSZSmogiAIKMPj1mfpaaXU0iILXCXk1bXA/6zPPaDS8nIt\nRhG0ZSjwvbWND7TWKzGTcOdzO/C11nqD1joTeAq4SSnlehFjH6CUOqaU+rtVBsYppe6qoM504Glg\njFUe/816D6dZrZgnlPH68CijfnOl1BqrvF2JmSAsOtZYKfWBVaYnK6V+VUo1rcqYtNb7tdZF982C\nkTERVWnD2pcJGOX7Mes4v7KWF7shK+Ph86m1z2lWudPa+ns6af3N/MWmTQ+l1HylVLz1vj+nlKrS\nJLZS6lqMQviYVSYXaK23l3W+1nqn1jrPpqgREGrTngNmIvdBKphQt479Ues405VS85RS/sqEu6Qp\n4wHkWZXxCDWPKIZCTfF3zMzoZ8A/tNanq9leX6A18BfgaaVUm7JO1FovBCYCm6zWuBnWB/NMjNAN\nBGIpaXmy5R0gEzO7Og4bRUMpNQjoB0RYZxhvARKtx6ZYhVOS9a/t56TzrjHcKsx2qouMH7G+CMwE\nllktj93KODUK2Ab4AJ9Yx90To2DdCbyllHKxnvsiRih2tv4Nxgh1lFKh5Y1PKTWmjOsPAHbb7C8A\n+imlAq3XvQPrC05ZKKWSMd/JG8AL5x+2+WzBWCLLI8o6tlsxFsepwNXWercopfpXUF8QhIbLwxjr\nXX+Mx0MyRmbYUpa86gT8WUqbFcnLvUCXoh1lLI/+WuttlehvB6BYEdBaHwZygMhK1C2NZoA7Zuzj\ngbfLe7nXWk/HyKkiL5lFwN+AsRjZ0NLa3ltlNPExsAWjED4P2HqE/B/ggZFTPhi5nwWglHq7FBlV\n9LnEfbPK7nTgGOBivWaV0FrPAz7CTFR6aK1HlHHqMOB9wAsjl1diZFgQ8Bww1+bc94FczD3qhplY\nGG/tc98K5HHRZGwfYD+wxPrO8auqIOZRmXjQLGAzsFprvdXm8N+BNVrrXZW7M9yECeuJxPzffA88\njvk+HTD/T0JdQmstm2w1sgE/YWYw3avRRjhQAATalP2KcS8sr97/Ab/Y7M8H/mWz74p54IZZ9wsx\nD1+Ltby1zbkvFLUFDAT2YdwW1UWOqS1GuCrgCoyLx60X2dYzwJLzylYDd9vchz9tjnW03k8/m7Iz\nQGfr5wyghc2xK4DD1fj+OmMU5yttyjwwCmqh9V7/DnhVoi1njOAfalP2AbAccMMoeweBrAp+S83O\nG/tom/3PgIcvxf+HbLLJdnlswBHgauvnPcBAm2OB1ueYpSJ5hXnpn1nGNcqUlxgF86DN/t3AvFLO\n+wB4+ryy/wL3nFd2HLjqIu7DAOAsYLEpOwlEVVCvhJyy9mmizX5kKffQggkRyAWcbc79qKgtjIK5\nHuhkp++5i7WvrhdZfxHwbDm/nWcw3jJFx4YBaVjfJaxyrMAqIwOAbKCxzfljgFVV7NN71jbvwihi\nt2ImM3wqqOcAXAdMsikLxSiZbtb9QqBlBf83t9nsfwa8bbP/IPC5Pb472ey3icVQqBGUUn/FPOD/\nizXQvpqctPmciXmAVoUgIKZoR5vYjkTMTKMtTTEPxOM2Zbb1VmNmNt8GTiqTRKVKfdFa79Nan9CG\nTRgr2KiqtFFFbO9dlrUPZ84rc7O64LgAvxfNrgIrAF8uAqVUBGZ28CGt9UabQ+8AjTGxiK7AF8AP\nFbWntc7CCLklSqkid6KHMLPfB6ztfEzJ7640Ttl8zuLC+1PV35YgCA2HcOALm2fkHiAP8yJfRFny\nKhljHStBJeSlOyYWu4hiN9JKkIFRNGzxBNIrWf98ErXWhTb71ZbH1s+NKHkPwSjdydZnv+25RXyA\nsbgtVUodV0r9y+rqeFFo42KZjUkQVFOcL2/OaKuWZN1XmPsZBjgCCUWWQEysqB9VIwuTb2GxNm6k\nyzCW0b7lVbKeuxK4Tik1zFo8G6P4luayXBbnj1fkbR1HFEPB7iil/IHXMC4PE4HRygQr1ybxGMEL\nmGxwGIXnfCXiNJCPjU895gFdjNb6La11T6A90AYT9I9S6gl1Lsuo7ZaulEorp2+ai09+Y8/g7zMY\nId9Ba+1j3by0cZktciUtc3yqZGa9cMwM+Ayt9fluOV2ARVrrVG1iGd4EopRSPpXoowNGeQ0G0Fqn\naK3/qrUO1Fp3sh7/rZr3QRAEoSxigSE2z0hvrbWr1jqhEnV3cJ4LZyXlZTus7qDKZCcdgHm+Vobd\nlHRDbYVROPZXsn5NUEIeWz/nUVJpAEgAvJVSzjZlxfJYa52vtX5Oa90BE8c+HOOiilLq3+XIq53l\n9K0RxnvoYrCnPD6GUVJ9bX5nXlrrzmAyr1cgj4t+QztK6VdV+tmIc3H91wAvK5N/oOj3vqmcMBLh\nMkQUQ6EmeAvjHvCLNhnVpgDzlVKOUJwQ5Ui5LZTEHhlDPwH+ppTqrEwylZnAZq31MduTrDOhnwPT\nlVLOyiSWKY5pUCZRSZRVOGdhHtyF1rqz9Lkso7abu9baw6aNG9S5ZAVRmCxgX9ocX61KSTleBieB\n5kpVKSC91HOts5bzgNet1kOUUsHKxFWitT5W3vi01p8U1QF+Bt7UJu7ifLYAY5UJrHcEHgDitNbn\nx2GilPqLUqqrUsqiTHKC14AkTMwNSqmWyiQLsiilhgATMHEaVRq7IAhCJXkPmKmUCgNQSjVVJVP6\nl/eM+QnorpRysikrV15aGYDx3gAT477d1mqjlGqklGqCeadzVCYpS9H73UeYmPa+1gnRZ4H/WL1m\nihKirKraLag2nwCTlUks44YJ11hqY4lUAFrrWGArMEMp5ajMMlTDixpRSkUrpTpax5qBUS6L5PF9\n5cirTtb6Sil1z3ny+AGM5bboGkeUTYK2CjjJxSuVJbD+Fn4EZiul3K19bams8YFa6/UVyOMN1qa+\nwCjXd1rl5CjMxOqG86+plGqjlBqszLqTjZSxZPfHJD8CEzfbxbp1tZYNs15DqCfUuGJo/ZHtU0rt\nV0pNKeOcaGXWS9mllFpdlbpC3UIpNQIzc/dYUZnWegFm2YEiZScUExdQWaoz21XUh58x2dg+t/al\nBcZfv7Q2H8K47iQAC61bER4Y5SkJ4z9/BpNevCqMAQ5arYiLMTEnH9ocr8r9WY4RoolKqaIA8aqu\nAWW7/zgmTm+zUioFI5iqmqRgHOb+TlelW0wf5Zz750lgMHBj0UHrc6DI+uiFeYlIsZ7fAhisz2X1\n6wHsxMRpvADcrrXeV07fKvotFe9bZ2TLs/QKQrUQ+XjZYPuceAOz3MSPSqlUYCMmoVVp55bY11qf\nAlYBI6Fy8lKZ7NntODd5eD0XupHOw3h7jMEk08oE/mptbw/GEvkxcAITq/2ATd1QSlESqsDFWMkW\nYtxAfwEOWftrm4TEts3bMQlUEjEy/H2bY80wcWupGMvoamu7VeFGzsnjJcAbWuu3AazKuQ8mCUtl\nWAB0UMb1s2h5rqreH9vzxwJOGHflJIy8b1ZapTIb0zoZk/Tlnxg5+hhwQ9FErDKW1aLkSQqYjpHL\npzDvQrdoa5IjbTKJn7JuJ619TdRa51RiLKXtl8D6rlDb3mUNnqKA15pp3Mzi7MeYn+MxloIxti9u\nymSz2ggM0lrHKaX8tNZnKlNXuDxRSv0APKK1Li07W4PGam1bprXuV9t9EQSh5hD52DBRSrUDFmut\ne1fy/FcwiWfete7vBm6213etlPofcI1VgRBssCop92ut76jtvgjCpaJRDbcfBRzQZn0xlFJLgRGY\nrI5F3I5xa4iDEkkxKlNXuAzRWg+u7T7UVaz/B6IUCkL9R+RjA0RrvReT1bqy5z9a9NlqwXrfnhMA\nWuvu9mqrvmF1x6yONVUQLjtq2pU0GBNAW8RxLswCGQn4KBNXtUUpdWcV6goNGGUWSbUNvi76/Hht\n900QBKECRD4KVUJrnae1tkeWb7tjdXUuNymZIAh1n5q2GFaGRkB3zALTrpgMR5tqt0vC5YDWemht\n90EQBKEGEfkoXBZorTvWdh8EQag+Na0YxlEy1X+ItcyW45h1XLKBbKXUL5iMR5WpC4BSquYCJQVB\nEIQ6hda6PmSXFfkoCIIg2J3qyMiadiXdAkQopcKVSc88Bvj6vHO+AvoppRyUUi4Y3/u9laxbjNa6\nUltiZiLBrwZzz9f3MvOTn2nRooDrr9f88YemsLBybdSl7Zlnnqn1PsjYZfwydhn/pdrqEZdcPg4d\nqnn00dr/DhvK1pD/T2t7k3sv976hbtWlRhVDrXUB8CAm5f1uzDo1e5VS9yql7rGesw9YiVmEczMw\nV2u9p6y61e2Tj7MPL1z9Akt3f0Jh4K/cO+N3duzQPP887NgBdrinwiVi8eLFtd0FoZaQ71643KkN\n+dimDRw7BllZF9fn6Ojoi6t4GbUlCILQkKnxGEOt9Q9Am/PK3jtv/xXglcrUtQc9gnpwd9e7mbPl\ndZ7s68HD0z14bVobXnoJ/vlP6NIFqrRcuCAIgiBUkUstH3v2hNmzITkZnJ0vosOCIAhCvabGF7iv\ni7Tza8fwNsPpH9af+dvew6PjZv7+dDz//S+88QZs3375WA4b8kxpQ7cayXffcGnI371w8fTuDUeO\nQGzsxdVfs2aN3fpSV9uyJ/J/WnvIva895N5f3tToAveXCqWUruo4MvMy+f7A97y04SUCXAO4qfUd\nnNk0hBef9WTUKLj3XujaVSyHgiAIdQmlFLp+JJ+5JNjKR63B3d1MgN59t8g3QRCE+kZ1ZWSDtBgC\nuDi6EN08mgndJ7Dt5Db+d2YDgVeu4dHHs/n0U1i8GP744/KxHDZEZFaq/tG8eXOUUrLJRvPmzWv7\n51jvUAratYM9eyAjo+r162pcoMgC4XKiucg52eywNa8hGVkX1jGsNfxc/BjYfCAp2SnMXD+TwCsD\naT3Qlb/nRvPqy41wdDTndesmM6uCcCmIiYmxS1Yt4fJHyUO3RujSBQ4cgKQkYz0UBOHSInJOsAc1\nJSMbrCtpEVprfov/jc/3fM7CbQuZMWAGoY168vvXvXj9dcV998GoUUY5tDRY+6ogXBqUUiIwBaDs\n34K1XLTGSnK+fHz3XZg3D+bMgb59a7FjgtBAETkn2IOakpEN2mII5gZ2b9ad5Kxkjqcd560tb/Ho\nlY9y5XBP8vLa8M474ORkXEq7dKHYiigIgiAIlxtRUfDMM3DqVG33RBAEQahriA0McHRwpF9YP0a0\nGYGvsy/Ldy/nZKPf+MvIBCZMMDOr338PK1bAiRO13VuhCIkrEQRBqBqdOkFaGpw5A7m5VatbV+MC\nRRYIgiDYhwZvMSzCzcmNq8KvIi03jZnrZrLp+CauCnfi+psGo7Uns2fDyJGQmgqRkcZ62KRJbfda\nEARBECqPoyO0bGniDM+eNR4xgiAIggASY3gBe07v4YeDP/D8L8/zjyv+QcemnXA/PYhd25owd65Z\nFPiee8DHxywWHBYmiWkEwV5I7IVQhMQY2oci+fjnmT+J9I1EKcXNN4ODA7z2GoSE1HYPBaFhIXJO\nsAc1JSPFlfQ82vq1pXdwb+7vdT+vbX6NuPTjFAZtpnPXAqZMgTZt4Ikn4M8/Yf16WLsW0tNru9eC\nIAgXEh8fj4+PDxs3biwuO3bsGD4+PmzZsqXcugMHDmThwoXV7sPatWsJDQ2tdjtC9TiedpzcAuM7\n2qkTxMVBSkotd0oQBKEaVEbGLV++nL59++Lq6srVV199QRvbtm2jZ8+euLq60qtXL7Zv317hdWfM\nmMHYsWPtMgaLxcLhw4ft0pY9EMXwPCzKQs+gnlwRcgUj24zk9V9f51jaEVxa/kGHTgUMGQKPPQaz\nZ8M338DJk/Ddd0ZRLCio7d43LCSuRKhv2HsWOSgoiJdeeolx48aRaw0omzhxIuPGjaNXr152vVZZ\naK1l6Yk6QG5BLjkFOQB07QoJCZCYWLU26mpcoMgCQbg8qA0Z5+vry+TJk3niiScuqJ+Xl8fIkSMZ\nO3YsKSkpjB07lhEjRpCfn2/XfpZHXZOPohiWQuNGjekX1o9rW15LqEcoH+78kINJ+znp+iMdeyYT\nGgpvvAGxsTB9ugng//13+PFHszaUIAj1lxdffJGQkBA8PDxo164dq1evprCwkJkzZxIREYGnpye9\nevUiLi4OgI0bNxIVFYW3tze9e/dm06ZNxW0NHDiQadOm0a9fP1xdXTly5AhpaWmMGzeOoKAgQkND\neeqpp4qF6aFDh4iOjsbLywt/f39uu+22Cvs7fvx4goKCmD59OkuWLGH//v0899xz5daZNm0a69at\n48EHH8TDw4OHH34YgH379jFo0CB8fX1p164dy5cvL67z/fff06FDBzw8PAgNDeW1114jMzOToUOH\nEh8fj7u7Ox4eHpyQDF61Qn5hfrHFsFs3oxieOVPLnRIEoc5R32Tc1VdfzahRowgMDLyg7po1aygo\nKODhhx/G0dGRhx56CK01q1atKvN6K1euZObMmSxbtgx3d3e6desGQFpaWnFfKjuuAQMGoLWmc+fO\neHh4lJCptYbW+rLfzDDsT2xKrF74v4U6ck6kvuHjG/SyXcv0R9s/0r/s26GXLc/Tn32m9QMPaO3p\nqfW0aVp/9ZXWH36o9bZtWufk1EiXBKFeU5n/ZbN4TPW3i+HPP//UoaGh+sSJE1prrWNiYvThw4f1\nSy+9pDt37qwPHDigtdZ6x44dOikpSSclJWlvb2/90Ucf6YKCAv3JJ59ob29vnZSUpLXWOjo6WoeH\nh+u9e/fqgoICnZeXp0eOHKnvu+8+nZWVpU+fPq179+6t586dq7XW+rbbbtMzZ87UWmudk5OjN2zY\nUKl+Hzp0SHt6emofHx+9Zs2aStWJjo7WCxYsKN4/e/asDg0N1e+//74uLCzU27Zt035+fnrv3r1a\na60DAwOL+5OSkqL/+OMPrbXWa9as0aGhoZW6pi1l/Ras5bUudy6XDdCbj23Wz699XselxWmttc7N\n1drXV+vZs0VWCcKlpiI5JzKuZmTc/Pnz9cCBA0uUzZ49Ww8dOrRE2fDhw/Vrr71W7vWmT5+u77zz\nzhJlFzsupZQ+fPhwpcZpS03JSLEYlkOoZyjdA7vz6JWPkpWfxeSVkzmVeYq43N1YIldS0PgM/fvD\nSy/B++/Dv/8Nnp6wd69Z2uLYMcjLq+1RCEL9wl5i82JwcHAgNzeXXbt2kZ+fT1hYGC1atGDBggW8\n8MILREREANCpUye8vb357rvviIyM5Pbbb8disTBmzBjatm3LN998U9zmXXfdRdu2bbFYLCQlJbFi\nxQpmz55NkyZN8PPzY9KkSSxduhQAR0dHYmJiiIuLw8nJiSuvvLJS/Q4PDycoKAgPDw/69+9/UWP/\n9ttvadGiBWPHjkUpRZcuXbj55puLZzidnJzYvXs36enpeHp60rVr14u6jmB/Nh3fxPrY9WTnZQMm\nM2nz5nD0qMlMKghC3UFk3KWTcRkZGXh6epYo8/DwIL2KyUNOnTpVrXHpi/3CagBRDCugo39HWvu0\n5p7u93Bfz/t4/pfn+c++/6AaZZMV/APZXttwcs7jnXfM+fffDxkZJgX4hg3wxRewZYtx2SksrN2x\n1DckrkS41LRq1YrXX3+d6dOn4+/vz+23305CQgLHjh2jZcuWF5wfHx9PeHh4ibLw8PBiFxygRGKW\nmJgY8vLyCAwMxMfHB29vbyZOnMjp06cBePnllyksLCQqKopOnTqxaNGiSvV71qxZ+Pn54e/vz8sv\nv3wxQycmJobNmzfj4+NT3LePP/6YkydPAvCf//yH7777jvDwcAYOHMjmzZsv6jqC/QlyDyIpO4nM\n/MzisrZt4ciRqimGdTUuUGSBINiHhibj3NzcSEtLK1GWmpqKu7t7pduAmhtXbSCKYQU4WBzoHdIb\nZydnWvu0Zt7weSRlJjF55WTS8pJxDNxHesD3xJw5waRJcOed8OijxmLo7w++viYW8aef4OuvYc8e\ns7iwIAiXJ2PGjGHdunXExsYCMGXKFMLCwjh06NAF5wYFBXH06NESZbGxsQQHBxfv2waeh4aG0qRJ\nExITE0lKSiI5OZmUlBR27NgBgL+/P3PnziUuLo53332X+++/v8JsZnv27OHVV19lwYIFzJ8/n5kz\nZ5ba1/M5PyA+NDSU6OhokpKSivuWlpbGW2+9BUCPHj348ssvOX36NCNGjOCWW24ptR3h0hPsHkxy\nVjJnc89pgZ07w/HjkplUEISSNBQZB9ChQ4fiaxexY8cOOnToUG690uSjvcdVW4hiWAmcHZ0Z1HIQ\nrX1bk5mXyaNXPsq4buN4ZvUzfL3/S0LDNPnhP7M1fgs9e+fw9tuwejWMH2+WtPD2hsBAcHGBnTvh\n229NopojRyA7u7ZHd/myZs2a2u6C0MDYv38/q1evJjc3FycnJ5ydnXFwcGD8+PFMmzaNgwcPArBz\n506Sk5MZOnQoBw4cYOnSpRQUFLBs2TL27t3L8OHDS22/WbNmDBo0iMmTJ5Oeno7WmsOHD/PLL78A\n8NlnnxXPxHp5eWGxWLBYyn6Ma60ZP348U6ZMoXXr1nTq1IlHHnmECRMmVDjWgICAEoJr2LBh7N+/\nnw8//JD8/Hzy8vLYunUr+/btIy8vj48//pi0tDQcHBxwd3fHwcGhuJ3ExMQLZmWFS0eQexDJ2clk\n5GYUl3XvDidOVC0zqT2fuXW1LUFoyNRHGVdYWEhOTg55eXkUFBSQk5NTnHU0OjoaBwcH3nzzTXJz\nc5kzZw4Wi6XUZS1sCQgI4OjRo8UuoNUZV7NmzeqWklidAMW6slFDyWdKIyEtQX++53O9bNcy/Z/d\n/9FXLbpKh88O12//9rZesHmpnrL4P3rux3F61SqtZ83SOjJS64gIrZ9/XutVq7Revdps336r9ccf\na/3JJ1qvW6d1QoLW+fmXbBiCUCe5lP/LF8OOHTt0VFSU9vDw0L6+vnr48OE6ISFBFxQU6BdeeEG3\naNFCe3h46KioKB0XZxJ9bNiwQffo0UN7eXnpnj176o0bNxa3N3DgwBIJXrTWOi0tTd933306JCRE\ne3l56e7du+tly5ZprbV+7LHHdHBwsHZ3d9cRERF6/vz55fZ39uzZumvXrjrf5uGSk5Oj27dvX2Hd\nTZs26cjISO3j46MfeeQRrbXW+/fv19dff71u2rSp9vPz09dcc43evn27zs3N1YMHD9Y+Pj7a09NT\nR0VFlQiuHzdunPb19dXe3t46ISGhEne65gLrG9oG6Oy8bO0ww0F/sfeL4vt4+rTWjo5aW39agiBc\nIuqynKuPMm7x4sVaKaUtFkvx9re//a34/G3btukePXpoFxcX3aNHD719+/YK71NiYqLu16+f9vb2\n1j169NBaa52amnpR43rvvfd0YGCg9vb21suXL6/w2kXUlIxUpo3LG6WUvpTjyMnP4Y+EPziYfBA/\nZz82Ht/IW7+9xdDWQxkZcQu/70qnSXYreod1obGDMxs2wKJFJuD/b3+DqCgoskIXFhrX0qwsE5fY\nrRu0aHHuuFA20dHRMlNcz1BKUR+eSUL1Keu3YC2XJ2QlKZKPHrM8ePnal7mnxz0opSgshNBQeOgh\nmDwZGjeuuC17PnPraluCUNOInBPsQU3JSHElvQgaN2pM75DeXBV+Fem56XQJ6ML8G+ZzNOUoj62e\nRFhEBo4a+JTXAAAgAElEQVQ+x/j+4DccSvmTK/rmM28e3HabyVz60ENm3UOtwWIBLy/jauruDhs3\nGvfTrKzaHqUgCIJQX/Bz8eP02dPkFxoXKosFWrWCw4chM7OCyoIgCEKDQCyG1SQzL5Mt8Vs4nnqc\npi5NWRu7ln9v+TfDIocxsOmtbN+XhqNypmdQD5o2CUYXWlizxixv4e1tLIi2Wd21NhlMLRa44goI\nCqqVYQlCrSAzqVVn/fr1DBkypEQwvNYapVSFcX3u7u6l1luxYgV9+/atsT5XBrEY2oci+dhnfh/6\nhPTh+aufx83JDYCJE02s+4IFEBJSyx0VhAaCyLmqUR0ZVx2GDh3KunXriq9bdM2pU6fy+OOP19h1\nK0tNyUhRDO2A1prDyYfZEr+FJo2akF+Yz5xf53Ag6QB/6zwBv6w+HIxLJsjLj46+3fFyakpBAfz8\ns1EQAwKMgtip07k2s7IgKQkiI6FLF+NmKgj1HRGYQhGiGNqHIvl449IbcXVyZc6QOfg4+wDw3nvw\n5pvwyScl5Y8gCDWHyDnBHograR1GKUUrn1YMbT0UF0cXcgtyeWbAM0zpO4XP9i1l4fHHCIlIJTMn\nl5+P/sj25PVk6zQGDTKK4V/+AjNnwj//abKWAjg7G/fSw4fhhx+qljmuoSBrVwmCIFSOYA+zZEVu\nQW5xWbduVctMWlfXHhRZIAiCYB9EMbQjHo09uKbFNXRt1pUTGSdo6d2Sd4e9y7DIYcze9gyb9Os0\nC7Bw+OQp1sZ/x4H0Pyi0ZDN0KCxZAgMGwL/+BZMmmRhEpYw10WIxyuHOnVBQUNujFARBEC43Qj1C\nSclOISc/p7isY0fIyACbtagFQRCEBoy4ktYQSVlJbInbwpnMM/i6+KK15tPdn/L5vs/5S+gw2hbc\nSkZ2Nh4eEOnRhSDnVjioRsUuph99BG5u8Ne/Qp8+JnvpqVPg62v2PTxqe4SCYH/ExUYoQlxJ7UOR\nfPxox0f8a/2/WDZ6Ge2bti8+HhEBt98OTz5ZucykgiBUD5Fzgj0QV9LLDB9nH65tdS39wvqRmZdJ\nak4qd3S+g/nD55Opk3g34W8kuWwmJ9WD7af/x8bEbzmVfQxlKWTQIFi4EEaPhvnz4d57YcMGYz3M\nzITvv4eDB02iGkEQBEGoiDDPMFJzUksscg8mjv3IETh7tpY6JgiCINQZRDGsQSzKQrhXOMMih9HJ\nvxOnM0+jUDzW9zH+9Zd/sevsapadvY/EvGNkJDdmW/IvbEtZw9n8NBwcIDoa5s2D//s/+PhjuPtu\n2LrVLG+xeTP88kvDTjMucSWCIAiVI9wrnJTsFM7mltQAO3eG2NjKKYZ1NS5QZIEgCIJ9EMXwEuDk\n4EQH/w7cEHkDIR4hxKXHEeAWwGuDXuOenuP5Ke1Nvs96hsTUXOLOpLIm/juOZuyhQOdjsUDfvmb9\nwwcegK+/hvHjTbxhQgJ89x0cPSrWQ0EQ6h6zZs3innvuqe1uCECwezCZeZkkZyWXKO/atWoJaARB\nEITqs379etq1a1fb3bgAUQwvIa5OrvQJ7cOQiCE4N3ImPj2e7oHdWTRiIdGte7Ms5e9sKZxLo0aa\n3+O2s/LgSo6cPENurklE06sXzJkDjz5q4hAnTTpnOVy1ClJTa3uEl5Y1a9bUdhcEoU4THx+Pj48P\nGzduLC47duwYPj4+bNmypdy6AwcOZOHChdW6/hNPPMHcuXOr1YZgHxwsDng38SYuPY5CXVhc3qMH\nxMfDsWMVt2HPZ25dbUsQhMuHysi45cuX07dvX1xdXbn66qsvaGPbtm307NkTV1dXevXqxfbt2yu8\n7owZMxg7dmy1+t6vXz/27t1brTZqAlEMawFfF1+uaXkNV4VfRXZ+NmcyzzCizQg+vOkDwpv68U7s\nfSR4fUnztqkkuKxkZ+LvHIvPISHBKH+dOsErr8BTT8GKFSaT6R9/mNjDnTshL6+2RygIwsVg74QE\nQUFBvPTSS4wbN47cXLNMwcSJExk3bhy9evWqVtsFkiL5ssPP1Y+TZ0+SnZ9dXNaypZl4jI1t2KEJ\ngiDUPLUh43x9fZk8eTJPPPHEBfXz8vIYOXIkY8eOJSUlhbFjxzJixAjy8/Or3bfLNcGQKIa1hEVZ\nCPUMZVjkMLo060JiZiJZeVn8rdvfWHjDQvIKs5m64X4O69X4tduNQ9vvaNH5OL6+msRE4/rj5wcv\nvQQ33ACzZsGHH8LGjUZBPHGitkdY80hciVAbvPjii4SEhODh4UG7du1YvXo1hYWFzJw5k4iICDw9\nPenVqxdx1jUANm7cSFRUFN7e3vTu3ZtNmzYVtzVw4ECmTZtGv379cHV15ciRI6SlpTFu3DiCgoII\nDQ3lqaeeKhYwhw4dIjo6Gi8vL/z9/bntttsq7O/48eMJCgpi+vTpLFmyhP379/Pcc8+VW2fatGms\nW7eOBx98EA8PDx5++GEALBYL77zzDpGRkURGRgIwadIkwsLCise9fv364nZmzJjBnXfeCUBMTAwW\ni4UlS5YQHh6Ov78/M2fOrMKdF6pLM7dmnDp7isy8cxqgg4NZz3Dr1ordSetqXKDIAkGwH/VNxl19\n9dWMGjWKwMDAC+quWbOGgoICHn74YRwdHXnooYfQWrNq1aoyr7dy5UpmzpzJsmXLcHd3p1u3bmWO\ndfHixbRv3x4PDw8iIiJKeNCsXbuW0NDQ4v0WLVrw6quv0qVLF7y9vbntttuKld1LSaNLfkWhBI4O\njrRv2p5wz3B2n97NoaRDWJSFB6MeZFT7USz4YwFf7fuKMR3HkBeUTsvQlgzu0Z38LFdOn4ZDh4wF\n8b33YOlSePxxuO02SEuD1q1NYgEXl9oepSDYDzXDPisV6GeqPpu3f/9+3n77bX7//XcCAgKIjY2l\noKCAV199lWXLlvHDDz8QERHBzp07cXFxITk5mWHDhvHWW28xZswYPv30U66//noOHTqEt7c3AB9+\n+CE//PADkZGRFBYWMnr0aAIDAzl8+DAZGRkMGzaMsLAwJkyYwFNPPcV1113HmjVryM3NZevWrZXq\n97x58+jevTsODg58/vnnNGnSpNzzn3/+eTZs2MCdd97J3XffXeLYV199xZYtW4rbiIqKYvr06Xh4\nePDGG28wevRoYmJicHJyAkzqbFs2bNjAgQMH2LdvH1FRUdx88820adOmUuMQqkeIewinz54mKy+r\nRPngwUZ+xMeDzXuKIAi1gMi4mpdxRezevZvOnTuXKOvSpQu7d+9m0KBBpda57rrrmDp1KocOHWLJ\nkiUljp0/1oCAAL7//nuaN2/OunXrGDx4MFFRUXTt2hW4UD4uX76cH3/8kcaNG3PllVeyePHiSx6n\nL4phHcHVyZWo4Cg6NO3A4ZTD7Du9j0YOjZjSdwoxqTHM/X0uX/75Jbd2uJW4tDh6BvWkdWRLWre2\ncOwY/O9/MGoUXHcdvP02/PQTjB1r3IN69IAWLcBSz+zDElfSMLkYYWcvHBwcyM3NZdeuXfj6+hIW\nFgbAggULeOWVV4iIiACgU6dOgBESkZGR3H777QCMGTOGOXPm8M033xTHJ9x11120bdsWgDNnzrBi\nxQpSU1Np3LgxTZo0YdKkScybN48JEybg6OhITEwMcXFxBAcHc+WVV1aq3+Hh4QQFBZGVlUX//v2r\ndQ+mTp2Kp6dn8X7R2AAmT57Mc889x59//ll8D2xRSjF9+nScnJzo3LkzXbp0Yfv27aIYXiLa+LVh\nxYEVpGSnEOp5TgMcPhyefRb27zex7GXJiroaFyiyQKhPiIy7dDIuIyOjhDwD8PDwID09vdJt2GI7\nVovFwpAhQ4qP9e/fn0GDBrFu3bpixfB8HnnkEQICAgAYPnw427Ztu6h+VId6pipc/rg6udLJvxMj\n246kT3Af8gvz8WjswdNXPc1DUQ/x9Z9f88zaZ1i0bRH/PfRf0nJTCA+HYcOMddDdHaZOhTFj4M03\nYe5cE4f488+QklLboxOEy5tWrVrx+uuvM336dPz9/bn99ttJSEjg2LFjtGzZ8oLz4+PjCQ8PL1EW\nHh5e7IIDlHAliYmJIS8vj8DAQHx8fPD29mbixImcPn0agJdffpnCwkKioqLo1KkTixYtqlS/Z82a\nhZ+fH/7+/rz88ssXM/RiQkJCSuy/8sortG/fHm9vb7y9vUlLS+PMmTNl1i8SegAuLi5kZGSUea5g\nX9o1bcfpzNMkZ5fMTBoebtYz3LrVeJsIgtAwaWgyzs3NjbTzHnqpqam4u7tXug1bQs9zuVixYgVX\nXHEFvr6+eHt7s2LFijovH0UxrKM4OjjSwrsF10dezzUtrsHL2YsQ9xCeG/gco9uNZvG2xUz5eQrv\nbX2PPaf3YHEooH17M/MbHg5t25oMpgEB8OSTZh3Er7+G7duhFlyWawSJKxFqgzFjxrBu3TpiY2MB\nmDJlCmFhYRw6dOiCc4OCgjh69GiJstjYWIKDg4v3bV1JQkNDadKkCYmJiSQlJZGcnExKSgo7duwA\nwN/fn7lz5xIXF8e7777L/fffz+HDh8vt7549e3j11VdZsGAB8+fPZ+bMmaX29XzOd3EprXz9+vW8\n/PLLfPbZZyQnJ5OcnIyHh8dlG3Rf3+nYtCMnMk5coBi6u8PAgbBpE1jfz0qlrsYFiiwQBPvRUGQc\nQIcOHYqvXcSOHTvo0KFDufUqIx9zc3MZNWoUjz32GKdPnyY5OZkhQ4bUefkoimEdx6IsBLgFEN08\nmusjr6eVdys6BnTkpWtf4sqQK5m1fhYz1s7gx4M/kpaThqsr9O4NQ4ZA06YwdKjJYLpnj8li+umn\nZu3D48dl7UNBqCr79+9n9erV5Obm4uTkhLOzMw4ODowfP55p06Zx8OBBAHbu3ElycjJDhw7lwIED\nLF26lIKCApYtW8bevXsZPnx4qe03a9aMQYMGMXnyZNLT09Fac/jwYX755RcAPvvss+KZWC8vLywW\nC5ZyfMS11owfP54pU6bQunVrOnXqxCOPPMKECRMqHGtAQECFAjk9PR1HR0d8fX3Jzc3l2WefLdcF\np64LxPpOmGcYBbqAE+knyC8smXXvjjtg926zydckCA2T+ijjCgsLycnJIS8vj4KCAnJycoqzjkZH\nR+Pg4MCbb75Jbm4uc+bMwWKxlLqshS0BAQEcPXq0XJmWm5tLbm4ufn5+WCwWVqxYwY8//lhuu3UB\nUQwvIzybeNIzuCcj2oygR1APrml5Dc9GP8uBxAM8vPJh5v4+l4OJBynUhfj4wNVXQ3Q0+PvDI4/A\nuHGwaJHJZPrJJ2b9w8vZbUjiSoRLTU5ODo8//jhNmzYlKCiI06dPM2vWLCZPnsytt97KoEGD8PT0\nZPz48WRlZeHj48O3337LK6+8gp+fH6+88grfffddcVB+abOOS5YsITc3l/bt2+Pj48Po0aM5YU0z\nvGXLFnr37o2HhwcjR45kzpw5NG/evMz+vvHGG2RlZfHPf/6zuGzatGmcPHmSBQsWlDvWRx55hOXL\nl+Pr68ukSZNK7e91113HddddR2RkJC1atMDFxeUCVxpbzq9f1qyrUDM0adSEYPdg4tLiSmQmBZPE\nLDTUZLYuK+ygrsYFiiwQBPtQH2XcBx98gLOzMw888ADr16/HxcWlOKGLo6MjX375Je+//z7e3t4s\nWbKEr776ikaNyk/BMnr0aLTW+Pr60rNnz1LH6ubmxpw5cxg9ejQ+Pj4sXbqUESNGlNlmXZGHqj7M\n4CqldH0YR1XJL8wnJiWGLXFbWH10Nct2L2NIxBDGdxtPn9A+uDq5mvPy4fBh2LbNuJGuWwfLlsGV\nV8KIEeZv27bg6FjLAxIaPEopsSoJQNm/BWt53ZCglwHny8fBHw7G39Wfl659iWZuzUqc++CDsGMH\nvPGGWcJCEAT7I3JOsAc1JSNr3GKolBqslNqnlNqvlJpSxjnRSqk/lFK7lFKrbcqPKqW2W4/9VtN9\nvdxoZGlEK59WDG8znNs7387TA55m75m93P/9/cz7fR4xKTForWnUyCQWuOEGaN/eWBFfew0aN4Yp\nU+DFF+Hzzy8/91KJKxEE4XKmNuRjW7+2HE87ztncsxcc++tfjWK4f7+ZUDyfuhoXKLJAEATBPtTo\nchVKKQvwFnANEA9sUUp9pbXeZ3OOJ/A2MEhrHaeU8rNpohCI1lqXjJQXSuDq5MpVYVcR7hlOkHsQ\n/z30X55Z+wxbE7ZyT/d76BXcC2dHZ5o0ge7dzfqGe/ZAkybG3XTpUuNqOno03HSTWd7Cw6O2RyUI\nQmVYv349Q4YMKeGGorVGKXVBtrXzcXd3L7XeihUr6Nu3b431Wag9+dixaUd+PPTjBQloALp2BS8v\nIx/69oXzEtAKgiBccqoj46rD0KFDWbduXfF1i645depUHn/88Rq7bm1To66kSqk+wDNa6yHW/ccB\nrbV+0eac+4BArfXTpdQ/AvTUWidWcJ0G6UpaGpl5mfwe/ztb4rawaNsi8gvzeSDqAW5seyPBHsEl\nzk1NhV27ICYGDh6EDz4w61fdfrtREMW9VLjUiIuNUER9dyWtLfn4W9xvDPloCMtGLeMvLf9ywflj\nx0JiIvz973DNNRc7OkEQykLknGAPakpG1vQC98HAMZv940DUeedEAo5WFxk3YI7W+gPrMQ38pJQq\nAOZqrefVcH8ve1wcXegX1o9wr3BCPENYcWAFT656ki1xW7iv1310a9aNxo0aA+DpaWaF27WDnTuh\nRQv4/Xd4+2344QfzgjB8OAQHQx2JiRUEQagv1Ip8bO/XnvScdE5mnCz1+KhRJlFZfLxJTibeI4Ig\nCA2HmlYMK0MjoDtwNeAKbFJKbdJaHwT6aq0TlFJNMQJwr9Z6fWmNTJ8+vfhzdHR0g445UEoR5hlG\nU5emhHiE0KFpBxZuW8iWr7bwSO9HGNFmBM3czyUd8PGBAQPgzBmjBHbuDKtWmfjDb7+FiRNNghof\nn7qlIEZHR0s2OkGo56xZs6Yh/5/bXT4OGDCAQPdAjiQfIb8wn0aWkq8B/fqZtXC//tq4lnbqdO6Y\nPZ+5dbUtQRCEywl7y8iaVgzjgDCb/RBrmS3HgTNa62wgWyn1C9AFOKi1TgDQWp9WSn2BmU2tUPAJ\nBmdHZ64IuYJwz3DCvML4dv+3PPbTY6w+upoHoh6gV1AvmjRqUny+n59Z5Pj0aZO2/Ior4JtvzPpW\n0dEmBrFfP6M8OjnV3riE+kt4eHidSdks1C7h4eHAhRN9M2bMqKUe2Z1ak48tYlpwLO0Y2fnZuDm5\nlTjm5QX33AOPPQZ9+hiPkgoytwuCUAVEzgn2oKZkZE3HGDoAf2KC6xOA34DbtNZ7bc5pC7wJDAYa\nA78CtwJHAYvWOkMp5Qr8CMzQWl+wOqTEGFZMdn42205sY0PsBj7d8ymxqbHc1eUu7u1xL+FeFz6k\ntIYTJ8wSF3v3wurVsGYN9OwJw4YZRbFlS/MSIc83QRAuFfUoxrDW5ONdX95FanYq826Yh5+L3/lV\n+PVXWLjQhBS88op57oeHmxh0QRAEoe5Sp2MMtdYFSqkHMULLAizQWu9VSt1rDuu5Wut9SqmVwA6g\nKFZij1KqBfCFUkpb+/lRaUJPqBxNGjWhT0gfwjzCiPCNYGPsRj7Y8QHfH/yef/T5Bze2uxH3xu7F\n5ysFgYEQEGBcS9u0MQrh+vXwwgvw8ccwdKhxMe3QwZwriWoEQRAqR23KxwifCFYeXEl2fnapxzt0\ngNtugyNH4KmnYPJk8/wPDi71dEEQBKGeIAvcN0DyC/OJSYlha8JWvv3zW7768yv6h/dn+oDpdA/s\njoPF4YI6hYUmGcG2bSYW8X//gy+/NEteDBlyzuWoRQuT1OZSIHElDRf57hsu9cVieKkoTT5+svMT\nXlj3Ap/d8hlt/dqWWk9rOHwYJkyAs2dh1ix49tm6GRcozwNBEARDnbYYCnWTRpZGtPJpRahnKJ38\nO3FV+FV8vPNjrv3gWu7qehdP9n+Spq5NS9SxWMyaVkFBEBcHvr7QqxccOABffAGffmosiH37mvjE\ntm3B3x8aN66lQQqCIAilEuETQXJ2Mmk5Za8BppQJF3jsMRNnvnlz6YveC4IgCPUHsRgKZOVlsT9x\nP9/u/5bF2xZToAt46qqnuKPzHTg5lJ5lprDQKIh//AEZGSYe8csvzbIX110HV10F3t7QrBk0b26U\nRFfXSzsuQRDqH2IxrBqlyceU7BSavdKMr8d8zaCIQeXWT02FBx4wa90uWGDcTAVBEIS6SXVlpCiG\nQjEZuRnsPrWbxdsXs3TXUroEdOHVQa/SPbB7mRm0Cgrg+HHYvt0oiFlZJs35qlUQEWEsiF27GqXQ\n09PMQAcESNIaQRAuDlEMq0ZZ8tFtphtvDH6Dcd3HVdjGxo0weLBxJ504ERwujDYQBEEQ6gDVlZGS\nY0woxs3Jjd4hvZl1zSw+ufkTXB1dGbB4APd+ey9xaednUTc4OJhsdddfbxLR+PnBrbfCRx/BjTfC\nrl0waRK8+abJavrrrybT3RdfmHjFU6cu3j2pIa9V2dCR714Qqkczt2YkpCeQX1jxA7hHDxg0CKZO\njebQIftc357/w/I8EARBsA8SYyhcgFcTLwZHDKZnUE++P/A9b/32Fu3ebseYjmN4sv+ThHuFX1DH\nwcG4jIaGwrFjxoIYEWEWR27UCDZtMlbEd96BqCjjapqTY5bCsFggLMxsfn4SlygIglDTBHsEcyLj\nBDn5OTRyKv9VoHFjePppEy7w4YcwZYqEBgiCINRHxJVUKBetNScyTvDN/m9Y+MdCdp/azU3tbmJq\n/6lE+kaW6WJaWGiylx48CLGxJsOdlxfk5sLatUZJPHzYuJoOHAitWpljSpl4xBYtJC5REIQLEVfS\nqlGWfBz7xViy8rJ4d9i7+Lr4VthOYSE8/zy89RYsXWqe2xIOIAiCULeQGENEMbwUFOpCEtITWHFg\nBYu2LWL7ye0MixzG1H5T6RjQEYsq2ys5O9ssdbF3r0lk4ORkEtMkJcHq1WY7edIsoty9u8lo2qTJ\nOWWyRQuTxMbTU15EBKGhI4ph1ShLPj69+mnWx67ngxs/INijcgsUpqaa7NMAb78NXbrIM1kQBKEu\nIYohohheSgp1IfFp8aw8tJIlO5bwe/zvXNvyWqb2n0q3wG40spTtkqQ1JCebRZMPHTKJa9zdwc3N\nKI5bt5r1EbdtM+Xdu0PHjsZF1c0NnJ1N8pqgIKNYXnONrF3VUJF1yxouohhWjbLk46I/FvHGr2/w\n6ahPifSLrFRb0dHRzJ69hrFjzfN47lyTXOxikHUMBUEQ7I+sYyhcUizKQohnCHd1vYtrW17LT0d+\n4pOdnzDw/YFEN49mSt8p9A7pXeoyF0qBj4/ZOnc2S1zs22eUwkaNTNa7G24wLkuHDxsl8eefTQKb\nwEAzOx0ZCa1bG0UxLc1kRPXwMPsWSaUkCIJQKVp6tyQlO4XUnNQq1evSxSQTmzwZnnwSPvnEPIMF\nQRCEyx+xGArVoqCwgGNpx1h9eDXL9ixjfex6rgy9kr9f8Xf6hfXDzcmtwjbS0iAmxiiDWVmmTClw\ncTGb1sYN9Y8/jLL4558mJrFdO5PsJjzcuJo2bWr++viYFxVnZ3FzEoT6hlgMq0ZZ8jE+PZ42b7Xh\ny1u/5JqW11SpzcJC+O9/TebpL74wGUsFQRCE2kdcSRHFsC6QX5hPbGosa4+u5fO9n7M2Zi2hHqEM\nixzG3d3upqV3SxwdHCtsJzvbKIopKcaiWLSchdbGqliUjGbPHtixwyS3OXgQzp49lxU1LMwoiy1b\nms/NmplYRXd3E98oCMLliyiGVaMs+ai1pskLTVhwwwL+2vmvF9X2sGHmufzBB+b5KgiCINQuohgi\nimFdIq8gj5iUGLbGb2XT8U2sjVnLgaQD9Anpwx2d7mBEmxH4OPuUmc30fLQ2Sl96uslyevIkJCaa\n8hkzonn++TU0bmwymh49apTEQ4fM37g4k9m0aCmM8HCzfEbr1sa66O4uyuLlisQUNVxEMawa5cnH\n0NmhPBT1EP+44h84WCpetf78/7utW0120q++ggEDqrbwvcQYCoIg2B+JMRTqFI4OjkT4RtDcuzkD\nmg/g5vY3s+vkLn6J/YVpq6YxbdU0rm11LRO6TaBHUA+cHZ3LbU8pEz/o5mbiDDt1MklrMjLg9dfN\nWolJSUYxDAw0iWn69zez2BaLsTjGxBhl8YcfTKp1JydjXWzRwvzt0MFkQvX3Ny6o7u4mK6ogCEJ9\nJtg9mISMBHIKcnCxuFS5fs+eZsmhSZNgxgyzPq1vxStfCIIgCHUUsRgKNU5mXiZxaXHsO7OP/yX8\njzVH1/Bb/G9E+kRyU7ubGNtlLCEeIZWasS6P3FxjXczMNGnVk5JMFtSzZ8+do7WxPh47ZrKjHjhg\nYhahpLLYti20bw8BAWaZDGdnszlW7A0rCEINIhbDqlGefLxl+S04WBx4e+jb+Dj7XFT7x4/Drbca\n9/9HHjGWw8hIie8WBEGoDcSVFFEMLxe01iRnJ3M0+Si7T+9m4/GNrD26luNpx+kX1o+b2t3Eda2u\no5lbs0rFI1aWggKjLGZmGqXw1Ck4fdrsF5GVZV5wjhyB/fvNlp1t3E+Dgow1sWlTCAkxVsrQUBO3\n6OJyTmkUl1RBqHlEMawa5cnHJ/77BFvit7DkxiUEuQddVPtaw6+/wvTpZqJt8mRo08ZMrgUGGu8N\nQRAE4dIgiiGiGF6O5BXkcTLjJAeSDrDj5A7Wxqxl+8ntJKQn0KFpB/qF9WNk25F0adYFz8aepcYk\nVjeuJCfHKIqpqUZRPHXKWBeLLpWdbeIUT50yS2okJJi/J06YWBp//5JbUJDJltqmjdkvcoFt0kRm\nz+2NxBQ1XEQxrBrlyce5v8/l31v+zfJblhPhE1FhW2X93+Xnw6pV8P77sGYNTJt2ztOiWzejIDo5\nlXwOSoyhIAiC/ZEYQ+GyxNHBkRDPEEI8Q4gKjmJwxGAOJB0gLi2OHSd3sCV+Cwu3LcTNyY1uzbox\nqEQ2iRQAACAASURBVNUgrm99PcEewTRpZJ8AwMaNzebnZxQ6MMpiRobJjHrqlImXycg490KjtYld\nzMoyrqpnzpxTHLduNcpjUpKxLgYHmy0sDDp2NC9IQUEms6qbW9USNQiCINib1j6tScpKIjW7amsZ\nnk+jRtCvn5lM8/ODqVPhscega1fYuNE8P5WCXr3OPWsFQRCEuodYDIU6xdncs5zJPENsaizH045z\nOPkw209uZ8fJHcSkxtDGtw29Q3pzQ+QN9A7ujbezd7VjEysiP9+88BRtZ88axTEtzVgcs7JKKo75\n+SZz6smTRmGMiTFbXJxxPw0JMQpjRIRJptOjh1EYi1xSRWEUhLIRi2HVKE8+xqfH0/rN1nx323dE\nt4iu9rXS0+Gnn0xW6NmzzaRamzbw6KNmku3kSZPFNDi42pcSBEEQSkFcSRHFsL6SX5hPSnYKCRkJ\nxKTEcCL9BLtP72b7ye1sP7kdhaK1b2u6NutK/9D+9A/vT6B7II0sl9YQXlBgFMacHPM3M9MkYija\n8vKM4lhQYKyLRRbGY8cgNtbENjo7Gytj06bG7apoHca2bc0Mu5eXcUlt3FjcUoWGjSiGVaM8+ai1\nxmWmC/OHzeeOLnfY5XqpqbBypcnwnJ1tPn/2GTz/vEnslZQEgwZJ9lJBEISaQBRDRDFsKJzNPUti\nZiKxabEcTz3Ok+Oe5LpnruNg0kEOJh0kLj2OQLdAOvp35IqQK7gq/Cp6BfWiiWPtrj2Rm2usipmZ\nxtqYnGxenlJSjHWxsPCcW2pysol3PHnynBKZlGResvz8TOxiSIhRHMPCjKWxWTOjTHp5mTgeJ6f6\nb3WUmKKGiyiGVaMi+djyjZZM6D6BKf2mYFGWctuq7P9dfLyJOfTzMxNm27aZ5YVmzzaTX1lZ8Prr\n0axfX3FblUGeB4IgCAaJMRQaDK5Orrg6uRLmFUZBYQFvNn6Tf1zxD85knuFM5hkSMxM5mnqUvaf3\n8tWfXzHntzmk5aTRxrcNPYJ60C+0H1eFX0VL75alJrOpKYqUNU/PC4/l5JiXpKKtyD216C8YS2Ny\nslESExON4rh5s1mXscilNS3NxD66uxsl0tPTzMj7+poXsYAAo0AWJcoJCDAvbU2amPggsUIKQsMk\nxCOE+PR4cvJzKlxXtrIEBRkX+f37zYRVRARMnAhPPgnvvGOW/UlONs8xMJ4Qbm5m0svZPl0QBEEQ\nLgKxGAr1hvzCfM7mniUjN4Pk7GTOnD3DkdQj7Dm1hz8T/+RoylFiUmMAaOfXjq7NutIzqCd9QvrQ\n3q89Fkv5s+WXGq2NtbEotjEr61xinLQ08zk//9y52dnnjhVZJG1jIdPTjcUyI8P8zcoyy224uRlF\n0tMTvL3Bx8cojUWurUWKZNFfFxdjkRRlUqgNxGJYNSqSj2O/GEtWXhZzh8/F29nb7tfXGtavNxNb\ny5fDrl3wwgtGOczLM+cUFJhnnVJmKaDMzP9n786j267OvIF/r/bdkvc1Tpw4CdnIBiRhMyG0rAU6\nTCldpzMDbYdOyzDttAzvW+h0pe20ndNl3rZDB9pOoZwp0IbSsIctYQ8JZI+zeY132dq3+/5xfS3Z\nJPES25Kt7+ec35El/SRd6Sf56tFzn3vV/zOfT/3PqahQk3YREdHpcSgpGBjSqUkpEU1GEYgFEIgG\n0BnqxM4TO7G3cy8O9RzCMf8xNPU3IZKIYGHhQqwoX4G1FWtxXtV5OLv8bFhN1mw/hdNKpVRwGI+r\nLfNvPYQ1HE5nJqNRtcXj6rbBYHrJDr//vUGkHv6q9wsG1a/7Ho/avF715S0zO1lUpC7XmcuCAvW3\n06mymifbTCb1RZFoNAwMx2e0/vFrW7+G544+hwf+6gFUuCumpA2BAPDYY+p/xf33A88/D9x22/Bl\nfSwW9T9pYCA9HF7/ICalyjquXj37h8kTEZ0JBoZgYJivzqSuJJaMYSA6AH/Uj45AB/Z27cWerj04\n1K2Cxeb+ZvRH+1Hnq8NZxWdhaclSnF1+NlaWr8ScgjkwG2d2FKMDylNteiKdzJlY9a/4OuuoJ9fx\n+9X5QCA9S6v+QqdrK0MhlQ2w21XGUZ/qv71eFVBWVqrayTlz1OQ7Pp8a7mqzqcBRZylZU5S/GBiO\nz2j94293/Rb3vHwP/njjH1FXWHfa+zqTz93+/WpJn6oqNXPpD3/YgJKSrUP/N5YtU7OXVla+97ZS\nqvVja2qA+npVjy2l+sFJSuCv/1q1y+GYUNOIiGYN1hgSTYDFaEGRowhFjiLU+eqwrmYdIokIBqID\n6Iv0oT3QjiO9R7Cnaw8O9x7GM0eewe/e/R3aBtpgMppQW1CLBYULsLRkKVaWr8TK8pUod5XDbraP\nOoFDLjAY0rWP45FKqUxkLJbOSsZi6ayiDgR1dlLK9Bpm0Wj6ulgsnb0MhVSmsqcHOHhQ1VF2d6ug\n02xWwaHXq4a4lpaqL47Hj6vMgx7uWlKiviTqzKPJxNpJorFYWLQQPaEe+KNntpbhaOrr1XDS9nbg\nssuAP/9ZTUgDqKGk//u/wGc/C5x1lhqVcPHFQEOD+l8lhKqRbm1VszjrrGEyqU4HBoC//AU4/3w1\n9JSfeyKiiWHGkOgUpJQIJ8IqsxjxoyPUgc5AJ1oDrUP1iq0DrUOb0+JEjacGdb46LCpahGWly7Ci\nbAWqPFWwm+ywmWzTOulNtkk5fFjryCGuOkjUWySibpN5ez2Lq57JtadHbX196VpJPfRVCDX5jsul\nTvVEPLpuUmcl9ZDXkpL05RaLCijNZg5Vy3XMGI7PaP2jP+JH6fdL8eiNj+KK+iumtC3RKPDkk+qz\nX1z83s9aWxtw9Kj6bD/8sAr8Lr8cWL9e1RmeTjis/jc4HCorWVOjPtuplPrfwGwiEeUDDiUFA0Oa\nXtGEqlkciA6gM9SJrlAXesO96Ap14bj/OJr6m9AeaEdrQAWMBmFAlbsKle5K1PnqsLhoMZaVLcPi\n4sXwWD15GTSeSmaNZOY2cvbWzNpJnZWMRNLDWfWQ1szzegisDih1/WQ8nh7W6nCoWki3W9VG6iDT\n40mfjvxb11DqukoTx2FMKQaG4zOW/tHzbQ++fem38Zm1n4HRMLW/jITDwL59amipJqX6caawMJ3t\nk1LNWvrCC8D27cDGjcDNN48+a2k8rj7vsVj6f4OU6nNaW6t+ENJBYiqlgk+3m59bIpodGBiCgWG+\nyqU6s8wZUXvCPWr5jHA3YskY+iP9aB1oxYngCbQOtKJloAXN/c3oi/ShzFWGSlclKtwVqHRXorag\nFnW+OtQX1qPMVQa7WQWNVqOVgWMGfexTqeEZST20NbMuMhxWf0ci6osgMHyoWSKR3l9vetbXzDrL\nSCQ9/DVzKGxmPWY8rr646oylDjB15lJveubXwkJ1vrhYnVqtzFqOhoHh+Iylf1zz8zW4YM4F+Nol\nX4PX5j3lfpP5P/fCCxvwxz9uHfrhp7kZOHJEDRkd+f7v7wd+8hNg5061DEZ9vdrPYlG3efTRBtx3\n39bTBnfhsAoYM/8H6JfF7QY2bFCfQSKimYw1hkQ5wGQwocBWgAJbAao8VQDSM6IOW0JjMLuYTCUR\nTUbRHmhHR7ADHcEOHOk9gtdaXkNHsANdoS5ISBTZVR1ksaMYVa4qVBdUo86rAsd5vnnw2r2wm+wz\nfjKciTIYVDBlHePksTpDkEwO//tk55PJ4TO9JhLpafWTyfTlmX/HYurLp15WRGcsAwE1HLalJT0Z\nj950MKozl05neqbGkcuI6KGwXu/wzedT++mgkr8h0HisqliFA90HMBAdOG1gOJmMRvWe1mpq1Ht4\n5071/nU61Q8qgDr9138FDh0Cdu9Wp6++qoK9efPUMPO//3vgYx8DVq1Sn5GR7PZTZxt1jeLcuWrz\neNS+mbM+p1Lq8hxb1YiIaFIxY0g0zaSUiCQiCMaDCEQD6A53oyfcg4HYAKKJKIQQEBAIxoLoDHWi\nL9I3lIXsCnWlh69GeuE0O1FkL0KJswRV7irUFtRifuF81PnqML9wPmoLanN+yY3ZJjNIzDzVgeDI\n+ko93C2RSAeKOrAcuXSIvl1mFjNzWK3Npr7QOp3pNSr15nSmt8zrdCDq8aQvc7vVfZlM6gv8yM1g\nGH5+OgNRZgzHZyz9471v3Yt/3/7v+O31v8XqytXT1LKT08vnvPOO+hyUlIx+GymBl19Wwd2776r3\n8IoVwPLl6rSqavT3aCqlPnPhcDqbOPI2RqPKVBYVpZfpGe8EXkREU4lDScHAkGYPnUmMJWOIJqLp\nNRhjgaHMYzAehH6/94Z70RPpwYngCXQGO9Ed6kZ3uBu9kV70hHsQjofhs/tQ4apAlbsKFe4KtbnU\n0NUqdxWqPdUodZZOeW0RvZeU6UykPh25nSzQPNmQ1mRSBYqh0PA6ykAgHTjqobYnGwabGXDqgNVm\nU9nYzFP9t950JkYvPWK3pwNUm00Fnjbb8DpOhyM94Y/ROPzvUwWferNYGBiOx1j6x72de7H2l2vx\n0F8/hKvqr5qmlp1eNAps26ay7Hp49liCsFQKOHZMBZa7dqnNZlMznM6dq96P7e1qohuLRQV4y5er\n5XFGywYmk+pzFY2qz6XBoGZBraxUMyZ7pyfZSkR0SgwMwcAwX+VSjeF0klIilowNbfFUHLFkDKF4\nCOF4GMF4EKFYCOFkWM2mGuhAR6hjaBirP+rHQHQAA7EB9Ef70R/tRyQRgdfmRaG9EMWOYpQ6S1Hm\nLEOVp2ooeJxTMAc1nho4LI6sL8mRr8f+dDKHvo7c4vH3Bn46KMycpCOz7krXXmbWbmYGo/p0ZB1m\nZi3myTZdAwoMnw3WYkkvN6IvN5mG72M2A089xcBwPMbSP8aTcVT9oAr/cv6/4LZ1t8FkOHmVyWR+\n7sZyX4mEWuKiowNobFTvnYKC984wetttDfjRj05+X1KqiW5eeEEFg4FAOpiLx4HOThU8+v1qGKre\namrGlmXUWf5kMr0Oq9mc/tFE//hjsajzrB8moqnEGkOiPCOEgNVkHdMQUSkl4qk44sn4sGAyFA8h\nEAuo03gAfaE+dIY6h4a19oR70NzfjN2du1UAGemHP+pHf7QfTosTxfZiFDuKUeYqQ4WrAjWeGlQX\nVKPaXY1ydzlKnaXwWDywmCxZDyLzhc6ojZdeVmTkjLCZQWXmciMj99XXJRLD7zczyNSPo79oG43D\nH3fkY51qdtp4XC2OTpPLbDRjaclS7Oncg4HoAHz23JiFxWRSwVZlpcrqtbUBb74JnDihMn0mU3pd\n1GBQZQNHEgJYvFhtp9PZCezYobbf/U7VBFssKhAtL1cZxbPOUn87HCpDmDkkW0oVXL722nsfH0i/\n/0tKgOpqNXTb4UhPOMXaRSLKBcwYEhGA4cNY9VDWcDyMgdjA0HDW/mg/eiO96A51q5rHcBf6wn3w\nR/3wR/zwR/1D+wKA0+KE2+KGx+pBgbUAPrsPhfbCocxkkaMIJY4SVLurUeut5ZDWGUzK9AQ+Jxse\nmzl5T+aWSKjb6dvrWSNHXqb/vvpqZgzHY6z941ee/gpeOv4S/ueD/4Nab+00tGxiYjFVR9jcrILC\nwkIVOB47ptY3NRjSQ5onWv8nZfoHD79fDWc9dAjYs0etlRgIqEDSalUBntOpZkpdsEAFezrrrZfR\nSaVUe8rK1AzEodDwxwLSE2npel+vV52XcvjwcJ3lT6XUEFldE6xnP/Z41OMTUX7iUFIwMCSaLnoY\nazQZHaqBDMVCGIgNDA1PDcVDw2Zk7Y/2Dw1f7Y/1IxANIBBX2Uq99Uf70RfpQyKVQKG9UA1ldZWh\n0l2JGk8NqtxVqPHUYI53DuYWzIXH5sn2S0FZwslnxmes/eNfDv4Ftzx2Cx698VGsqVwzDS2bXFKq\noK2vT9UQdnWpQMpiUZPETPYESVKqrGIgoILHAwfUcNdoNJ35llIFhEKoILapSe0/f74KZufPB5Ys\nUZPjOBzp4eB6uLU+bHqItR5ebTCkJ6zKzNxreiZjg0EFrYWFw4fgRiLqsQyG9GMODKjXTmcxUyn1\nXAYGVDuKi9V9WSzpCadsNg6NJco1DAzBwDBfsc4sdyVTSSRSiVNu8VQckURkKLgMx8MIxUPoDncP\nTaLTFe5CT7gHveFeDMQGhrKSfZE+JJ5OoOwDZfBavfDZfSiyF6HYWayGuDqLUeooRalTbeUuNbSV\ns7PODgwMx2es/aM/4kfp90vxwAcfwAeXfPCk+0x3jeGZ3tfAgMouHj2qgiCXSwVC4bAKfHRdLTB8\nfUODQQVTU7HofXe3WnuxuVllIffuBVpb1XUlJSoAKypSp8XFKgMYi713NmJdK2w0qn3cbnVaW6s2\nKVVgZzKpv6VU+ySTKgOpn3fmkG+TSV2vzwuRzj7qwHPk0NjCQhUwZr5Wur7S6UxPQmU0prOdJpM6\nPXFCXVZYqNrmcKj99CiBVEods9MdB/3cOBSXZot4XH22JvL/R30WWGNIRDnGaDDCaDDCivEFY7om\nMrMeMpqIIhgPIhgLqprIaAC3/+l2fGbDZ9AX6RvKSPZH+tE20DZUOxmMBdWSIINDW60mKzxWz/Bg\n0lGMEmeJOnWUoNSlJt0pdZSi3F0Oi5Fz0VN+KLAVoM5Xh9dbX8cHFn/glBPQzCRuN7B+PbB0KXD8\nuMok2u0q8CovVwFMMJjOrAEqmDp2TE1Yo+tmTab0OqEj6VpZHVDpYDORSA/51MGLHlK6YgWwZs3w\nLGYwqLKcmVtLixq+qieu0UFWQUF6huBkUgXA/f0q4HzmGeDgQfV4JpN6Pm63qpEsL1eBaSCQXhe1\nuFjt29KiTisrVbbRbleZ0BMnVHBWUqIep7c3PUusy6Xapofvlpen6y3j8fTroZ9/LKayut3daihu\nf3+6xtJuV7ctL1f33d+vXkOfT03oo18rt1vtG4mo1+zECRVMlpWp4beRiGqPxZKeOVlPAKSzrrou\nVA9vt1qHB5b6mOkgVc9Cmxk06+BcD+XVt9en0Wg6Y2w0pm870eV9TrZ8ymwkZbr0ILPuXC8jozPW\n+hibzeljoT97unxBH3e/Xx0PozH9PtPHRD+OnhxND+XW71v9XtDZev1DSzisPgvd3en3nH6/6Ynb\n9I9MBkP6faQndEsmVfsdDvW+NRjUe97vV89X/yijs/qFheozGA6rzL6urc78YUS39UxNecZQCHE5\ngB8BMAC4V0p5z4jrvwjgowAkADOAswAUSyn7Rrttxn0wY0iUZ3RWUk+ukznJTiQRQTgeRiQZSWcj\nQ2oZj75I37CAciA6gFAihFAsNCyQDMaDsBgtcJqdahusl3Rb3em6SVsBvDYvfDYfvDav+nsw6Cyy\nF8Fj9cBsNMNkMLF2cpLMpoxhrvWPn3zkk+iL9uG+a+/LmQlosiVz+ZfmZuDw4fQXtsxgRwj15U5n\nxXRQZLOpL5i61lAHUJ2dapbVcFg9jhDpdUMnK+uVGUQkk+oLbGOjykyWlqp26S+1XV1qv8pKdZvW\nVvXFMxRS+5WXp2sqPR71BTUSSQejgUB6KGprq3qN9PI1Dof6kjwwoPYTQgWiZWWqHUVF6S/9wWC6\nnrO/XwWERqNqXyw2/Iu53oJBtRUVDV+rUgetBoPaz+dTlwmhvrgXFak2Auk6Tf3664Ben+pMbTSa\nns1Z/20wqC/1+jUOBk8+K3Qyqb60+3zq+VdWAhUV6WV7TKZ0wFJZqV5no1Ednz171HvPbFaTHxUW\nqvtsaVE/dOiAxOtVgYP+UUKvQWu3q+t1G/R7LBhMZ2T1c9fLCwHpicFSKXU/+jXXga0OePRyQ5nv\nvcwfSiIRdex1hl7fh163t6tLvXZ6CHbm52qi7/mRl+lgMnMZKH29Hpat26WP/ekeP5VSnxFAHUOf\nTz1G5n3rzLwOAHVgqDejUR1TnVUfOVN45kzcemh3KJR+LwaD6bbqADqRUJ+dBx/M4aGkQggDgAMA\nLgXQCuB1AB+WUu47xf5XA7hNSrlpPLdlYEhEY5GSKbXEx4hAUg9nDSfCCMaCiCQiCMaD8EdU4KiX\nAAkkAkOZy1A8hEgiooLQRHjo9joQDcaDSKaScJgdcFpUcOmyuFBgLRgKKnUQWeIoQZGjaGipkBJH\nCdxWN0wG09BGymwJDHOxf/zvHf+N7277LrZ8dEtOT0CTDXpopv5Sp78UT3RG0VRKfWFub1cZyp6e\n4Rk2IB10Ztb1AelJnMLh4bMBZ876azanv6BrZrPaJ5VSX4T12qSTlYnSWcFwWH2JDYWGD3XVAYSe\neEq/DnrSqswJdYQYPkNxKqVOM4+BDvg6OlT9pn79/H61pVLqi3R3t/rCLKX6Qt3ZmV4yJxxOB636\nddfZVp2lHbk+q94SCRXUGAwqKHO5hi+zo+tB9bHp7VWBUFubatPJ1qwNhVRGGFD7ezzpCYu6utLB\nk8+ngkEdJOggRK8nqwOOzM1sTg+ZNhjSz9flUo+pJzDKXPpIB9Z6uLB+72dmWXVwqN+XI+nnp9uu\na2h1Rl3fLjMA11sgoF4v/QNGZlCqs4M6yNUZxMzTZFLdZ1+f2nQwqD+/mX/bbOpHA52JHxnc6/di\nb2/6WCeT6r2mj7cO4MxmdSwMhvT7Vf9YopexiURUm3p71eX6c2K3D1+zWJ8aDOl99H6Z7zWzWe37\nyCO5PZT0XAAHpZTHAEAI8SCAawGctOMDcBOAByZ4W8ozrDHMXxM99gZhgM1kg81kG9P+mct9ZGYn\nE6nEsGBSz+AaToYRS8SQSCUAASSSiaG1JQOxwNAEPXq4a3eoG7viu9T5hBr+mjmrq9vqhsviGgoo\nvTbv0GnmDK+F9kIU2tSpz+4blqlkUJmzcq5/3FS3Cbc+fivaAm0nDQxnWo3hZNKTrdjG9q9jVPpL\nnscDLFyY/gKrA6BIRH3h7OhQX451EChlOniqrU1PMiNEOivS06O+LOsvomZzOnOXTKrzoZD6Qtre\n/t56Q6NRffHXQ1ETiXQ2JfP1yPy9QQecemio/gKrv+D29qb3t9tV5kvfTgeoJpN6vm1t6f1GZryc\nTtUWPTusDvD0cNORwbUOBHSwqYfb6ddLDw3Ux0S/FgZDemZaHVzriXYyM046sMkMwPV1+jnox9aZ\nVn19Znv1a5FIpGe8LS1NB/g6i5VZexaNDp8ESA+JHBmcB4PprJ1+nMzaWr9fZXvfeUe1TwcZuhZU\nv9aZwVIspo6FDlL08Fw9YVEgkN7i8fRrrYPIkUHryTavVz3GFVeks6F6qKl+7Y1GtY/BMHz5JP3j\ng348HUjr90DmjxF6C4fTQ0Mzs6S63fp1KSwcniXVwWAymf4xZyrqk8eisxN45JEzu4+pbnoVgKaM\n881QHdp7CCHsAC4HcOt4b0tENBWEELAYLeOuNUzJ1Ekn3Rka/pqMI5JUk+8MZR3jYYQSIcSTcQBq\n0fGB2GAgGQ3AH/MPBY5N/U3Y371/2MyuOgANxUNIyRQcZsfQ5rK4VOZycEisy+yCy+pSQ2JtHngs\nHrisLnWqs5o2jwo0bT7YTDYOhZ18Odc/1hTUoNBeiJeOv4R11evO9O5oHHRGIVNFxejrL55MRcXY\n99VZC501CYdVoNDbq67T6zXq4bFlZSpoyaz50pmb/n4VYEQi6Zo+u11lvHRdl86knCpLedZZ6gu9\nHgZ6Ojqo0hknHTjrwBpQ99PXp4ZeAun26kBAD//UgYKmh/i63emhfPF4+nUymdJBmtWazl5m1oXp\nOrhMOsOVObwy8/50zWhPT7qGTGeHAHVZKKTu2+dTbe/uTmdVo1F1vcWSHj57stcsM3srZTqg1+3R\nQbDOno6cfTaZVM9BDykeGFDPy2YbHijqoarjyUrrQFu/1jpbP7LOM3MYpQ7q9TBmHRBmDiPVQzH1\ncdbvMf2+1O/VzKB5ZL1jMqle78zno7PJmUNGQ6H07XRW8mQ/IOgMqH5P6ssy6wVHDl3PvK0+Rvo6\nfR9nIpd+Sr4GwEtSyr5sN4RmBmYL81euH3uDMEwooARUUJk51HVoMp5EDKGECgAjiYgaEpuKI5qM\nqixmUmUpARVU6kAxGA9iIDagMpo6w5mMom2gDUeTR4fuS88Qq2s0o4moGhqbCMNkMMFusg8Ni3WZ\nVRZT11vq+soCW8FQvaXP5hvKahY5iuAyu2A2miHyYQaFyTdt/eO66nV458Q7SKQS78k2T+bnLlfv\nK9/YbKqOMFN19ei304FKJrdb1fqdqbGuP5k5dPZk7dEqKlTAOZrMdVP1MMOJOtVaknporec0Ky6V\nlqqlTM5U5rqxuoZNX66zxzpz29OTznpl1lCaTOpHAj1keWSW2GRS91FcnA7kU6l0EOf3p+vxMjOj\n2smCn8xhmTorqpdg0YE9oDKFTmc6aI/F0oFcNKoC1p4edZmeoGjevHSGUT/PYDBdS6qzszqY02uL\nZs6wqyeZ0cPBu7pUsJhIqPbpfZzO9I8q8Xj69vo10sdCHxc99FgP4dUTJ8Vi6SA3c3RAZhY2M5j/\n6EfP7H0z1YFhC4A5GeerBy87mQ8jPUxmvLfF3XffPfR3Q0MDGhoaxtdSIqIcYBAGWE3WCc3ompTJ\n92Qn9WUpmUIylUQylUQsFRvKXL5nKZFkHEmp9okn44gn4oim1HqVelIePeurHv7aMtCCQz2HEElG\nhjKgkXhkKJAdmcXUQaXL4oLT7BwKMF0WlbX02DzwWFUm8+jbR3HgrQOwGq1jHgI8Q+Rk/3jx3Ivx\nu3d+h4HoQN5PQEP5ZWS2bKbTAbPdnq5bPJW5c09/vV5CIXM4p54NNLMuUE+2oh9XiOEz1Fqt6do7\nYHjW62RrY45cVmYiMusqp8KCBVNzv2O1devWSf1xbKonnzEC2A9VIN8G4DUAN0kp947YrwDAYQDV\nUsrweG47uC8nn8lDrDHMXzz200cHnJmB5sn+zlybUgeHmZnIaCI6FEgG40EMRFWtZTgRRiQeQTip\najWjiSgiyQhiCTUpUCQRGTqNJCII/Gtgtkw+k5P94/6u/Vh/73o898nncHb52cOuy9W6QP4/rVya\nJAAAIABJREFUICJSznSCtinNGEopk0KIzwF4EukptfcKIT6trpa/GNz1OgBP6E7vdLedyvYSEdFw\nQgiYhJrEZrxZzEwny0xmBpfRRDSdpRwcPhtPxt8zrPZD//qhSXx22ZOr/ePCooUosBXgod0PYa53\nLgpso6QaiIho1pjydQynAzOGRET5YbYsVzFdJtI/3vH0HXjx+Iv46kVfxab5m2AQUzQGi4iIJtWZ\n9pH8b09ERERDPrnyk3i7/W20DLTguP94tptDRETThIEhzVicYCh/8dgTTZ1FRYswv3A+9nXvw64T\nu5BMqTnWJ/Nzl6v3RUSUzxgYEhER0RAhBK5ddC2eOfwMAtEA2gbast0kIiKaBqwxJCKiGYM1huMz\n0f5xX+c+nPtf5+IH7/sBKtwVuKL+CtYaEhHlONYYEhER0aSq8lThkrmXYEvjFvijfnSHurPdJCIi\nmmIMDGnGYl1J/uKxJ5paLosLVy+8Gk82PolEKoFj/mM5WxfI/wdERJNjStcxJCIioplHCIGzy8/G\nirIV2Na0DQ6TAyzZICKa3VhjSEREMwZrDMfnTPrHzmAnfvbGz/CLN3+B7276LjbVbUKZq2ySW0hE\nRJOFNYZEREQ06YodxVhVtgpmgxmNvY042nc0200iIqIpNObAUAjhmMqGEI0X60ryF4895ZrZ2EcK\nIbCkZAkunHMhXjz2Ij51/aeQSCUm5b5ZY0hElHtGDQyFEBuEEHsA7Bs8f7YQ4mdT3jIiIqIcN9v7\nyOqCalxUexG2N29HAgm0D7Rnu0lERDRFRq0xFEK8CuAGAH+SUq4avOxdKeWyaWjfmLDGkIgoP+Ra\njWGu95GT0T++3vI6Pr/l81hVvgrXL74el82/bJJaR0REk2laagyllE0jLkpO9AGJiIhmk9neR9YX\n1WPj3I3YfGAzTgROwB/xZ7tJREQ0BcYSGDYJITYAkEIIsxDiiwD2TnG7iEbFupL8xWNPOWTW95Fe\nmxeb6jah5+EebG/ePimT0LDGkIgo94wlMPwMgFsBVAFoAbBy8DwREVG+y4s+cknJEhTHivHw3oex\nu3M3oolotptEREST7LQ1hkIII4DPSyl/OH1NGj/WGBIR5YdcqjGcCX3kZPWPUkpsObQFdz57J1aW\nr8Q/rP0HrK1aOwktJCKiyTKlNYZSyiSAj0z0zomIiGarfOojhRBYV70ONy69EQ/vfRivtbyGrlBX\ntptFRESTaCxDSV8SQvxECHGhEGK13qa8ZUSjYF1J/uKxpxySN33k9Vdcj+sWX4cL5lyA3+/5PV5r\neQ0pmZrQfbHGkIgo95jGsM/KwdN/y7hMAtg4+c0hIiKaUfKqj6wvqsfnzvkcPvnHT+LFYy9iZdlK\nVHoqs90sIiKaBKOuYzgTsMaQiCg/5FKN4UwwFf1jf7Qfdzx9B15uehnfu+x72FS3CULwkBARZduU\nr2MohCgQQvxACPHG4PbvQoiCiT4gERHRbJGPfaTH6sEta27B0b6jeLv9bXSHu7PdJCIimgRjqTH8\nFYABAB8a3PoB/PdUNopoLFhXkr947CmH5E0fmfm5W1q6FJvqNuG5o89hT+eeM7qvyWwXERFN3FgC\nw/lSyruklIcHt68BqJvqhhEREc0AedlHmgwmfGbNZ/Di8RdxsPsg+iJ92W4SERGdoVFrDIUQ2wF8\nSUr50uD58wF8X0q5fhraNyasMSQiyg+5VmOY633kVPaPA9EBXPrrSzHXOxf/vP6fcV71eVPyOERE\nNDZn2keOZVbSzwK4P6NmohfA30z0AYmIiGaRvO0j3VY3/mndP+HWx2/F4qLFWFKyBG6rO9vNIiKi\nCRp1KKmU8m0p5dkAVgBYIaVcJaXcOfVNIzo91pXkLx57yhX51Eee7HN3fs35uHn1zfjpGz/FK02v\nnNF9TWa7iIho/MYyK+m3hBBeKWW/lLJfCOETQnxjOhpHRESUy/K9j6xwV+Cy+ZdhQ/UG3P7U7egM\ndma7SURENEFjqTHcIaVcNeKyt6SUq6e0ZePAGkMiovyQgzWGOd1HTkf/mJIpHOo+hKt+dxU21GzA\nr679FYwG45Q+JhERvdeUr2MIwCiEsGY8oB2A9TT7ExER5Yu87yMNwoCFxQvxqw/8Co/sewQPvPtA\ntptEREQTMJbA8H8APCOE+DshxN8BeArA/VPbLKLRsa4kf/HYUw7Jmz5ytM/dBbUX4M4L78RtW27D\nuyfePaP7msx2ERHR2Iw6K6mU8h4hxE4AmwYv+rqU8ompbRYREVHuYx+ZJoTAP63/J2xr2oZPPPoJ\nPPGxJ1DiLMl2s4iIaIzGUmPoBBCWUqaEEIsALALwFyllfDoaOBasMSQiyg85WGOY031kNvrH7lA3\nLr7vYthNdtx77b1YVroMBjGWAUpERHQmpqPG8AUANiFEFYAtAD4O4L6JPiAREdEswj5yhCJHEf58\n059hMphww0M3YHvTdvDHWyKi3DeWwFBIKUMAPgjgP6WUfw1g6dQ2i2h0rCvJXzz2lEPypo8cz+eu\n1leLB254AB6rB19/4evY07lnwvc1me0iIqJTG1NgKIRYD+CjAP48eBnnoSYiImIfeUpzvXPx0yt/\nitdaXsNvdv0GLf0t2W4SERGdxlhqDC8C8EUALw8W2dcBuE1K+fnpaOBYsMaQiCg/5GCNYU73kdnu\nH1MyhXteugff2/Y9fPey7+LjKz4OqymvVvMgIpo2Z9pHjhoYjqEBP5ZS/uMZ3ckZynbHR0RE0yPX\nAsPRZLuPzIX+sSfcg8889hnsaN+B31z/G6yrXpfV9hARzVbTMfnMaM6fhPsgGjfWleQvHnuaQWZN\nHznRz12hvRBfPv/L8Nl8uPOZO9Ed6maNIRFRDpry+aOFEJcLIfYJIQ4IIb58kuu/KITYIYR4Swjx\njhAiIYTwDl53VAixc/D616a6rURERNMln/rHVRWr8P3Lvo8d7Tvwyzd/yVlKiYhy0GQMJX1LSrn6\nFNcZABwAcCmAVgCvA/iwlHLfKfa/Gqo2Y9Pg+cMA1kgpe0dpQ9aHyhAR0dSbgUNJT9pH5mP/KKXE\nj1/9Mb754jfx0t++hPqi+mw3iYhoVsmFoaSne/BzARyUUh4bXOz3QQDXnmb/mwA8MOK+uSouERHN\nVKfqI/OufxRC4NZzb8WCwgX44pNfRDQRzXaTiIgow2R0Kv9xmuuqADRlnG8evOw9hBB2AJcD+EPG\nxRLAU0KI14UQN59pQ2l2YV1J/uKxpxnkVH3kjOsfJ+NzZzQYcf/19+Px//c4vvHCN5BIJXKiXURE\nBJhG20EI8RSAv5ZS9g2e9wF4UEr5fgCQUt43SW25BsBL+nEGnS+lbBNClEB1gHullC+d7MZ33333\n0N8NDQ3sKIiIZoGtW7di69at2W7GKU1THzmr+scFhQuwKLkIP3r1R5hTMAcfP/vjsJlsWW0TEdFM\nNNl95FjWMdwhpVw12mWnuO06AHdLKS8fPP8VAFJKec9J9n0YwENSygdPcV93ARiQUv7gJNflTA0F\nERFNnVyrMZxoH5nv/aOUEt968Vv47rbvotBWiC+s+wL+8dx/hNFgzHbTiIhmrOmoMUwJIeZkPGAt\n1BCWsXgdwAIhRK0QwgLgwwD+NHInIUQBgIsB/DHjMocQwjX4txPA+wC8O8bHJSIimg4T7SPzun8U\nQuBL538JD/7Vg/jQ0g/hrq134d+e/zekZCrbTSMiyltjCQzvBPCSEOI3QojfAngBwB1juXMpZRLA\n5wA8CWA31PCavUKITwshbsnY9ToAT0gpwxmXlQ0+7g4ArwDYLKV8ciyPS/kh28OhKHt47CmHTKiP\nnIn942SvPWgxWnD5gsvx1Yu/il9f92v8+LUf4yN/+Aia/E2j38EUtYuIKJ+NWmMopdwihFgNYN3g\nRbdJKbvG+gBSyi0AFo247Ocjzt8P4P4Rlx0BsHKsj0NERDTdzqSPZP+oModOixPXLr4WT3mewlee\n+QqW/HQJvnT+l3DHBXfAbDRnu4lERHljLDWGF53scinlC1PSognI1RoKIiKaXDlYY5jTfeRM6x9D\n8RD+sOcP+OJTX8S66nX49XW/RoGtINvNIiKaEc60jxxLYLg546wNau2lN6WUGyf6oJNtpnV8REQ0\nMTkYGOZ0HzlT+8cdrTvw0Uc+ikJ7IR6+8WGUOkuz3SQiopw35ZPPSCmvydguA7AMQO9EH5BosrCu\nJH/x2FOuyKc+crJrDE9nVeUqPP6Rx9Ef7cc1D1yDg90HcaoAl/8PiIgmx0QWuG8GcNZkN4SIiGgW\nYB85Seb65mLzTZshpcSlv74U9719H/qj/dluFhHRrDWWoaQ/RnrqbQNUwftRKeXHprhtYzZTh8oQ\nEdH45OBQ0pzuI2dD/9jkb8JdW+/CH/b+AXdccAduX387LEZLtptFRJRzzrSPHHVWUgBvZPydAPCA\nlPLliT4gERHRLMI+corVFNTgmxu/iUp3Jb714rfgNDvxuXM/ByFy5vcBIqJZYdSM4UwwG34RpfFr\naGjA1q1bs90MygIe+/yVaxnDXDeZ/eNkfu4mcl894R7c+9a9+PoLX8dnz/ksvr3x2zAYDPx/QEQ0\naMozhkKIegDfBrAEasY1AICUsm6iD0pERDQbsI+cPoX2Qvzzhn/GqopVuHnzzdjetB0P3vBgtptF\nRDRrjKXG8CUAdwH4IYBrAHwKgEFK+dWpb97YMGNIRJQfci1jmOt95GztHzsCHfiHx/8BTx9+Gnde\neCduX387jAZjtptFRJRV07GO4ZtSyjVCiHeklMszL5vog0622drxERHRcDkYGOZ0Hzmb+8eUTOH3\n7/4edz57J1wWF3525c9w/pzzWXtIRHlrytcxBBAVQhgAHBRCfE4IcT0A10QfkGiycO2q/MVjTzkk\nb/rI6VzHcCwMwoCblt+Eij9UYGX5Slz1u6tw39v3ISVTZ95AIqI8NJZZSb8AwAHg8wC+DuASAJ+c\nykYRERHNEOwjs8xsMOPnV/8ci4oW4fNbPo/93fvxpQ1fQpGjKNtNIyKaUc54VlIhxI+llP84Se2Z\naBtm7VAZIiJKy7WhpKPJdh+ZT/1jIpXAb3f+Ft948RsIJ8L4yvlfwS1rboHVZM1204iIpsV0rGM4\nmvMn4T6IiIhmI/aR08RkMOETKz+Bc6rOwb077sWdz96J7nA37rjgDgaHRERjMJYaQ6KcxDqz/MVj\nTzT9cq3G8GT3ZRAGLC1dirsuvgvf2PgN/PCVH+LmzTfjSM8RJFKJSXtMIqLZiIEhERERzSoFtgJ8\ndu1ncf919+PVlldx+e8ux692/Aq94d5sN42IKGdNRo3hDinlqklqz0TbkDc1FERE+WwG1hhmtY/M\n9/5RSoldHbvwvZe/hz/t/xM21W3Cv5z/L1hRtgIOsyPbzSMimlRTvo7hGBrwN1LK+87oTs5Qvnd8\nRET5YgYGhlntI9k/quBwf/d+PNX4FB7a8xDebn8bDbUN+MJ5X8D5c86H3WzPdhOJiCbFlK9jKIR4\nSgjhzTjvE0I8oc9nOyik/MU6s/zFY0+5Ip/6yJlQY3gyQggsLl6Mj5/9cXx747fxjUu+gXgqjg8+\n9EHcvPlmHOw+iHwPnomIgLHNSlospezTZ6SUvUKI0ilsExER0UzBPnKG8Nq8uKD2AiwrW4Zzq87F\ntuPb8N87/xtXP3A1vrXxW7h8weVwWpzZbiYRUdaMOpRUCPEmgOullMcHz9cCeERKuXoa2jcmHCpD\nRJQfcm0oaa73kewfT80f8WNn+0787I2f4c8H/owr66/E58/7PM6pOgcWoyXbzSMiGrcprzEUQlwO\n4BcAngcgAFwI4BYp5ROnveE0YsdHRJQfcjAwzOk+kv3j6Ukpcdx/HI/uexQPvPsAmvubcc+me3DD\nkhu49iERzThTXmMopdwCYDWA3wN4EMCaXOnwKL+xzix/8dhTrsinPnKm1hiejhACtd5a/O2qv8V3\nLv0OLpxzIW5/4nb8Zudv0BHsYO0hEeWVsdQYAsAGABdlnH9sCtpCREQ0E7GPnOHcVjcunnsxqj3V\nsJvtuO2J2/DA7gdw/eLrsbZiLcpcZaj11sIguPwzEc1eYxlK+h0A5wD4n8GLbgLwupTyX6e4bWPG\noTJERPkhB4eS5nQfyf5x/Jr8TXj80ON4uvFpPH/seZgMJly76Fp8bMXHcG7VuTAbzdluIhHRSU1H\njeEuACullKnB80YAO6SUKyb6oJONHR8RUX7IwcAwp/tI9o8T0xfpw872nWjyN6F5oBk/ee0nWF66\nHLesuQXnVJ6DSk8ls4dElHOmvMZwkDfj74KJPhjRZGKdWf7isacckxd9ZK7UBU7lfWlemxcX1V6E\ny+svx/rq9fi/F/1f9EX78Jk/fwZf3fpV/HHfH9Hkb0JK/R5ARDQrnLbGUAghAHwfwA4hxHNQM65d\nBOAr09A2IiKinMU+cnYTQqDYUYyL516MxcWLUewoxr7ufXh076N4+vDT+Njyj+GiuRdhXfU6eG3e\n0e+QiCjHjWUo6TsA3gdVQwEAr0kp26e6YePBoTJERPkhB4eS5nQfyf5x8gRjQexo24Fj/mN4p+Md\n3Pf2fagvrMeHl30Yl9ZdioVFCzm8lIiyajpqDO8H8BMp5esTfZCpxo6PiCg/5GBgmNN9JPvHyeeP\n+PH2ibfR2N2IZ448g8cOPoar6q/CzatvxjlV58BlcWW7iUSUp6ajxvA8ANuFEI1CiF1CiHcGi+2J\nsop1ZvmLx55ySN70kblaFzjd/w8KbAW4aM5FuGTeJbh+8fW46+K7cLDnID7x6Cdwz0v34KnGp3Cg\n6wC6Ql1IppLT2jYiojMxlnUM3z/lrSAiIpqZ2EfmISEE5vnmocpThWN9x1DjrsG25m34+Zs/x4vH\nX8T1i69HqbMUdpMdZ5WchTpfHZe5IKKcN+pQ0pmAQ2WIiPJDrg0lzXXsH6dHLBlDY08jtjVtw3NH\nn8PmA5tx4ZwLcePSG2EymOCwOHBOxTmocFdAzVlERDT5przGcCZgx0dElB8YGI4P+8fp1drfiheO\nvwApJR47+Bg279+MS+ddig+e9UEYhAFemxdLSpagpqAGJsNYBm0REY3ddK1jSJRzWGeWv3jsiaZf\nrtYF5tL/g0pPJd43/31wWBy4fvH1uP+6+2E2mnHr47di84HNCMaCeKX5FWzevxmHew8jnoxnu8lE\nREMYGBIRERFNkkJ7Id4///0oc5YhFA/hUys/hXs/cC+C8SBueewWbD22FUZhxKstr+LRfY9i14ld\n6An3gJldIso2DiUlIqIZg0NJx4f9Y/ZIKdE60Io3Wt9AKB6C2+pGT7gH//XWf2F/9358ZNlHcOm8\nSxFKhJBMJVHiLMH66vVwWpzZbjoRzVA5P5RUCHG5EGKfEOKAEOLLJ7neI4T4kxDi7cFpvv9mrLcl\nIiKaqdg/zm5CCFR5qnD1wqtx4ZwLYRRGmAwm3HXxXbjr4rvweuvr+MSjn8Aj+x5BIpVAf7Qffzn0\nFzT7m5k9JKKsmNLAUAhhAPATqOm8lwK4SQixeMRutwLYLaVcCeASAP8uhDCN8baUx3KproSmF489\nzXQzsX/M1brAXP9/YDQYUV1QjffNfx9Wlq9ER6gD5a5yfP2Sr+M/Lv8PSCnx+S2fx292/gZGYcTz\nx57Hs0eeRXeoO9tNJ6I8M9UZw3MBHJRSHpNSxgE8CODaEftIAO7Bv90AuqWUiTHeloiIaCZi/5hn\njAYjlpQswVX1V6HYUYzWQCvcVjc+vebT+PV1v0YwHsTn/vI5HPcfx0B0AE80PoGtR7cyQCSiaTPV\ncyVXAWjKON8M1aFl+gmAPwkhWgG4ANw4jttSHtu6dWu2m0BZwmNPs8CM6x8n83OXq/c1HTxWDy6q\nvQhdoS7s7tiNlv4WWEwWfPn8L+ON1jfwszd+hhJHCT66/KNwmBzY0rgFVe4qLCtdhiJ7EddBJKIp\nkwuL6LwfwA4p5UYhxHwATwkhVmS7UURERFnG/nEWK3YU4+K5F6Mv0oeD3QdxqOcQ6ovqce8H7sWW\nQ1vww1d+CLvZjg8t+RDsRjueaHwCZc4yLC1ZilJnKYwGY7afAhHNMlMdGLYAmJNxvnrwskyfAvBt\nAJBSNgohjgBYPMbbDrn77ruH/m5oaMj5mgM6cw0NDTPul2KaHDz2+WPr1q2z9VjPuP5xMj93uXpf\n2eC1eXFO1TlYWLQQO9p2oGWgBRvnbcSV9Vdie9N2PLT7IfzyrV/ihiU34II5F+C5o8/BYXLg7PKz\nMadgDgNEojw22X3klC5XIYQwAtgP4FIAbQBeA3CTlHJvxj4/BdAhpfyaEKIMwBsAzgbgH+22GffB\n6bjz0Ez/MkATx2Ofv2bLchUzsX/M1WBuNv0/kFKibaANb7S9gUAsALfFDZfFhb1de/HQ7oewo30H\nrq6/GlcvvBpSSjjMDiwuWYwqdxXcVvfoD0BEs9qZ9pFTvo6hEOJyAP8BNdHNvVLK7wghPg1ASil/\nIYSoAHAfgIrBm3xbSvnAqW57isdgYEhElAdmS2AIsH+kU0ukEmgfaMf+7v3oCHYAAApsBegN9+J/\n9/wvnj36LD609EO4pv4ahBNhJFNJFDuLUV9Yj5qCGpgMuVApRETTLecDw+nAjo+IKD/MpsBwOrB/\nnPlC8RA6g514t+Nd9EX64LV50Rfpw8/f/Dne7XgX1y2+DtcuuhYmgwn90X7YTDasKFuBud65HGZK\nlGdyfoF7oqnCOtL8xWNPNP1yde3B2f7/wGF2oNZbiyvqr8Alcy+BhIRBGPB/Lvo/+MH7f4D2QDs+\n/sjH8V9v/RdiyRgcZgdebX4VWxq3oHWgFYlUIttPgYhmCI41ICIiIspxBmFApacSZa4yHOk9grfa\n3oLL7MKXNnwJf7fq7/Dovkdx+5O3o8pdhesWX4fVFavx/NHnYTKYsKBwAeb55sFr82b7aRBRDuNQ\nUiIimjE4lHR82D/OXqF4CLvad6GxtxEuiwsFtgIkUglsa9qGR/Y9gub+Zly76FpcseAKpGQK8VQc\nJY4SnFV8Fsrd5axDJJqFWGMIdnxERPmCgeH4sH+c/XrCPdjRtgPtgXYU2ArgNDshhMChnkN4eO/D\neOHYC1hVvgob6zZiSfESJGUSRmFErbcWc71zUWQvgtlozvbTIKJJwMAQ7Pjy1WyaopzGh8c+fzEw\nHB8uV5Ef9DIXuzt3oyvcBUjAZXHBZXEhGA/ixWMvYuuxrXjnxDtYUrIEV9ZfieWly5FIJWA0GLGw\naCHmeefBY/VACH68iGaqM+0jOY6AiIiIaAYTQqDSU4lKTyUiiQg6Ah1o7G1Ee6AdJoMJl82/DFfU\nX4FIIoJtTdvwx/1/xM9e/xmurL8SVy64Ege7D2JPxx44zA7UFNSg1luLQnshDIJzFBLlE2YMiYho\nxmDGcHzYP+a3gegAGnsb0djTiFgyBiEELEYL3BY3mvubsfnAZjx9+GmsrliNv1ryV1hYuBCBWACx\nZAxWkxXVnmpUuivhsrjgtri5/AVRjuNQUrDjIyLKFwwMx4f9IwFASqbQF+lDf6QfPeEeHO49jHgq\nDp/dh2QqiScan8Aj+x6B3WTHxnkbsbx0Oeb75iOUCCGaiEJAwGqyYkXZCswpmMOaRKIcxcAQ7Pjy\nFetK8hePff5iYDg+rDGkk4kn42jub8aO9h2IJqIochTBZDDhjdY38ErzK9h1Yhd6wj1omNuATXWb\ncFbxWYglY+iJ9KiJawpqMc83D0X2ImYRiXIIawyJiIiIaMzMRjPm+eah2lONw72HsevELiRSCawq\nX4Vzq84FALT0t+CZI8/gOy99B8lUEtcsugZX1V8Fh9mBloEWNPY0wmK0YH7hfMz1zoXP7svysyKi\nM8WMIRERzRjMGI4P+0cai1gyNhQgJlNJWE1WWI1WOC1OSCmxr2sfHtn3CLY3b8fayrVomNuANRVr\nYDPZ0BvuRTwVR5W7CsvLlqPQXpjtp0OUtziUFOz4iIjyBQPD8WH/SOMRSUTQ0t+CQCyAE8ET6Ap2\nwWKyoMheBCEE/BE/Xjj+Al449gJ2d+xGna8OG+dtRENtAwwGA4KxIHw2H+oK61BoL4Tb4obdbM/2\n0yLKGwwMwY4vX7GuJH/x2OcvBobjwxpDOhN9kT7s69yHxt5G2M12FFgLhmoKY8kY3mp7C88eeRbb\nm7dj49yNuGHJDSh2FKM/2g8pJSQkKt2VWFC4AF6bFw6zg+skEk0h1hgSERER0aTz2rxYV7MOi4oX\nYX/3fhztOwopJZwWJ1wWF9ZVr8O66nXoDffiD3v/gC9s+QKKHcW4cM6FWF2xGouKFqEv0ocXjr0A\nIQTcVjfOLj0blZ5KrpFIlIOYMSQiohmDGcPxYf9IkymaiOJE4ASO+o+iLdAGmVLvLZfVBafZiZRM\nYeeJnXil+RW82fYmArEArll4DRrmNqDKXYVQPIS+SB9cVheWFC9BtaeaQ02JJhGHkoIdHxFRvmBg\nOD7sH2mqpGQKgVgAXaEuNPY0ojPYCbPRDJ/dB5NBDUg70H0Amw9sxitNr8BoMOLqhVfj+sXXw2gw\noi/SByklih3FqC2oRYmzBF6bl0NNic4AA0Ow48tXrCvJXzz2+YuB4fiwxpCmiz/ix5G+I2jsaUQs\nGYPVZB2qSZRSorG3Eb/f/Xu81vIaLpxzIS6qvQirylchloxhIDaAlEyhzFmG1RWrufQF0QSxxpCI\niIiIsqrAVoCV5SuxvHQ5usPdONZ3DEf6jiCZSsJr82JB4QLceeGdOBE4geePPY9f7/w1vvniN7G+\nej0urr0YayrXIBAL4PGDj6PYUYx53nkoc5XBY/Uwi0g0TZgxJCKiGYMZw/Fh/0jZFEvG0NzfjD2d\nezAQHYBBGFBoL4TZaAYAdAY71fIXR1/AUf9RXFl/JT6w8AMosBUMzWxqN9lR5ipDmasMRfYiBopE\np8GhpGDHR0SULxgYjg/7R8oVgVgAx/3H8W7Hu0imkrCZbHBb3UP1iC39LXh036N48vBynTR7AAAg\nAElEQVSTqPZU44I5F2B1xWrM8cxBLBlDOBEGJOC0OLGsdBmqPdVDASYRKQwMwY4vX7GuJH/x2Ocv\nBobjwxpDyjXRRBQdwQ60BdpwrO8YEqkEXBYXnBYnDMKAeDKOHe07sL1pO3a070BPuAcry1fivOrz\ncEHNBbAYLeiL9sEszFhUsghzC+bCbXVn+2kR5QTWGBIRERHRjGA1WVFTUIOaghqsKl+FtoE2HO49\njPZgO6SUsJqsWF2xGudWnQsA6Ap1YUfbDrzc9DL+8/X/xNLSpWiobcB5VedhT8cevHviXXjtXtT7\n6lHlqeLyF0RngBlDIiKaMZgxHB/2jzRTxJIx9IR70NzfjCO9R5BIJWAymGA32+E0OyGEQDgexvbm\n7dh6dCveansLy8uWo2FuA9aUr0EilYAUEkW2IhQ5ilBTUIMSRwnrESmvcCgp2PEREeULBobjw/6R\nZqJEKoGuUBd6wj3oCHSgLdgGSMBtdcNlcQEAQvEQtjVtw9ajW/F2+9tYV70OV9RfgUWFixBLxRBJ\nROC1eVHnq0ORvQiF9kIYDcYsPzOiqcXAEOz48hXrSvIXj33+YmA4PqwxpNkgkoigbaANh3oOoSvU\nBQBwmB1wWVwwGozoj/bjycYnseXQFvSEe9AwtwE3Lr0RbqsbA1G1RqLFaEF9UT0K7YWwm+zw2X0w\nCEOWnxnR5GKNIRERERHNWjaTDfN88zDPNw/BWBBdoS4c9x/HieAJxJNxCCFwVf1VuGHJDWjub8bj\nBx/HLY/dgg3VG3DJvEuwqnwVJCT2d+1HIpUAANhNdtQXqbrEAmsBh5wSgRlDIiKaQZgxHB/2jzSb\npWQK/dF+dAQ6cKDnAPqj/XCYHSiwFsAf9eOJQ0/gxeMv4pj/GNZVr8M5leegvrAecwrmICmT6A33\nIiVTcFvdWFC4AOWucrgtbg45pRmLQ0nBjo+IKF8wMBwf9o+UL6SU6Ap1YU/nHjT3N8NhdsBn9wFQ\nM5u+dPwl7DqxCwd7DiIQC+CCORdgbcVaLClZArfVjb5IHyABg8GAQnshvDYviu3F8Nq98Fg9HHZK\nMwIDQ7Djy1esK8lfPPb5i4Hh+LDGkPJRb7gXu07sQvNAM5xm53sCu9aBVrx47EXsPLETuzt3o8pd\nhWsWXoMNNRvgsrgQTUYRTahNQsJkMKHSXYnaglqUukphMVqy+OyITo01hkREREREg3x2Hy6qvQid\noU4c6D6Apv4mQKo1FF0WFyrdlbhx2Y24cdmNSKaSeK3lNTx+8HH89PWfoqagBudUnoNzqs7BkuIl\nMBqMSKaSQ3WNQggU2gpR7ipHlaeKk9jQrMKMIRERzRjMGI4P+0ciNatpT7gHrQOtaPY3I5KIQELC\nYXbAbDTDarTCaDAiloxhd8duvN76Ot5ofQNtgTasKl+FtZVrcW7VuSh3lSMlU4gmogjEAkikErCb\n7JhfNB81nhp4bd5sP1XKcxxKCnZ8RET5goHh+LB/JBpOSolgPIjuUDfaBtoQiAfQG+5FIpWA1+aF\n3Wwf2rcn3IM3W98cChRdFhfWVq7F+ur1OLv8bFiMFsSSMfgjfsSTcVR5qrCsdBmKHEVZfIaUzxgY\ngh1fvmJdSf7isc9fDAzHhzWGRKOLJ+M47j+OfV370B/th0EY4LP7htUSpmQKjT2NeLXlVbzS/Aqa\n+pvQUNuA9y94P84qPgsA0BfpQygeQrWnGktLl6LQXshhpjStWGNIRERERDRBZqMZ8wvnY37hfAxE\nB9Ay0IK9nXvRk+yBQRjgtrhhM9lQX1SP+qJ6fGzFx3AicAJPHX4K33npOwCA981/HzbVbUKluxI9\n4R482fgkbCYbFvgWoMJdAZ/dB5OBX7sptzFjSEREMwYzhuPD/pFoYpKpJHojvWgPtKOlvwU94R4A\nagKbAmvB0FqHUkrs7dqLJxqfwNajW7G4eDGuW3wd1lSsAQD4I34kUgkICPjsPvjsPjjNTpS5ylBk\nL4IQ/HdGk4dDScGOj4goXzAwHB/2j0STI5aMoSfcgyZ/E470HUEylYTL4oLL4hoK7mLJGJ498iw2\nH9iMw72HMd83H+dWnYsNNRtQ561Ty2Ako4gn44in4nBanKhwVaDEUTJ0XzaTjcEiTRgDQ7Djy1es\nK8lfPPb5i4Hh+LDGkGjyxZNxtAfacaD7ADqCHSetSQzHw9jduRuvNL+C7U3bEU/Fsa56HdZUrMHK\n8pUosBUgmogiFA8hmogCApCQMBvMKLYXo85XhxJnybDJcIhGwxpDIiIiIqJpYjaaUVNQg5qCGgRi\nARz3H8f+rv3oSfZASgmP1QOnxYm1lWuxtnItbj3nVhz3H8erLa/iL4f+gu9t+x5WV6zGprpNOLvs\nbJS7y4fuO5lKYiA2gJebXgYAuCwulDpL4bV54bF64LF64DA7mFWkKTHlGUMhxOUAfgTAAOBeKeU9\nI673APgtgDkAjAD+XUp53+B1RwH4AaQAxKWU557iMZgxJCLKA7MpY8j+kWj2kFIiEAugM9SJQz2H\n0B3qhoAYWi/RY/UMBXOBWADPHnkWLx1/CXs696DIUYRlpcuwuHgx6rx1WFC4AFaTFYAanhqKhxBL\nxpCSKUgp4bV5sbRkKcrd5cOylEQ5PZRUCGEAcADApQBaAbwO4MNSyn0Z+9wBwCOlvEMIUQxgP4Ay\nKWVCCHEYwBopZe8oj8OOj4goD8yWwJD9I9HsFk/GEUlE4I/4cbjvMFoHWiEh4ba44bK4hvZLppI4\n0ncE75x4Bwe6D+Bw32E0+ZuwuHgxVlesxuqK1agvrIfZaB66TTAWRH+0H0IIVLorMd83H+Wu8qEJ\ncSh/5fpQ0nMBHJRSHgMAIcSDAK4FsC9jHwnAPfi3G0C3lDIxeF5A/ZJK9B6sK8lfPPY0C8y4/jFX\n6wL5/4BykdlohtlohtvqRnVBNSKJCDoCHdjXvQ+tA60wG8xDS1gsKFyABYULhm4bioew88ROvNX2\nFn6w/Qdo7m9GrbcWayvWYn3NepxVfBacFidSMoW+SB+eP/o8rCYr6nx1qHRXosBWAJvJlsVnTzPV\nVAeGVQCaMs43Q3WGmX4C4E9CiFYALgA3ZlwnATwlhEgC+IWU8pdT2VgiIqJpwv6RKI/YTDbM8c5B\nTUEN+iJ9ONp3FId6DiGejMNutsNtdQ+tc+gwO7C+ej3WV68HAEQSERzsPohXW17FD1/5IXrCPTiv\n6jysr16PtZVrUempRCwZw+Hew9jXtW/oPkqdpShxlqDAWgCP1TM0PJXoVHJh8pn3A9ghpdwohJgP\n1dGtkFIGAJwvpWwTQpQMXr5XSvnSye7k7rvvHvq7oaEBDQ0N09B0yib+Qpy/eOzzx9atW/P5eOdU\n/ziZxyFX74toqgmRXs9wedlydAY7cbTvKNoCbYglY4BU+zjMDjjMDhgNRthMNiwvW47lZcvx96v/\nHu2Bdmxv3o4/H/wz7nn5HiwpWYL1NeuxoXoDKtwVAFRtYkewA8f8x4Yee45nDuYXzkeJswQGwQF5\ns8Fk95FTXWO4DsDdUsrLB89/BYDMLLAXQjwG4NtSypcHzz8D4MtSyjdG3NddAAaklD84yeOwhoKI\nKA/MohpD9o9ENERKiVA8hEAsgN5ILzqCHTgROIFEKgEBAZfVBYfZ8Z6ALhwP443WN7CteRtebX4V\nHqsHG2o2YHXFaiwsWgiP1QMASMkU/BE/IokIbCYbFhQtQJmzDD6bb1j9Is1suT75jBGqWP5SAG0A\nXgNwk5Ryb8Y+PwXQIaX8mhCiDMAbAM4GEAFgkFIGhBBOAE8C+JqU8smTPA47vjzEupL8xWOfv2ZR\nYDjj+sdcrQvk/wOarXQw1xXqQnN/M9qD7RAQcFvcJ12yIiVT2Ne1D9ubtmNXxy4c7D4In82H+qJ6\nrCpfhXXV61DmKkMsGYM/4kcilYBBGFDhrkCluxIuiws2kw0WowV2k51LYsxAOT35jJQyKYT4HFSn\npafj3iuE+LS6+v+3d/fBcV3nfce/z2JfsLtYvAMkCJDiC0DRNEVFcglZUp268TRROq3tJo1rp3/I\nTdJmOrGSaTuT2pnOqNNpJ05ae8ZpxtM6sS2lY4/ddOKXJBNXiWKlY8W03kiKlEyBIClSBAgQwAKL\n3cViX0//2OUKBAEJSwJY7N7fZ+YO7r7cu2fv2d3nPjjn3OO+BPxn4Ckze7Wy2W865+JmdgD4lpm5\nSjm/tlbQExERaTSKjyLybnzmq3Y7HekZYbmwzLXENS4vXGY6PY1zjpA/RDQQJdgSxGc+jvYd5Wjf\nUaB8xdNri9c4P3eelydf5iunv0JvpLc6fvFI7xHMjIXlBSaTk2+/sIOgP8hgbJCBtgG6wl2EA+Hq\nGEhpXls+j+F2UIuhiIg3NEuL4XZRfBRpTrlijngmztXEVW6kb5DMJgHKF7IJxtacuqJYKvL67Ouc\nfOskJydOMrc0x+jgKA8NPsThnsPsie2pbpcv5knn02TymXLLoYNIMMJw9zCDscFb5mWUnWNHdyXd\nLgp8IiLeoMSwNoqPIt6QL+aZXZrl8vxlJlOTFErlmW0MIxqMrjk+cSo1xclrJ3lp8iXG4+MksgkO\ndB7gYNdBDnUf4mjfUQ53H64mgNlCloXlBUquRMgfYjA2yK7oLnoiPcRCsdvKJNtPiSEKfF6lcSXe\npbr3LiWGtdEYQxHvcc6RyqVI59PVbqIz6RkcDsNoD7UTDoRv2y6VS3Fp/hIX4xe5OH+RM9NnyBay\nvG/P+zjSc4Tju46zv3M/ZnZLiyLAUPsQw93DdLZ2rrlv2R47eoyhiIiIiIhsHzMjFooRC8XY3bab\nI71HKJaKLGYXmUnPMD4/zlRyCkd5jGIkECHUEqIt2MbxXcc5vus4UE4wryaucmb6DOdnz/PN175J\nvpTnxJ4TjA6O8sDuBxiIDeCcYy4zx8SbEzhzhFpCdIQ62Nu+l4HYgFoTG4haDEVEpGGoxbA2io8i\nspal/BLzmXmmU9NMpaZIZBPVLqNhf7h6ddKV4widc0wkJ3hh4gVenHyRs9Nnyxez2fswH9j3AQ73\nHMbv81MoFVguLJPOpSm5ErFQjHs676E33EssFCMaiGp84hZRV1IU+EREvEKJYW0UH0VkI3LFHIvZ\nRRLLCWbSM8xmZqsXtIkGo7QF224bo1gsFRmbG+P5t57nb9/6W66nrnOo6xCD7YPs79jPQ0MPcaDz\nANlilmQ2SdEVcc4RaAmwK7qLwfZBusPdtIfab9u33BklhijweZXGlXiX6t67lBjWRmMMReRO5Yt5\nplPTXJy/yFRqCuccPp+PaCC65jyK6Vya8fg4E8kJxuPj/PDaDzGMR/Y+wvuH3s+x/mO0+lsploqk\n82mW8ksA+H1+BmODDMYG6Qp3EQ1GlSjeIY0xFBERERGRTRVoCTDUMcRQxxD5Yp755Xlml2aZWJyo\nzqPo9/lpC7aV51MMRrl/9/3cv/t+AJ4YfYLLC5d5/urzPHX6KS7OX+Tennt5YOABHtz9IEd6jxBo\nCVAoFZhOT/PmwpuYGYbRFmyj1d9Kb6SX3W276WztJOQP1fmIND+1GIqISMNQi2FtFB9FZCvkijkW\nlheYTk8zuTjJ/PI8AA5Hi7UQbAkSDUQJtASq2yzllzg7fZZTU6d45forTCQneG/fe6uJ4nD3MC2+\nFkquRKFUIF/MkylkKJQKOOeqF9Ppj/TT0dpBLBRTy+Iq6kqKAp+IiFcoMayN4qOIbIeb3UOT2STJ\nXJLEcoKJ5ATZQhaf+YiFYkQCkVu2WcwucmbqTDVRnMvMMdI9Up5HsesQh7oPcaDzQDW5zBaypPNp\nsoUsUO6C2hXuoru1m/62fjpbOz1/YRslhijweZXGlXiX6t67lBjWRmMMRaReSq5UvvJpepqriavM\nZ8qtipFAhGgwit9364i2+cw8F+IXynMpzl9kPD7OVGqKQ12HODF4ghN7TjDcPUywJQiUk9FsMcty\nYZlsIYthBP1BBtoGGGgbqCajrf5WzySLGmMoIiIiIiI7is989ER66In0cLTvKEv5JWbSM0wmJ5lM\nTpIr5gj5y/MnBluCdIW7GB0cZXRwtLqPTD7D6zOvc3LiJJ/74eeYWJxgb8deDvccZrh7mIOdBxnu\nHqY73A2UL5hzI32DK4kr1X2YGe3BdtpD7XS0dtDV2kVHaweRQERdUVdRi6GIiDQMtRjWRvFRRHai\nYqnIXGaOq4mrTCxOkClkqo+F/WHCgXC1ZXClbCHLxfmLjM2NMR4f5/LCZS7NX2IwNsix/mMc6z/G\ne3rfw57YnmorYcmVyBVz5Io5soUsBVfAnIFBa0srPZEe+qP9tIfaiQQiBFuCBFuCtPhatu14bBZ1\nJUWBT0TEK5QY1kbxUUR2OuccS/klUrkUieUE8UycqdRUNVn0+/zEQjFa/a1rbp8v5rkQv8C5G+c4\nd+Mcb8y9wVJ+icM9h6vLvT33MtA2cEuXUucchVKBTCFDJp/B4cABBobR2drJnvY99IZ7q0njTu+S\nqsQQBT6v0rgS71Lde5cSw9pojKGINCLnHIlsgmQ2yUJ2gSsLV1jMLuLDRyRYHjfo9/nX7Qo6n5ln\nbG6Msbkx3ph7g7G5MZYLy4z0jHBvz70c7DpIX6SP/mg//dH+21oHnXMsF5ZJ5VIUXRHnHIGWAP3R\nfobah+hqLc+3uFarZj1pjKGIiIiIiDQNs3KLXWdrJ3vZy7G+YywsLxDPxJlMTrKYXWR+eR5XcmAQ\nbAlWxyoCdIW7eGjoIR4aeqi6z3gmXk0Wf3D1B8xl5riRvsHC8gK723YzFBtiIDZAf7Sf/Z37Odp3\nlL5oX3X7YqlIYjnB5OIkAM4c4ZYwPZEe+qJ9dITKU2g08pVR1WIoIiINQy2GtVF8FJFm5ZyrTpEx\nmZzkWvIaS7mlm3GCVn8r7aH2dx0ruFxYLm+/eI2p1BQz6RnG58c5P3uePbE93Nd/X3X84q7orluS\nvptzLS4Xlim5Ejjwt/i5p+MehtqHqldFDflDW304AHUlBRT4RES8QolhbRQfRcRL8sU8qVyKVC7F\nZHKSK4krlFyJFmshGozS6m/d8JVIV49dPHfjHCVXYrh7mOHuYUa6RxjpGWEwNnhL8lkoFVjMLpIr\n5igPW3SE/CF6I73sa99HT6SHtmDblrQqKjFEgc+rNK7Eu1T33qXEsDYaYygiXlYoFZjPzDOVnmIq\nOUV8Oc7N30TnHD7zEWwJEvKH8Pv8BHyBdRM25xxzmTkuxC8wPjfO+Pw443PjxJfjHOw6WE0Wh7uH\nOdh18Jbxh4VSgaX8Ekv5JXAQ8ofY17GPofYheiI9t83peKc0xlBERERERGQVv89PX7SPvmgf9/Xf\nR8mVyOQzpPNpsoUsmXyGRDZBIpsgnU8Tz8fLVyalnGRFg9HqfIdmRm+kl95ILw8PPVx9jVQuxcX4\nxWrr4rfPf5tri9fYE9tzS+vikd4j7G7bDUCumOPNhTcZmxvDZz4GYgPs79hPf1v/uldf3Q5qMRQR\nkYahFsPaKD6KiGzczauRpvNpZpdmubZ4jbmlOZxzmBmRQIRAS4CAL/COYxdvJn7j8XHG4+OMzY1x\naf4SIz0jHO07ykj3CA8OPEhnayclVyKVS5HOpcGgP9LPga4D9EX6au5yqq6kKPCJiHiFEsPaKD6K\niNydYqlIIpvgRvoGM+mZ6gVviqUiVKJRNBAlGoy+4/jFTD7D2RtneWP2Dc7PnefM1BkOdh3kkb2P\n8PDQw+zr2AdAOp8mlU3hcESDUQ73HGaofYi2YNu7llWJIQp8XqVxJd6luvcuJYa10RhDEZHNt3Ke\nw0Q2wWRykuvJ6zgchlFyJfw+P5FAhHAgvGbCmCvmOD11muffep4fXfsR2WL2liugjnSPUHTlKTJK\nrkQkGGFXZBfhQJhIIMKutl20h9pv2afGGIqIiIiIiGwTMyMcCBMOhOmL9jHcPUyxVGS5sEy2mGUp\nv8T88jzTqWlm0jPlqSyASCBCNBjF7/MTbAkyOjjK6OAoANOp6erVT5+5+AyTyUmO9R/jpw78FA8P\nPUzYH2Y6PU2hVKBQKpSTxUCE7nA3XeGu25LEO3pfzdDSphZDERFvUIthbRQfRUTqq1gqkswliWfi\nXE9eZzo9TbaQBaDF10JHqGPNeQ5TuRQvTLzAs5ef5fTUaWLBWHWKjJt/Y8EY2WKWbCFLKpfilx78\nJXUlVeATEfEGJYa1UXwUEdl58sU8yVySyeQkl+Yvkc6lMTMMo9XfSqu/lWBLsHrhmZIrMZmcZGxu\njPH4OBfmLnAhfgGf+RjpKU+RsTu6m88/9nklhgp83qRxJd6luvcuJYa10RhDEZGdzTlHKpcimUuS\nyqaIZ+LMZeZI5pLVqTPaQm3VaTNWbje7NFtNFs/NnOOlf/WSxhiKiIiIiIg0GjMjFooRC8Ug9vb9\nxVKRdD7NTHqGywuXmV2arY5V9Pv8RANReiO99EX7eHTfo8ykZ/gYH7u7sjRDS5taDEVEvEEthrVR\nfBQRaQ7OOZbySyxmF5lJzzCRmiCxnKg+ni1k+eQDn1RXUgU+ERFvUGJYG8VHEZHmdXOsYmI5wezS\nLKNDo3cVI9efhVFkh/vgBz9Y7yJInajuRbbfZn7vduq+REQaSaAlQHe4mwNdBzgxeOKu96fEUERE\nRERExOPUlVRERBqGupLWRvFRRMQ77jZGqsVQRERERETE45QYSsPSuBLvUt2LbL+dOi5QvwciIptD\niaGIiIiIiIjHaYyhiIg0DI0xrI3io4iId2iMoYiIiIiIiNyVLU8MzewxMztvZmNm9u/XeLzTzP7E\nzM6Y2UkzO7rRbcXbNK7Eu1T30gwaLT7u1HGB+j0QEdkcW5oYmpkP+H3gZ4D3Ap8wsyOrnvZbwCnn\n3P3A48Dv1bCt5z333HP1LkLdLCws1LsIdaW69y4v132zUHxsfvqe1o+Off3o2De2rW4xHAUuOOeu\nOOfywDeAj6x6zlHgrwGcc28A+82sb4Pbep6Xv4Af/ehH612EulLde5eX676JNFx83MzP3U7d12ba\nqeXyAh37+tGxb2xbnRgOAm+tuH2tct9KZ4CfAzCzUWAfMLTBbUVERBqR4qOIiOwoO+HiM58Fuszs\nFeDXgFNAsb5Fkkbw1FNP1bsIUieqe/GIHRUfd+q4QI0xFBHZHFs6XYWZvR/4j865xyq3Pw0459zv\nvMM2l4H7gGMb3dbMdC1uERGPaIbpKhQfRURkK9xNjPRvZkHW8CIwbGb3ANeBjwOfWPkEM+sAlpxz\neTP7l8DfOOdSZvau297UDCcJIiLiKYqPIiKyo2xpYuicK5rZp4BnKHdb/bJz7sdm9qvlh92XgPcA\nT5tZCXgN+OV32nYryysiIrIdFB9FRGSn2dKupCIiIiIiIrLz7YSLz9yxekzwu5OY2ZuViY9PmdkL\n9S7PVjKzL5vZtJm9uuK+LjN7xszeMLP/W+l21ZTWef9Pmtk1M3ulsjxWzzJuFTMbMrO/NrPXzOys\nmf165f6mr/813vsTlfubvu7NLGRmP6r8vp01sycr9zd9vW8Wr8fI7bZWTNbndWvUek5gZp8xswtm\n9mMz++n6lLo51Ho+omO/ee7kfKjW49+wLYZWnuB3DPgQMEl5vMbHnXPn61qwbWRml4D3Oefm612W\nrWZmfxdIAX/knDteue93gDnn3O9WTnq6nHOfrmc5t8o67/9JIOmc+3xdC7fFzGw3sNs5d9rM2oCX\nKc/Z9i9o8vp/h/f+z/BG3Uecc0tm1gI8D/w68PM0eb1vBsXI7bdWTPZSnNpOtZwTmNlR4GvACcrT\nvfwVMOIa9QS4zmo5HzGz9wBfR8d+U9R6PnQnn/1GbjGsywS/O4zR2HW4Yc65HwCrE+CPAE9X1p8G\nmnbW83XeP5Q/A03NOTflnDtdWU8BP6b8A9f09b/Oe785X50X6n6pshqiPCbe4YF63ySKkdtvrZis\nz+sWqPGc4MPAN5xzBefcm8AFyt8PuQM1no98BB37TXMH50M1f/YbOanQBL/lk6S/NLMXrXzFOq/p\nd85NQ/nLAvTXuTz18CkzO21mf+iFLkpmth/4CeAksMtL9b/ivf+oclfT172Z+czsFDAF/KVz7kU8\nVu93QTFy+62Myb9SuU+f1+2z3jnB6u/CBPoubIW1YpKO/RbZ4PlQzce/kRNDgUedcw8C/xD4tUrz\nvpd5rWvCF4GDzrmfoHzi3OzdCtuA/wP8RuU/Zavru2nrf4337om6d86VnHMPUP6P6KiZvRcP1bs0\nnNUx+QPo81pPOtbbZ3VM+lydy9PUtvJ8qJETwwlg34rbQ5X7PMM5d73ydwb4Ft5rnp82s11Q7Xd9\no87l2VbOuZkV/cT/gHIf8qZkZn7KP4L/yzn3ncrdnqj/td67l+oewDm3CDwHPIZH6n0TeD5GbrdV\nMfnblGOyPq/bZ71jPQHsXfE8fRc22Rox6eb5qI79JqvxfKjm49/IiWF1gl8zC1Ke4Pe7dS7TtjGz\nSOU/BphZFPhp4Fx9S7XljFv7sH8X+GRl/XHgO6s3aDK3vP/Kl/+mn6O56/8rwOvOuS+suM8r9X/b\ne/dC3ZtZ783uSGYWBv4B5fEUXqn3u+XpGLnd1onJZ9HndStt9Jzgu8DHzSxoZgeAYaCpr+S+DTZ6\nPqJjv/lqOR+q+fg37FVJoXwpbuALvD3B72frXKRtU6ngb1FuLvYDX2vm929mXwc+CPQA08CTlP8j\n+8eU/xtyBfiYc26hXmXcSuu8/79PuX95CXgT+NWbfcybiZk9Cvw/yidZrrL8FuUft/9NE9f/O7z3\nX6TJ697M7qM8iN5XWb7pnPsvZtZNk9f7ZvFyjNxu68VkfV63Rq3nBGb2GeCXgTzl7nfP1KHYTaHW\n8xEd+81zJ+dDtR7/hk4MRURERERE5O41cldSERERERER2QRKDEVERERERDxOiaGIiIiIiIjHKTEU\nERERERHxOCWGIiIiIiIiHqfEUERERERExOOUGIqIiIiIiHicEkORHcbM7jezn9l4EnIAAANbSURB\nVF1x+x+b2W9u0r5/w8xaN2NfIiIi200xUmTraIJ7kR3GzB4H/o5z7okt2Pdl4H3OuXgN2/icc6XN\nLouIiEitFCNFto5aDEXukJndY2avm9mXzOycmX3PzELrPPegmf2Fmb1oZn9jZocr9/+CmZ01s1Nm\n9pyZBYD/BHzMzF6pPP64mf33yvO/amZfNLMfmtm4mf09M/typRxfWfF6XzSzFyr7frJy3xPAHuD7\nZvZs5b5PmNmrleWzK7ZPmtl/M7NTwPvN7LfN7DUzO21mv7tFh1RERJqEYqRIA3LOadGi5Q4W4B4g\nB9xXuf1N4BfXee5fAYcq66PAs5X1V4GBynp75e/jwO+t2LZ6G/gq8PXK+oeBBHC0cvsl4HhlvbPy\n1wd8HzhWuX0J6KqsDwBXgO7K854FPlx5rAT8fGW9Gzi/ojzt9T72WrRo0aJlZy+KkVq0NN6iFkOR\nu3PZOXe2sv4ysH/1E8wsCjwC/HHlv4v/E9hVefh54Gkz+xXAv8HX/NPK37PAlHPu9crt11a8/sfN\n7GXgFHC0sgBYZQE4AXzfORd35W4wXwN+svJYEfiTynoCyJjZH5rZPwEyGyyniIh4m2KkSAPZ6JdM\nRNaWXbFeBNYatO4D5p1zD65+wDn3r83sBPCPgJfN7LbnvMNrlla9fgnwm9l+4N9RHiexaGZfXadc\n8HYAXC3jnHOVMhbNbBT4EPALwKcq6yIiIu9EMVKkgajFUOTurBc0qpxzSeCymf3T6kZmxyt/Dzrn\nXnTOPQncAPYCSaD9Ll6/HUgBSTPbBfzsiscWV+z7BeAnzazbzFqATwDPrd5v5b+5nc657wH/Fji+\nwbKJiIi3KUaKNBC1GIrcnY1e1vefA//DzP4D5e/dNyiPnfivZjZSec6zzrlXzewt4NNm9grw2+/y\nem71emUfp4EfA28BP1jxnD8AvmdmE865D5nZZ3g70P25c+7P1thvDPiOvX0J73+zwfcsIiLephgp\n0kA0XYWIiIiIiIjHqSupiIiIiIiIx6krqcgmMrPfBx6l3M3EKn+/4Jx7uq4FExERqTPFSJGdTV1J\nRUREREREPE5dSUVERERERDxOiaGIiIiIiIjHKTEUERERERHxOCWGIiIiIiIiHqfEUERERERExOP+\nP5t5E767rqEVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa1a3e30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig,ax = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "title = 'X' + ',  n_folds=5' + ',  time={:.2f} m.'.format(time_X/60)\n",
    "error_plot(scores_X_test[0], scores_X_test[1], color='b', label='scores_X_test', title=title)\n",
    "error_plot(scores_X_train[0], scores_X_train[1], color='g', label='scores_X_train')\n",
    "plt.ylim([0.9, 0.6]);\n",
    "\n",
    "plt.subplot(122)\n",
    "title='len(X)/10' + ',  n_folds=3' + ',  time={:.2f} m.'.format(time_X10/60)\n",
    "error_plot(scores_X10_test[0], scores_X10_test[1], color='b', label='scores_X10_test', title=title)\n",
    "error_plot(scores_X10_train[0], scores_X10_train[1], color='g', label='scores_X10_train')\n",
    "plt.ylim([0.9, 0.6]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.68929122420419542, 0.69781476212375149)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(scores_X_test[0]), max(scores_X10_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 148)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where( scores_X_test[0]==max(scores_X_test[0]) )[0][0], np.where( scores_X10_test[0]==max(scores_X10_test[0]) )[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В отчете по данному этапу должны содержаться ответы на следующие вопросы:\n",
    "\n",
    "** 1.Какие признаки имеют пропуски среди своих значений (приведите полный список имен этих признаков)? Что могут означать пропуски в этих признаках (ответьте на этот вопрос для двух любых признаков)? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkblue\" size=\"3em\">\n",
    "\n",
    "Пропуски имеют следующие признаки:\n",
    "\n",
    "```\n",
    "Признак                        Количество  Комментарий\n",
    "                               значений \n",
    "\n",
    "first_blood_time               77677       # игровое время первой крови\n",
    "first_blood_team               77677       # команда, совершившая первую кровь (0 — Radiant, 1 — Dire)\n",
    "first_blood_player1            77677       # игрок, причастный к событию\n",
    "first_blood_player2            53243       # второй игрок, причастный к событию\n",
    "\n",
    "radiant_bottle_time            81539       # время первого приобретения командой предмета \"bottle\"\n",
    "radiant_courier_time           96538       # время приобретения предмета \"courier\"\n",
    "radiant_flying_courier_time    69751       # время приобретения предмета \"flying_courier\"\n",
    "radiant_first_ward_time        95394       # время установки командой первого \"наблюдателя\", т.е. предмета, \n",
    "                                           # который позволяет видеть часть игрового поля\n",
    "dire_bottle_time               81087\n",
    "dire_courier_time              96554\n",
    "dire_flying_courier_time       71132\n",
    "dire_first_ward_time           95404\n",
    "```\n",
    "\n",
    "Первые четыре признака из этого списка - признаки события \"первая кровь\" (first blood). Если событие \"первая кровь\" не успело произойти за первые 5 минут, то признаки принимают пропущенное значение.\n",
    "\n",
    "Следующие восемь признаков - признаки приобретения некоторых предметов каждой из команд (префиксы radiant и dire). По всей видимости, данные события для команд происходят не в каждой игре."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.Как называется столбец, содержащий целевую переменную? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkblue\" size=\"3em\">\n",
    "\n",
    "Целевую переменную содержит столбец  `radiant_win`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.Как долго проводилась кросс-валидация для градиентного бустинга с 30 деревьями? Инструкцию по измерению времени можно найти выше по тексту. Какое качество при этом получилось? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkblue\" size=\"3em\">\n",
    "\n",
    "Кросс-валидация для градиентного бустинга с параметром `n_folds=5` и `n_estimators=30` на полной выборке данных проводилась 28.4 мин. При этом лучшее значение `auc_roc`, характеризующее качество классификации, получилось равно `0.689`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.Имеет ли смысл использовать больше 30 деревьев в градиентном бустинге? Что можно сделать, чтобы ускорить его обучение при увеличении количества деревьев? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkblue\" size=\"3em\">\n",
    "\n",
    "При использовании 10, 20, 30 деревьев наблюдается тенденция к увеличению точности (значения `roc_auc_score`) классификации при кросс-валидации. Увеличение количества деревьев должно повысить точность классификации.\n",
    "\n",
    "Для ускорения обучения при увеличении количества деревьев можно, например, использовать для обучения меньшую по размеру выбору данных. \n",
    "\n",
    "На рисунках показано как зависит точность классификации от количества деревьев (`n_estimators`) для полной выборки и уменьшенной в 10 раз. Построены зависимости для тестирования классификации на тестовой выборке (синяя кривая), и той же выборке, на которой проводилось обучение (зеленая кривая). Тенденция к уменьшению ошибки классификации с увеличением количества деревьев до 200, сохраняется. Синяя и зеленая кривые для полной выборки (левый рисунок) достаточно похожи, в то время как для сокращённой в десять раз (правый рисунок) - сильно расходятся. Качество классификации при тестировании на той же выборке, на которой проводилось обучение (зеленая кривая на правом рисунке), стремится к практически идеальному. Скорее всего, это связано с переобучением, возникающим из-за недостаточно репрезентативной (сокращенной в 10 раз) обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подход 2: логистическая регрессия\n",
    "\n",
    "Линейные методы работают гораздо быстрее композиций деревьев, поэтому кажется разумным воспользоваться именно ими для ускорения анализа данных. Одним из наиболее распространенных методов для классификации является логистическая регрессия.\n",
    "\n",
    "**Важно:** не забывайте, что линейные алгоритмы чувствительны к масштабу признаков! Может пригодиться `sklearn.preprocessing.StandartScaler`.\n",
    "\n",
    "** 1.Оцените качество логистической регрессии (`sklearn.linear_model.LogisticRegression` с L2-регуляризацией) с помощью кросс-валидации по той же схеме, которая использовалась для градиентного бустинга. Подберите при этом лучший параметр регуляризации (`C`). Какое наилучшее качество у вас получилось? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>lobby_type</th>\n",
       "      <th>r1_hero</th>\n",
       "      <th>r1_level</th>\n",
       "      <th>r1_xp</th>\n",
       "      <th>r1_gold</th>\n",
       "      <th>r1_lh</th>\n",
       "      <th>r1_kills</th>\n",
       "      <th>r1_deaths</th>\n",
       "      <th>r1_items</th>\n",
       "      <th>...</th>\n",
       "      <th>radiant_ward_sentry_count</th>\n",
       "      <th>radiant_first_ward_time</th>\n",
       "      <th>dire_bottle_time</th>\n",
       "      <th>dire_courier_time</th>\n",
       "      <th>dire_flying_courier_time</th>\n",
       "      <th>dire_tpscroll_count</th>\n",
       "      <th>dire_boots_count</th>\n",
       "      <th>dire_ward_observer_count</th>\n",
       "      <th>dire_ward_sentry_count</th>\n",
       "      <th>dire_first_ward_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "      <td>97230.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.444232e+09</td>\n",
       "      <td>2.630999</td>\n",
       "      <td>51.517104</td>\n",
       "      <td>3.442672</td>\n",
       "      <td>1233.405801</td>\n",
       "      <td>1147.899702</td>\n",
       "      <td>11.231996</td>\n",
       "      <td>0.357009</td>\n",
       "      <td>0.362285</td>\n",
       "      <td>8.271315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716250</td>\n",
       "      <td>-6.745912</td>\n",
       "      <td>106.093644</td>\n",
       "      <td>-79.634352</td>\n",
       "      <td>157.196040</td>\n",
       "      <td>2.965566</td>\n",
       "      <td>3.349553</td>\n",
       "      <td>2.448339</td>\n",
       "      <td>0.689119</td>\n",
       "      <td>-6.772303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.515393e+06</td>\n",
       "      <td>2.835761</td>\n",
       "      <td>32.564211</td>\n",
       "      <td>1.111741</td>\n",
       "      <td>566.588895</td>\n",
       "      <td>464.111662</td>\n",
       "      <td>9.041620</td>\n",
       "      <td>0.663889</td>\n",
       "      <td>0.626704</td>\n",
       "      <td>2.497575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725331</td>\n",
       "      <td>39.145035</td>\n",
       "      <td>74.111528</td>\n",
       "      <td>16.604443</td>\n",
       "      <td>99.593382</td>\n",
       "      <td>1.907288</td>\n",
       "      <td>1.155609</td>\n",
       "      <td>0.813459</td>\n",
       "      <td>0.710122</td>\n",
       "      <td>40.328277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.430199e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-236.000000</td>\n",
       "      <td>-45.000000</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.440815e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-31.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>-86.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.446338e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1175.000000</td>\n",
       "      <td>1113.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-14.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>-84.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.448829e+09</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1704.000000</td>\n",
       "      <td>1479.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>-79.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.450313e+09</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3319.000000</td>\n",
       "      <td>4332.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         start_time    lobby_type       r1_hero      r1_level         r1_xp  \\\n",
       "count  9.723000e+04  97230.000000  97230.000000  97230.000000  97230.000000   \n",
       "mean   1.444232e+09      2.630999     51.517104      3.442672   1233.405801   \n",
       "std    5.515393e+06      2.835761     32.564211      1.111741    566.588895   \n",
       "min    1.430199e+09      0.000000      1.000000      0.000000      0.000000   \n",
       "25%    1.440815e+09      1.000000     22.000000      3.000000    767.000000   \n",
       "50%    1.446338e+09      1.000000     50.000000      3.000000   1175.000000   \n",
       "75%    1.448829e+09      7.000000     75.000000      4.000000   1704.000000   \n",
       "max    1.450313e+09      7.000000    112.000000      6.000000   3319.000000   \n",
       "\n",
       "            r1_gold         r1_lh      r1_kills     r1_deaths      r1_items  \\\n",
       "count  97230.000000  97230.000000  97230.000000  97230.000000  97230.000000   \n",
       "mean    1147.899702     11.231996      0.357009      0.362285      8.271315   \n",
       "std      464.111662      9.041620      0.663889      0.626704      2.497575   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      746.000000      2.000000      0.000000      0.000000      7.000000   \n",
       "50%     1113.000000     11.000000      0.000000      0.000000      8.000000   \n",
       "75%     1479.000000     19.000000      1.000000      1.000000     10.000000   \n",
       "max     4332.000000     47.000000      8.000000      5.000000     34.000000   \n",
       "\n",
       "               ...           radiant_ward_sentry_count  \\\n",
       "count          ...                        97230.000000   \n",
       "mean           ...                            0.716250   \n",
       "std            ...                            0.725331   \n",
       "min            ...                            0.000000   \n",
       "25%            ...                            0.000000   \n",
       "50%            ...                            1.000000   \n",
       "75%            ...                            1.000000   \n",
       "max            ...                           25.000000   \n",
       "\n",
       "       radiant_first_ward_time  dire_bottle_time  dire_courier_time  \\\n",
       "count             97230.000000      97230.000000       97230.000000   \n",
       "mean                 -6.745912        106.093644         -79.634352   \n",
       "std                  39.145035         74.111528          16.604443   \n",
       "min                -236.000000        -45.000000         -90.000000   \n",
       "25%                 -31.000000         42.000000         -86.000000   \n",
       "50%                 -14.000000        118.000000         -84.000000   \n",
       "75%                   9.000000        158.000000         -79.000000   \n",
       "max                 300.000000        300.000000         296.000000   \n",
       "\n",
       "       dire_flying_courier_time  dire_tpscroll_count  dire_boots_count  \\\n",
       "count              97230.000000         97230.000000      97230.000000   \n",
       "mean                 157.196040             2.965566          3.349553   \n",
       "std                   99.593382             1.907288          1.155609   \n",
       "min                    0.000000             0.000000          0.000000   \n",
       "25%                    0.000000             2.000000          3.000000   \n",
       "50%                  189.000000             3.000000          3.000000   \n",
       "75%                  222.000000             4.000000          4.000000   \n",
       "max                  300.000000            21.000000          9.000000   \n",
       "\n",
       "       dire_ward_observer_count  dire_ward_sentry_count  dire_first_ward_time  \n",
       "count              97230.000000            97230.000000          97230.000000  \n",
       "mean                   2.448339                0.689119             -6.772303  \n",
       "std                    0.813459                0.710122             40.328277  \n",
       "min                    0.000000                0.000000            -84.000000  \n",
       "25%                    2.000000                0.000000            -31.000000  \n",
       "50%                    2.000000                1.000000            -15.000000  \n",
       "75%                    3.000000                1.000000              8.000000  \n",
       "max                    9.000000               13.000000            300.000000  \n",
       "\n",
       "[8 rows x 102 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "X_ = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X_, index=X.index, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97230, 102)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>lobby_type</th>\n",
       "      <th>r1_hero</th>\n",
       "      <th>r1_level</th>\n",
       "      <th>r1_xp</th>\n",
       "      <th>r1_gold</th>\n",
       "      <th>r1_lh</th>\n",
       "      <th>r1_kills</th>\n",
       "      <th>r1_deaths</th>\n",
       "      <th>r1_items</th>\n",
       "      <th>...</th>\n",
       "      <th>radiant_ward_sentry_count</th>\n",
       "      <th>radiant_first_ward_time</th>\n",
       "      <th>dire_bottle_time</th>\n",
       "      <th>dire_courier_time</th>\n",
       "      <th>dire_flying_courier_time</th>\n",
       "      <th>dire_tpscroll_count</th>\n",
       "      <th>dire_boots_count</th>\n",
       "      <th>dire_ward_observer_count</th>\n",
       "      <th>dire_ward_sentry_count</th>\n",
       "      <th>dire_first_ward_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>9.723000e+04</td>\n",
       "      <td>9.723000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.196314e-14</td>\n",
       "      <td>-1.207810e-13</td>\n",
       "      <td>-7.771676e-16</td>\n",
       "      <td>3.483134e-15</td>\n",
       "      <td>1.749769e-16</td>\n",
       "      <td>4.000126e-16</td>\n",
       "      <td>1.875506e-15</td>\n",
       "      <td>1.562528e-14</td>\n",
       "      <td>-1.285509e-14</td>\n",
       "      <td>1.675296e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.766165e-14</td>\n",
       "      <td>-4.253560e-15</td>\n",
       "      <td>5.158146e-15</td>\n",
       "      <td>-6.090892e-16</td>\n",
       "      <td>-1.830392e-14</td>\n",
       "      <td>-1.118102e-13</td>\n",
       "      <td>-3.081769e-14</td>\n",
       "      <td>3.524860e-14</td>\n",
       "      <td>7.812983e-15</td>\n",
       "      <td>1.632655e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.544364e+00</td>\n",
       "      <td>-9.277976e-01</td>\n",
       "      <td>-1.551315e+00</td>\n",
       "      <td>-3.096665e+00</td>\n",
       "      <td>-2.176908e+00</td>\n",
       "      <td>-2.473339e+00</td>\n",
       "      <td>-1.242261e+00</td>\n",
       "      <td>-5.377573e-01</td>\n",
       "      <td>-5.780831e-01</td>\n",
       "      <td>-3.311756e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.874859e-01</td>\n",
       "      <td>-5.856560e+00</td>\n",
       "      <td>-2.038744e+00</td>\n",
       "      <td>-6.242728e-01</td>\n",
       "      <td>-1.578386e+00</td>\n",
       "      <td>-1.554868e+00</td>\n",
       "      <td>-2.898532e+00</td>\n",
       "      <td>-3.009802e+00</td>\n",
       "      <td>-9.704278e-01</td>\n",
       "      <td>-1.914986e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.195682e-01</td>\n",
       "      <td>-5.751567e-01</td>\n",
       "      <td>-9.064324e-01</td>\n",
       "      <td>-3.981811e-01</td>\n",
       "      <td>-8.231863e-01</td>\n",
       "      <td>-8.659592e-01</td>\n",
       "      <td>-1.021061e+00</td>\n",
       "      <td>-5.377573e-01</td>\n",
       "      <td>-5.780831e-01</td>\n",
       "      <td>-5.090226e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.874859e-01</td>\n",
       "      <td>-6.195987e-01</td>\n",
       "      <td>-8.648314e-01</td>\n",
       "      <td>-3.833722e-01</td>\n",
       "      <td>-1.578386e+00</td>\n",
       "      <td>-5.062533e-01</td>\n",
       "      <td>-3.024850e-01</td>\n",
       "      <td>-5.511539e-01</td>\n",
       "      <td>-9.704278e-01</td>\n",
       "      <td>-6.007651e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.818965e-01</td>\n",
       "      <td>-5.751567e-01</td>\n",
       "      <td>-4.658831e-02</td>\n",
       "      <td>-3.981811e-01</td>\n",
       "      <td>-1.030837e-01</td>\n",
       "      <td>-7.519717e-02</td>\n",
       "      <td>-2.565884e-02</td>\n",
       "      <td>-5.377573e-01</td>\n",
       "      <td>-5.780831e-01</td>\n",
       "      <td>-1.086321e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.912027e-01</td>\n",
       "      <td>-1.853141e-01</td>\n",
       "      <td>1.606554e-01</td>\n",
       "      <td>-2.629218e-01</td>\n",
       "      <td>3.193397e-01</td>\n",
       "      <td>1.805390e-02</td>\n",
       "      <td>-3.024850e-01</td>\n",
       "      <td>-5.511539e-01</td>\n",
       "      <td>4.377882e-01</td>\n",
       "      <td>-2.040191e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.335776e-01</td>\n",
       "      <td>1.540688e+00</td>\n",
       "      <td>7.211296e-01</td>\n",
       "      <td>5.013135e-01</td>\n",
       "      <td>8.305786e-01</td>\n",
       "      <td>7.134102e-01</td>\n",
       "      <td>8.591429e-01</td>\n",
       "      <td>9.685271e-01</td>\n",
       "      <td>1.017574e+00</td>\n",
       "      <td>6.921489e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.912027e-01</td>\n",
       "      <td>4.022475e-01</td>\n",
       "      <td>7.003853e-01</td>\n",
       "      <td>3.820392e-02</td>\n",
       "      <td>6.506887e-01</td>\n",
       "      <td>5.423611e-01</td>\n",
       "      <td>5.628640e-01</td>\n",
       "      <td>6.781701e-01</td>\n",
       "      <td>4.377882e-01</td>\n",
       "      <td>3.663032e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.102648e+00</td>\n",
       "      <td>1.540688e+00</td>\n",
       "      <td>1.857352e+00</td>\n",
       "      <td>2.300303e+00</td>\n",
       "      <td>3.680984e+00</td>\n",
       "      <td>6.860669e+00</td>\n",
       "      <td>3.955949e+00</td>\n",
       "      <td>1.151252e+01</td>\n",
       "      <td>7.400202e+00</td>\n",
       "      <td>1.030152e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.347973e+01</td>\n",
       "      <td>7.836179e+00</td>\n",
       "      <td>2.616426e+00</td>\n",
       "      <td>2.262264e+01</td>\n",
       "      <td>1.433877e+00</td>\n",
       "      <td>9.455584e+00</td>\n",
       "      <td>4.889609e+00</td>\n",
       "      <td>8.054114e+00</td>\n",
       "      <td>1.733638e+01</td>\n",
       "      <td>7.606918e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         start_time    lobby_type       r1_hero      r1_level         r1_xp  \\\n",
       "count  9.723000e+04  9.723000e+04  9.723000e+04  9.723000e+04  9.723000e+04   \n",
       "mean  -1.196314e-14 -1.207810e-13 -7.771676e-16  3.483134e-15  1.749769e-16   \n",
       "std    1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00   \n",
       "min   -2.544364e+00 -9.277976e-01 -1.551315e+00 -3.096665e+00 -2.176908e+00   \n",
       "25%   -6.195682e-01 -5.751567e-01 -9.064324e-01 -3.981811e-01 -8.231863e-01   \n",
       "50%    3.818965e-01 -5.751567e-01 -4.658831e-02 -3.981811e-01 -1.030837e-01   \n",
       "75%    8.335776e-01  1.540688e+00  7.211296e-01  5.013135e-01  8.305786e-01   \n",
       "max    1.102648e+00  1.540688e+00  1.857352e+00  2.300303e+00  3.680984e+00   \n",
       "\n",
       "            r1_gold         r1_lh      r1_kills     r1_deaths      r1_items  \\\n",
       "count  9.723000e+04  9.723000e+04  9.723000e+04  9.723000e+04  9.723000e+04   \n",
       "mean   4.000126e-16  1.875506e-15  1.562528e-14 -1.285509e-14  1.675296e-15   \n",
       "std    1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00   \n",
       "min   -2.473339e+00 -1.242261e+00 -5.377573e-01 -5.780831e-01 -3.311756e+00   \n",
       "25%   -8.659592e-01 -1.021061e+00 -5.377573e-01 -5.780831e-01 -5.090226e-01   \n",
       "50%   -7.519717e-02 -2.565884e-02 -5.377573e-01 -5.780831e-01 -1.086321e-01   \n",
       "75%    7.134102e-01  8.591429e-01  9.685271e-01  1.017574e+00  6.921489e-01   \n",
       "max    6.860669e+00  3.955949e+00  1.151252e+01  7.400202e+00  1.030152e+01   \n",
       "\n",
       "               ...           radiant_ward_sentry_count  \\\n",
       "count          ...                        9.723000e+04   \n",
       "mean           ...                       -1.766165e-14   \n",
       "std            ...                        1.000005e+00   \n",
       "min            ...                       -9.874859e-01   \n",
       "25%            ...                       -9.874859e-01   \n",
       "50%            ...                        3.912027e-01   \n",
       "75%            ...                        3.912027e-01   \n",
       "max            ...                        3.347973e+01   \n",
       "\n",
       "       radiant_first_ward_time  dire_bottle_time  dire_courier_time  \\\n",
       "count             9.723000e+04      9.723000e+04       9.723000e+04   \n",
       "mean             -4.253560e-15      5.158146e-15      -6.090892e-16   \n",
       "std               1.000005e+00      1.000005e+00       1.000005e+00   \n",
       "min              -5.856560e+00     -2.038744e+00      -6.242728e-01   \n",
       "25%              -6.195987e-01     -8.648314e-01      -3.833722e-01   \n",
       "50%              -1.853141e-01      1.606554e-01      -2.629218e-01   \n",
       "75%               4.022475e-01      7.003853e-01       3.820392e-02   \n",
       "max               7.836179e+00      2.616426e+00       2.262264e+01   \n",
       "\n",
       "       dire_flying_courier_time  dire_tpscroll_count  dire_boots_count  \\\n",
       "count              9.723000e+04         9.723000e+04      9.723000e+04   \n",
       "mean              -1.830392e-14        -1.118102e-13     -3.081769e-14   \n",
       "std                1.000005e+00         1.000005e+00      1.000005e+00   \n",
       "min               -1.578386e+00        -1.554868e+00     -2.898532e+00   \n",
       "25%               -1.578386e+00        -5.062533e-01     -3.024850e-01   \n",
       "50%                3.193397e-01         1.805390e-02     -3.024850e-01   \n",
       "75%                6.506887e-01         5.423611e-01      5.628640e-01   \n",
       "max                1.433877e+00         9.455584e+00      4.889609e+00   \n",
       "\n",
       "       dire_ward_observer_count  dire_ward_sentry_count  dire_first_ward_time  \n",
       "count              9.723000e+04            9.723000e+04          9.723000e+04  \n",
       "mean               3.524860e-14            7.812983e-15          1.632655e-16  \n",
       "std                1.000005e+00            1.000005e+00          1.000005e+00  \n",
       "min               -3.009802e+00           -9.704278e-01         -1.914986e+00  \n",
       "25%               -5.511539e-01           -9.704278e-01         -6.007651e-01  \n",
       "50%               -5.511539e-01            4.377882e-01         -2.040191e-01  \n",
       "75%                6.781701e-01            4.377882e-01          3.663032e-01  \n",
       "max                8.054114e+00            1.733638e+01          7.606918e+00  \n",
       "\n",
       "[8 rows x 102 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = sklearn.cross_validation.KFold(len(X), n_folds=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_classifier = sklearn.linear_model.LogisticRegression(penalty='l2', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = dict(C=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0])\n",
    "\n",
    "grid_search = sklearn.grid_search.GridSearchCV(\n",
    "    logistic_classifier, param_grid=param_grid, scoring='roc_auc', cv=kfold, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] C=0.001 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.001, score=0.718567 -  10.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.001, score=0.713360 -   9.8s\n",
      "[CV] C=0.001 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.001, score=0.716188 -  10.2s\n",
      "[CV] C=0.001 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.001, score=0.715365 -   9.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks       | elapsed:   10.4s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks       | elapsed:   40.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.001 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.001, score=0.718084 -  10.4s\n",
      "[CV] C=0.005 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.005, score=0.718990 -  12.8s\n",
      "[CV] C=0.005 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.005, score=0.713292 -  13.0s\n",
      "[CV] C=0.005 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.005, score=0.716202 -   9.3s\n",
      "[CV] C=0.005 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.005, score=0.715651 -  12.9s\n",
      "[CV] C=0.005 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.005, score=0.718395 -  13.3s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.01, score=0.719016 -  13.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.01, score=0.713234 -  14.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 tasks       | elapsed:  1.3min\n",
      "[Parallel(n_jobs=1)]: Done  12 tasks       | elapsed:  2.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.01 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.01, score=0.716150 -  13.2s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.01, score=0.715664 -  13.1s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.01, score=0.718398 -  13.5s\n",
      "[CV] C=0.05 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.05, score=0.719033 -  13.9s\n",
      "[CV] C=0.05 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.05, score=0.713182 -  14.2s\n",
      "[CV] C=0.05 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.05, score=0.716106 -  13.5s\n",
      "[CV] C=0.05 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.05, score=0.715669 -  13.3s\n",
      "[CV] C=0.05 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.05, score=0.718381 -  13.8s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.1, score=0.719036 -  13.9s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.1, score=0.713175 -  14.3s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.1, score=0.716097 -  14.1s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.1, score=0.715666 -  13.7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks       | elapsed:  3.5min\n",
      "[Parallel(n_jobs=1)]: Done  24 tasks       | elapsed:  5.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.1 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.1, score=0.718380 -  17.2s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.5, score=0.719035 -  17.4s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.5, score=0.713168 -  17.9s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.5, score=0.716092 -  14.5s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.5, score=0.715664 -  14.1s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.5, score=0.718377 -  14.4s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=1.0, score=0.719036 -  13.8s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=1.0, score=0.713167 -  15.0s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=1.0, score=0.716091 -  14.1s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=1.0, score=0.715664 -  14.3s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=1.0, score=0.718377 -  14.1s\n",
      "[CV] C=5.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=5.0, score=0.719036 -  14.0s\n",
      "[CV] C=5.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=5.0, score=0.713166 -  15.0s\n",
      "[CV] C=5.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=5.0, score=0.716092 -  14.1s\n",
      "[CV] C=5.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=5.0, score=0.715665 -  14.2s\n",
      "[CV] C=5.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=5.0, score=0.718377 -  13.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  31 tasks       | elapsed:  6.9min\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:  9.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=10.0 ..........................................................\n",
      "[LibLinear][CV] ................................. C=10.0, score=0.719036 -  13.9s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[LibLinear][CV] ................................. C=10.0, score=0.713167 -  15.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[LibLinear][CV] ................................. C=10.0, score=0.716091 -  14.1s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[LibLinear][CV] ................................. C=10.0, score=0.715665 -  14.2s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[LibLinear][CV] ................................. C=10.0, score=0.718377 -  13.8s\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 10.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.KFold(n=97230, n_folds=5, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=1, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=10)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  10.33 min.\n"
     ]
    }
   ],
   "source": [
    "print(\"Elapsed time: \", \"{:.2f} min.\".format((toc-tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.71631, std: 0.00189, params: {'C': 0.001},\n",
       " mean: 0.71651, std: 0.00204, params: {'C': 0.005},\n",
       " mean: 0.71649, std: 0.00207, params: {'C': 0.01},\n",
       " mean: 0.71647, std: 0.00209, params: {'C': 0.05},\n",
       " mean: 0.71647, std: 0.00209, params: {'C': 0.1},\n",
       " mean: 0.71647, std: 0.00209, params: {'C': 0.5},\n",
       " mean: 0.71647, std: 0.00209, params: {'C': 1.0},\n",
       " mean: 0.71647, std: 0.00209, params: {'C': 5.0},\n",
       " mean: 0.71647, std: 0.00209, params: {'C': 10.0}]"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.005}"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71650590821237004"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.Среди признаков в выборке есть категориальные, которые мы использовали как числовые, что вряд ли является хорошей идеей. Категориальных признаков в этой задаче одиннадцать: `lobby_type` и `r1_hero`, `r2_hero`, ..., `r5_hero`, `d1_hero`, `d2_hero`, ..., `d5_hero`. Уберите их из выборки, и проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Изменилось ли качество? Чем вы можете это объяснить?  **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero',\n",
       "       'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heroes = X.columns[ X.columns.str.find('_hero')!=-1 ]\n",
    "heroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_woCateg = X.drop(['lobby_type', *heroes], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97230, 91)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_woCateg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] C=0.001 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.001, score=0.718625 -  12.1s\n",
      "[CV] C=0.001 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.001, score=0.713448 -  11.2s\n",
      "[CV] C=0.001 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.001, score=0.716086 -  10.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.001, score=0.715361 -  10.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks       | elapsed:   12.1s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks       | elapsed:   44.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.001 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.001, score=0.718293 -  11.5s\n",
      "[CV] C=0.005 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.005, score=0.719045 -  13.9s\n",
      "[CV] C=0.005 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.005, score=0.713368 -  12.5s\n",
      "[CV] C=0.005 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.005, score=0.716127 -   9.3s\n",
      "[CV] C=0.005 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.005, score=0.715659 -  10.8s\n",
      "[CV] C=0.005 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.005, score=0.718611 -  13.6s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.01, score=0.719067 -  13.7s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.01, score=0.713315 -  13.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 tasks       | elapsed:  1.4min\n",
      "[Parallel(n_jobs=1)]: Done  12 tasks       | elapsed:  2.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.01 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.01, score=0.716092 -  13.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.01, score=0.715661 -  12.2s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.01, score=0.718610 -  12.6s\n",
      "[CV] C=0.05 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.05, score=0.719079 -  12.7s\n",
      "[CV] C=0.05 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.05, score=0.713261 -  12.7s\n",
      "[CV] C=0.05 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.05, score=0.716046 -  12.5s\n",
      "[CV] C=0.05 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.05, score=0.715654 -  13.3s\n",
      "[CV] C=0.05 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.05, score=0.718592 -  14.1s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.1, score=0.719080 -  14.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.1, score=0.713255 -  14.1s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.1, score=0.716037 -  12.6s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.1, score=0.715652 -  13.8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks       | elapsed:  3.5min\n",
      "[Parallel(n_jobs=1)]: Done  24 tasks       | elapsed:  5.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.1 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.1, score=0.718589 -  12.4s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.5, score=0.719077 -  12.4s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.5, score=0.713245 -  13.2s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.5, score=0.716027 -  13.0s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.5, score=0.715651 -  12.8s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.5, score=0.718586 -  12.6s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=1.0, score=0.719077 -  12.4s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=1.0, score=0.713245 -  13.2s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=1.0, score=0.716027 -  13.3s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=1.0, score=0.715650 -  12.9s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=1.0, score=0.718585 -  12.7s\n",
      "[CV] C=5.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=5.0, score=0.719076 -  12.4s\n",
      "[CV] C=5.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=5.0, score=0.713244 -  13.2s\n",
      "[CV] C=5.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=5.0, score=0.716027 -  13.0s\n",
      "[CV] C=5.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=5.0, score=0.715650 -  13.5s\n",
      "[CV] C=5.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=5.0, score=0.718584 -  13.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  31 tasks       | elapsed:  6.6min\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:  8.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=10.0 ..........................................................\n",
      "[LibLinear][CV] ................................. C=10.0, score=0.719076 -  12.6s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[LibLinear][CV] ................................. C=10.0, score=0.713244 -  13.4s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[LibLinear][CV] ................................. C=10.0, score=0.716027 -  13.7s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[LibLinear][CV] ................................. C=10.0, score=0.715650 -  14.2s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[LibLinear][CV] ................................. C=10.0, score=0.718584 -  12.8s\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  9.7min finished\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "grid_search.fit(X_woCateg, y)\n",
    "\n",
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  9.93 min.\n"
     ]
    }
   ],
   "source": [
    "print(\"Elapsed time: \", \"{:.2f} min.\".format((toc-tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.71636, std: 0.00192, params: {'C': 0.001},\n",
       " mean: 0.71656, std: 0.00208, params: {'C': 0.005},\n",
       " mean: 0.71655, std: 0.00210, params: {'C': 0.01},\n",
       " mean: 0.71653, std: 0.00212, params: {'C': 0.05},\n",
       " mean: 0.71652, std: 0.00212, params: {'C': 0.1},\n",
       " mean: 0.71652, std: 0.00212, params: {'C': 0.5},\n",
       " mean: 0.71652, std: 0.00212, params: {'C': 1.0},\n",
       " mean: 0.71652, std: 0.00212, params: {'C': 5.0},\n",
       " mean: 0.71652, std: 0.00212, params: {'C': 10.0}]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 0.005}, 0.71656199614726124)"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.На предыдущем шаге мы исключили из выборки признаки `rM_hero` и `dM_hero`, которые показывают, какие именно герои играли за каждую команду. Это важные признаки — герои имеют разные характеристики, и некоторые из них выигрывают чаще, чем другие. Выясните из данных, сколько различных идентификаторов героев существует в данной игре (вам может пригодиться фукнция `unique` или `value_counts`). **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 11,  42,  33,  29,  13,   8,  35,  17,  15,  22,  27,  68,  26,\n",
       "         53,  20,  92,  88, 104,   3,  73,  72, 110,  36,  58,  91,  50,\n",
       "         71,  30,  25,  39,  19, 101,  94,  51,   7,  75,  46,  66,  67,\n",
       "         93,  38,  65,  12,  99,  44,  10,  41,  34, 102,  32,  95,  84,\n",
       "         81,  16,   6,  96,  43,  79,  47,   1,   2,  63,  97,  80,  54,\n",
       "         83,   5,  60,  77, 112,  21,  69,  85,  82,  87,  62,  18,  74,\n",
       "         28,  61,  14,  90,  70,  78,  52,  48,  49,   4,  98,  59,  56,\n",
       "         86,  37, 100,  23,  57, 106,  40,   9,  76,  31,  64, 109, 103,\n",
       "         55, 105,  89,  45], dtype=int64), (108,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.r1_hero.unique(), np.shape(data.r1_hero.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11     5045\n",
       "7      3899\n",
       "72     3551\n",
       "39     3341\n",
       "112    3119\n",
       "50     3006\n",
       "100    2623\n",
       "21     2533\n",
       "25     2385\n",
       "71     2349\n",
       "55     2235\n",
       "106    2128\n",
       "85     1965\n",
       "30     1845\n",
       "8      1748\n",
       "28     1688\n",
       "51     1635\n",
       "86     1595\n",
       "26     1584\n",
       "87     1542\n",
       "68     1511\n",
       "60     1479\n",
       "74     1379\n",
       "46     1343\n",
       "47     1313\n",
       "75     1301\n",
       "73     1225\n",
       "1      1199\n",
       "42     1079\n",
       "3      1058\n",
       "       ... \n",
       "61      318\n",
       "9       315\n",
       "34      306\n",
       "79      305\n",
       "16      295\n",
       "98      286\n",
       "43      279\n",
       "54      266\n",
       "23      259\n",
       "90      238\n",
       "35      238\n",
       "63      232\n",
       "92      231\n",
       "65      217\n",
       "45      214\n",
       "76      213\n",
       "82      212\n",
       "95      199\n",
       "32      193\n",
       "83      169\n",
       "53      167\n",
       "105     159\n",
       "10      157\n",
       "78      156\n",
       "77      130\n",
       "66      108\n",
       "80       88\n",
       "103      75\n",
       "58       69\n",
       "109      20\n",
       "Name: r1_hero, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.r1_hero.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 11,  67,  29,  20, 105,   4,  42,  21,  37,  84,  49,  26,  39,\n",
       "         88,  79,   7,  12,  33,  98,  27,  22,  66,  86,  80,  30,  75,\n",
       "         41,  96,  48,  15, 102,  13,  72,  93,  69,  25,   8,  28,  65,\n",
       "         55,  52,   3,  73,  57,  36, 101,  47,  35,  83, 100,  44,  17,\n",
       "         91,  53,  90,  19,  74,  76,  99,   1,  94,  82,  60, 112,  31,\n",
       "         85,  61,  70,  68,  51,   2,  50,  71,  23,  77,  16,  63,  92,\n",
       "         81,  18,  59,  95,  64,  58,  43, 104,  40,  87,  10,  14, 110,\n",
       "         38,  46,  54,  97,  89,   5,  62,   6,  78, 106,  34,  56, 103,\n",
       "        109,  45,   9,  32], dtype=int64), 108, 112)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_heroes = pd.Series( data[[*heroes]].values.flatten() ).unique()\n",
    "\n",
    "num_unique_heroes = len(unique_heroes)\n",
    "N_heroes = max(unique_heroes)\n",
    "\n",
    "unique_heroes, num_unique_heroes, N_heroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.Воспользуемся подходом \"мешок слов\" для кодирования информации о героях. Пусть всего в игре имеет `N` различных героев. Сформируем `N` признаков, при этом `i`-й будет равен нулю, если `i`-й герой не участвовал в матче; единице, если `i`-й герой играл за команду Radiant; минус единице, если `i`-й герой играл за команду Dire. Ниже вы можете найти код, который выполняет данной преобразование. Добавьте полученные признаки к числовым, которые вы использовали во втором пункте данного этапа. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Код для формирования \"мешка слов\" по героям\n",
    "# N — количество различных героев в выборке\n",
    "data_heroes = data[[*heroes]]\n",
    "\n",
    "X_pick = np.zeros((data_heroes.shape[0], N_heroes))\n",
    "\n",
    "for i, match_id in enumerate(data_heroes.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data_heroes.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data_heroes.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97230, 10), (97230, 112))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_heroes), np.shape(X_pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  1., -1.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
       "         0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), 5, 5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pick[0], np.sum(X_pick[0]==1), np.sum(X_pick[0]==-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_wBag = pd.concat([ X_woCateg, pd.DataFrame(X_pick, index=X_woCateg.index)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97230, 203)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_wBag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5.Проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Какое получилось качество? Улучшилось ли оно? Чем вы можете это объяснить? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] C=0.001 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.001, score=0.746154 -  15.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.001, score=0.752095 -  13.1s\n",
      "[CV] C=0.001 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.001, score=0.743552 -  12.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.001, score=0.743085 -  15.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks       | elapsed:   15.4s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks       | elapsed:   56.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.001 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.001, score=0.746382 -  12.8s\n",
      "[CV] C=0.005 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.005, score=0.751621 -  18.4s\n",
      "[CV] C=0.005 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.005, score=0.756534 -  19.0s\n",
      "[CV] C=0.005 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.005, score=0.748955 -  18.9s\n",
      "[CV] C=0.005 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.005, score=0.748892 -  17.6s\n",
      "[CV] C=0.005 .........................................................\n",
      "[LibLinear][CV] ................................ C=0.005, score=0.750149 -  18.2s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.01, score=0.752253 -  20.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.01, score=0.756953 -  19.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 tasks       | elapsed:  1.8min\n",
      "[Parallel(n_jobs=1)]: Done  12 tasks       | elapsed:  3.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.01 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.01, score=0.749594 -  19.3s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.01, score=0.749709 -  19.3s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.01, score=0.750406 -  17.9s\n",
      "[CV] C=0.05 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.05, score=0.752544 -  23.8s\n",
      "[CV] C=0.05 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.05, score=0.757091 -  22.8s\n",
      "[CV] C=0.05 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.05, score=0.749935 -  25.9s\n",
      "[CV] C=0.05 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.05, score=0.750208 -  24.6s\n",
      "[CV] C=0.05 ..........................................................\n",
      "[LibLinear][CV] ................................. C=0.05, score=0.750361 -  21.8s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.1, score=0.752553 -  26.3s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.1, score=0.757070 -  24.7s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.1, score=0.749947 -  27.1s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.1, score=0.750239 -  27.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks       | elapsed:  5.1min\n",
      "[Parallel(n_jobs=1)]: Done  24 tasks       | elapsed:  8.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.1 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.1, score=0.750308 -  21.7s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.5, score=0.752542 -  27.8s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.5, score=0.757051 -  28.1s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.5, score=0.749938 -  27.7s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.5, score=0.750255 -  30.6s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[LibLinear][CV] .................................. C=0.5, score=0.750260 -  25.4s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=1.0, score=0.752542 -  28.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=1.0, score=0.757048 -  27.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=1.0, score=0.749939 -  35.1s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=1.0, score=0.750256 -  47.3s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=1.0, score=0.750252 -  23.9s\n",
      "[CV] C=5.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=5.0, score=0.752539 -  27.8s\n",
      "[CV] C=5.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=5.0, score=0.757045 -  28.1s\n",
      "[CV] C=5.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=5.0, score=0.749938 -  27.8s\n",
      "[CV] C=5.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=5.0, score=0.750257 -  30.4s\n",
      "[CV] C=5.0 ...........................................................\n",
      "[LibLinear][CV] .................................. C=5.0, score=0.750246 -  24.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  31 tasks       | elapsed: 11.3min\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed: 15.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=10.0 ..........................................................\n",
      "[LibLinear][CV] ................................. C=10.0, score=0.752538 -  27.7s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[LibLinear][CV] ................................. C=10.0, score=0.757045 -  27.5s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[LibLinear][CV] ................................. C=10.0, score=0.749938 -  27.5s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[LibLinear][CV] ................................. C=10.0, score=0.750257 -  27.9s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[LibLinear][CV] ................................. C=10.0, score=0.750245 -  23.9s\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 18.1min finished\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "grid_search.fit(X_wBag, y)\n",
    "\n",
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  18.57 min.\n"
     ]
    }
   ],
   "source": [
    "print(\"Elapsed time: \", \"{:.2f} min.\".format((toc-tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.74625, std: 0.00321, params: {'C': 0.001},\n",
       " mean: 0.75123, std: 0.00283, params: {'C': 0.005},\n",
       " mean: 0.75178, std: 0.00275, params: {'C': 0.01},\n",
       " mean: 0.75203, std: 0.00270, params: {'C': 0.05},\n",
       " mean: 0.75202, std: 0.00269, params: {'C': 0.1},\n",
       " mean: 0.75201, std: 0.00269, params: {'C': 0.5},\n",
       " mean: 0.75201, std: 0.00269, params: {'C': 1.0},\n",
       " mean: 0.75200, std: 0.00269, params: {'C': 5.0},\n",
       " mean: 0.75200, std: 0.00269, params: {'C': 10.0}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 0.05}, 0.75202780383492607)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 6.Постройте предсказания вероятностей победы команды Radiant для тестовой выборки с помощью лучшей из изученных моделей (лучшей с точки зрения AUC-ROC на кросс-валидации). Убедитесь, что предсказанные вероятности адекватные — находятся на отрезке [0, 1], не совпадают между собой (т.е. что модель не получилась константной). **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "logistic_classifier = sklearn.linear_model.LogisticRegression(C=0.05, penalty='l2', verbose=1)\n",
    "logistic_classifier.fit(X_wBag, y)\n",
    "\n",
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  0.57 min.\n"
     ]
    }
   ],
   "source": [
    "print(\"Elapsed time: \", \"{:.2f} min.\".format((toc-tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75443547606949113"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logistic_classifier.predict_proba(X_wBag)\n",
    "\n",
    "sklearn.metrics.roc_auc_score(y, y_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>lobby_type</th>\n",
       "      <th>r1_hero</th>\n",
       "      <th>r1_level</th>\n",
       "      <th>r1_xp</th>\n",
       "      <th>r1_gold</th>\n",
       "      <th>r1_lh</th>\n",
       "      <th>r1_kills</th>\n",
       "      <th>r1_deaths</th>\n",
       "      <th>r1_items</th>\n",
       "      <th>...</th>\n",
       "      <th>radiant_ward_sentry_count</th>\n",
       "      <th>radiant_first_ward_time</th>\n",
       "      <th>dire_bottle_time</th>\n",
       "      <th>dire_courier_time</th>\n",
       "      <th>dire_flying_courier_time</th>\n",
       "      <th>dire_tpscroll_count</th>\n",
       "      <th>dire_boots_count</th>\n",
       "      <th>dire_ward_observer_count</th>\n",
       "      <th>dire_ward_sentry_count</th>\n",
       "      <th>dire_first_ward_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1430287923</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "      <td>1103</td>\n",
       "      <td>1089</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>247</td>\n",
       "      <td>-86</td>\n",
       "      <td>272</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1430293357</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>556</td>\n",
       "      <td>570</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-29</td>\n",
       "      <td>168</td>\n",
       "      <td>-54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1430301774</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>751</td>\n",
       "      <td>808</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-22</td>\n",
       "      <td>46</td>\n",
       "      <td>-87</td>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1430323933</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>708</td>\n",
       "      <td>903</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-49</td>\n",
       "      <td>30</td>\n",
       "      <td>-89</td>\n",
       "      <td>210</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1430331112</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>1259</td>\n",
       "      <td>661</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>180</td>\n",
       "      <td>-86</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          start_time  lobby_type  r1_hero  r1_level  r1_xp  r1_gold  r1_lh  \\\n",
       "match_id                                                                     \n",
       "6         1430287923           0       93         4   1103     1089      8   \n",
       "7         1430293357           1       20         2    556      570      1   \n",
       "10        1430301774           1      112         2    751      808      1   \n",
       "13        1430323933           1       27         3    708      903      1   \n",
       "16        1430331112           1       39         4   1259      661      4   \n",
       "\n",
       "          r1_kills  r1_deaths  r1_items          ...           \\\n",
       "match_id                                         ...            \n",
       "6                0          1         9          ...            \n",
       "7                0          0         9          ...            \n",
       "10               0          0        13          ...            \n",
       "13               1          1        11          ...            \n",
       "16               0          0         9          ...            \n",
       "\n",
       "          radiant_ward_sentry_count  radiant_first_ward_time  \\\n",
       "match_id                                                       \n",
       "6                                 0                       12   \n",
       "7                                 2                      -29   \n",
       "10                                1                      -22   \n",
       "13                                2                      -49   \n",
       "16                                0                       36   \n",
       "\n",
       "          dire_bottle_time  dire_courier_time  dire_flying_courier_time  \\\n",
       "match_id                                                                  \n",
       "6                      247                -86                       272   \n",
       "7                      168                -54                       NaN   \n",
       "10                      46                -87                       186   \n",
       "13                      30                -89                       210   \n",
       "16                     180                -86                       180   \n",
       "\n",
       "          dire_tpscroll_count  dire_boots_count  dire_ward_observer_count  \\\n",
       "match_id                                                                    \n",
       "6                           3                 4                         2   \n",
       "7                           3                 2                         2   \n",
       "10                          1                 3                         3   \n",
       "13                          3                 4                         2   \n",
       "16                          1                 3                         2   \n",
       "\n",
       "          dire_ward_sentry_count  dire_first_ward_time  \n",
       "match_id                                                \n",
       "6                              0                   118  \n",
       "7                              1                    16  \n",
       "10                             0                   -34  \n",
       "13                             1                   -26  \n",
       "16                             1                   -33  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zfile_test = zipfile.ZipFile('features_test.zip')\n",
    "\n",
    "data_test = pd.read_csv(zfile_test.open('features_test.csv'), index_col='match_id')\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17177, 102)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = data_test\n",
    "np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "X_test = pd.DataFrame( scaler.fit_transform(X) , index=X_test.index, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_woCateg_test = X_test.drop(['lobby_type', *heroes], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Код для формирования \"мешка слов\" по героям\n",
    "# N — количество различных героев в выборке\n",
    "data_heroes = data_test[[*heroes]]\n",
    "\n",
    "X_pick = np.zeros((data_heroes.shape[0], N_heroes))\n",
    "\n",
    "for i, match_id in enumerate(data_heroes.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data_heroes.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data_heroes.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_wBag_test = pd.concat([ X_woCateg_test, pd.DataFrame(X_pick, index=X_woCateg_test.index)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17177, 203)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_wBag_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17177, 2)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logistic_classifier.predict_proba(X_wBag_test)\n",
    "np.shape(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x8e0d530>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEQCAYAAACz0c/rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8e207d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred[:,1], bins=50);\n",
    "plt.axvline(0.5,linestyle='--',color='r')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0085516454251114843, 0.99640182014530887)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(y_pred[:,1]), np.max(y_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.xscale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((203,), (203,))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_wBag_test.columns.shape, logistic_classifier.coef_[:][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(np.c_[X_wBag_test.columns, logistic_classifier.coef_[:][0]], columns=['feature','importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importance['abs'] = np.abs(importance.importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = importance['abs'].quantile(np.linspace(0,1,11)[1:-1]).values\n",
    "importance['quant'] = importance['abs'].apply(lambda x: (x > q).sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>abs</th>\n",
       "      <th>quant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>66</td>\n",
       "      <td>0.616287</td>\n",
       "      <td>0.616287</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.53652</td>\n",
       "      <td>0.53652</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.497777</td>\n",
       "      <td>0.497777</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>56</td>\n",
       "      <td>0.478889</td>\n",
       "      <td>0.478889</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>75</td>\n",
       "      <td>-0.442539</td>\n",
       "      <td>0.442539</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>57</td>\n",
       "      <td>-0.440963</td>\n",
       "      <td>0.440963</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>32</td>\n",
       "      <td>-0.404076</td>\n",
       "      <td>0.404076</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>38</td>\n",
       "      <td>-0.378644</td>\n",
       "      <td>0.378644</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>101</td>\n",
       "      <td>0.374187</td>\n",
       "      <td>0.374187</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>31</td>\n",
       "      <td>0.354631</td>\n",
       "      <td>0.354631</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>100</td>\n",
       "      <td>-0.342659</td>\n",
       "      <td>0.342659</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>41</td>\n",
       "      <td>0.327427</td>\n",
       "      <td>0.327427</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>46</td>\n",
       "      <td>-0.324748</td>\n",
       "      <td>0.324748</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>24</td>\n",
       "      <td>-0.316576</td>\n",
       "      <td>0.316576</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>76</td>\n",
       "      <td>0.295601</td>\n",
       "      <td>0.295601</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>68</td>\n",
       "      <td>0.295221</td>\n",
       "      <td>0.295221</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>60</td>\n",
       "      <td>-0.290441</td>\n",
       "      <td>0.290441</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>21</td>\n",
       "      <td>0.279591</td>\n",
       "      <td>0.279591</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>81</td>\n",
       "      <td>0.277021</td>\n",
       "      <td>0.277021</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>70</td>\n",
       "      <td>0.254506</td>\n",
       "      <td>0.254506</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>52</td>\n",
       "      <td>-0.250264</td>\n",
       "      <td>0.250264</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>103</td>\n",
       "      <td>-0.236331</td>\n",
       "      <td>0.236331</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>d3_lh</td>\n",
       "      <td>-0.234651</td>\n",
       "      <td>0.234651</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>r3_lh</td>\n",
       "      <td>0.231318</td>\n",
       "      <td>0.231318</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>r4_lh</td>\n",
       "      <td>0.230342</td>\n",
       "      <td>0.230342</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>69</td>\n",
       "      <td>0.229446</td>\n",
       "      <td>0.229446</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6</td>\n",
       "      <td>0.228367</td>\n",
       "      <td>0.228367</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>d5_lh</td>\n",
       "      <td>-0.225597</td>\n",
       "      <td>0.225597</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>r2_lh</td>\n",
       "      <td>0.22519</td>\n",
       "      <td>0.22519</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>20</td>\n",
       "      <td>-0.223604</td>\n",
       "      <td>0.223604</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>d1_level</td>\n",
       "      <td>-0.0154802</td>\n",
       "      <td>0.0154802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>73</td>\n",
       "      <td>-0.0137634</td>\n",
       "      <td>0.0137634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>49</td>\n",
       "      <td>-0.0136257</td>\n",
       "      <td>0.0136257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>dire_flying_courier_time</td>\n",
       "      <td>-0.0123931</td>\n",
       "      <td>0.0123931</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>dire_boots_count</td>\n",
       "      <td>-0.0109439</td>\n",
       "      <td>0.0109439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>28</td>\n",
       "      <td>-0.0106761</td>\n",
       "      <td>0.0106761</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>first_blood_time</td>\n",
       "      <td>0.00936023</td>\n",
       "      <td>0.00936023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>r4_level</td>\n",
       "      <td>0.00908072</td>\n",
       "      <td>0.00908072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>dire_ward_observer_count</td>\n",
       "      <td>0.00758172</td>\n",
       "      <td>0.00758172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>radiant_ward_observer_count</td>\n",
       "      <td>-0.0073735</td>\n",
       "      <td>0.0073735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>dire_bottle_time</td>\n",
       "      <td>0.00718674</td>\n",
       "      <td>0.00718674</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>15</td>\n",
       "      <td>0.00683146</td>\n",
       "      <td>0.00683146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>d2_level</td>\n",
       "      <td>-0.00661283</td>\n",
       "      <td>0.00661283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>111</td>\n",
       "      <td>0.00607384</td>\n",
       "      <td>0.00607384</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>first_blood_team</td>\n",
       "      <td>0.0059366</td>\n",
       "      <td>0.0059366</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r1_level</td>\n",
       "      <td>-0.00499394</td>\n",
       "      <td>0.00499394</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>r3_level</td>\n",
       "      <td>0.00489562</td>\n",
       "      <td>0.00489562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>22</td>\n",
       "      <td>0.00435964</td>\n",
       "      <td>0.00435964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>dire_ward_sentry_count</td>\n",
       "      <td>-0.00333701</td>\n",
       "      <td>0.00333701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>radiant_ward_sentry_count</td>\n",
       "      <td>0.00318312</td>\n",
       "      <td>0.00318312</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>d3_level</td>\n",
       "      <td>0.00249767</td>\n",
       "      <td>0.00249767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>77</td>\n",
       "      <td>-0.00226028</td>\n",
       "      <td>0.00226028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>radiant_bottle_time</td>\n",
       "      <td>-0.00191585</td>\n",
       "      <td>0.00191585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>44</td>\n",
       "      <td>0.00164964</td>\n",
       "      <td>0.00164964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>d5_level</td>\n",
       "      <td>0.00142477</td>\n",
       "      <td>0.00142477</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>first_blood_player1</td>\n",
       "      <td>-0.000637421</td>\n",
       "      <td>0.000637421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         feature   importance          abs  quant\n",
       "157                           66     0.616287     0.616287      9\n",
       "92                             1     -0.53652      0.53652      9\n",
       "103                           12    -0.497777     0.497777      9\n",
       "147                           56     0.478889     0.478889      9\n",
       "166                           75    -0.442539     0.442539      9\n",
       "148                           57    -0.440963     0.440963      9\n",
       "123                           32    -0.404076     0.404076      9\n",
       "129                           38    -0.378644     0.378644      9\n",
       "192                          101     0.374187     0.374187      9\n",
       "122                           31     0.354631     0.354631      9\n",
       "191                          100    -0.342659     0.342659      9\n",
       "132                           41     0.327427     0.327427      9\n",
       "137                           46    -0.324748     0.324748      9\n",
       "115                           24    -0.316576     0.316576      9\n",
       "167                           76     0.295601     0.295601      9\n",
       "159                           68     0.295221     0.295221      9\n",
       "151                           60    -0.290441     0.290441      9\n",
       "112                           21     0.279591     0.279591      9\n",
       "172                           81     0.277021     0.277021      9\n",
       "161                           70     0.254506     0.254506      9\n",
       "143                           52    -0.250264     0.250264      9\n",
       "194                          103    -0.236331     0.236331      8\n",
       "53                         d3_lh    -0.234651     0.234651      8\n",
       "18                         r3_lh     0.231318     0.231318      8\n",
       "25                         r4_lh     0.230342     0.230342      8\n",
       "160                           69     0.229446     0.229446      8\n",
       "97                             6     0.228367     0.228367      8\n",
       "67                         d5_lh    -0.225597     0.225597      8\n",
       "11                         r2_lh      0.22519      0.22519      8\n",
       "111                           20    -0.223604     0.223604      8\n",
       "..                           ...          ...          ...    ...\n",
       "36                      d1_level   -0.0154802    0.0154802      1\n",
       "164                           73   -0.0137634    0.0137634      1\n",
       "140                           49   -0.0136257    0.0136257      1\n",
       "85      dire_flying_courier_time   -0.0123931    0.0123931      1\n",
       "87              dire_boots_count   -0.0109439    0.0109439      1\n",
       "119                           28   -0.0106761    0.0106761      1\n",
       "71              first_blood_time   0.00936023   0.00936023      1\n",
       "22                      r4_level   0.00908072   0.00908072      1\n",
       "88      dire_ward_observer_count   0.00758172   0.00758172      1\n",
       "80   radiant_ward_observer_count   -0.0073735    0.0073735      0\n",
       "83              dire_bottle_time   0.00718674   0.00718674      0\n",
       "106                           15   0.00683146   0.00683146      0\n",
       "43                      d2_level  -0.00661283   0.00661283      0\n",
       "202                          111   0.00607384   0.00607384      0\n",
       "72              first_blood_team    0.0059366    0.0059366      0\n",
       "1                       r1_level  -0.00499394   0.00499394      0\n",
       "15                      r3_level   0.00489562   0.00489562      0\n",
       "113                           22   0.00435964   0.00435964      0\n",
       "89        dire_ward_sentry_count  -0.00333701   0.00333701      0\n",
       "81     radiant_ward_sentry_count   0.00318312   0.00318312      0\n",
       "50                      d3_level   0.00249767   0.00249767      0\n",
       "168                           77  -0.00226028   0.00226028      0\n",
       "75           radiant_bottle_time  -0.00191585   0.00191585      0\n",
       "135                           44   0.00164964   0.00164964      0\n",
       "64                      d5_level   0.00142477   0.00142477      0\n",
       "73           first_blood_player1 -0.000637421  0.000637421      0\n",
       "197                          106            0            0      0\n",
       "198                          107            0            0      0\n",
       "114                           23            0            0      0\n",
       "201                          110            0            0      0\n",
       "\n",
       "[203 rows x 4 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance.sort('abs',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В отчете по данному этапу вы должны ответить на следующие вопросы:\n",
    "\n",
    "** 1.Какое качество получилось у логистической регрессии над всеми исходными признаками? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"darkblue\" size=\"3em\">\n",
    "\n",
    "Значение `auc_roc`, характеризующее качество классификации, у логистической регрессии со всеми исходными признаками для лучшего подобранного значения параметра регуляризации `C=0.05` получилось равно `0.7165`. Для градиентного бустинга в лучшем случае удавалось получить не более `0.689` по полной выборке для `n_estimators=30`. \n",
    "\n",
    "Такую разницу можно объяснить особенностями выборки. По всей видимости, в выборке присутствует большое количество коррелирующих признаков. На такой выборке лучше работает именно линейный классификатор с регуляризацией, уменьшающей переобучение. Возможно, сильное сокращение количества признаков позволит методу градиентного бустинга показать лучшие результаты.\n",
    "\n",
    "Обучение логистической регрессии происходит значительно быстрее (1-2 мин. на одну модель с 5-ю кросс-валидациями) обучения градиентного бустинга (более 28 минут на одну модель)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.Как влияет на качество логистической регрессии удаление категориальных признаков (укажите новое значение метрики качества)? Чем вы можете объяснить это изменение? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"darkblue\" size=\"3em\">\n",
    "\n",
    "Удаление категориальных признаков незначительно улучшило качество классификации, с `0.716505` до `0.716561`. \n",
    "\n",
    "Скорее всего, удаление части признаков может положительно сказаться на результате только если удаляются признаки, которые сильно коррелируют с уже имеющимися. К тому же удаляется лишь небольшой процент от общего числа признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.Сколько различных идентификаторов героев существует в данной игре? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"darkblue\" size=\"3em\">\n",
    "\n",
    "Идентификаторы героев находятся в диапазоне от `1` до `112`, но некоторые герои в данной выборке матчей не принимали участие. В данной выборке присутствует `108` различных уникальных идентификаторов героев. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.Какое получилось качество при добавлении \"мешка слов\" по героям? Улучшилось ли оно по сравнению с предыдущим вариантом? Чем вы можете это объяснить? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"darkblue\" size=\"3em\">\n",
    "\n",
    "При добавлении к признакам \"мешка слов\" по героям, значение `auc_roc` увеличилось на кросс-валидации до `0.7520` при `C=0.05`. Это значительное улучшение по сравнению с предыдущими результатами.\n",
    "\n",
    "Данное улучшение можно объяснить тем, что, по всей видимости, выбор игроками конкретных героев в данной игре может оказывать существенное влияние на конечный результат игры при прочих равных условиях, наблюдающихся в первые пять минут матча."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5.Какое минимальное и максимальное значение прогноза на тестовой выборке получилось у лучшего из алгоритмов? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"darkblue\" size=\"3em\">\n",
    "\n",
    "Для лучшего из алгоритмов (`LogisticRegression` с параметром `C=0.05`) значения прогноза `y_pred` на тестовой выборке оказались в диапазоне от `0.0085` до `0.9964`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
